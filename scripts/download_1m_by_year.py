"""
åˆ†å¹´ä¸‹è¼‰ 1m Kç·šè³‡æ–™
æ›´å®‰å…¨ã€å¯æ¢å¾©ã€ä¸æ˜“ä¸­æ–·
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
import time
import pandas as pd
from tqdm import tqdm
import json

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.exchange.binance_client import BinanceClient


def download_year_data(client: BinanceClient, year: int, symbol: str = "BTCUSDT") -> pd.DataFrame:
    """
    ä¸‹è¼‰æŒ‡å®šå¹´ä»½çš„ 1m Kç·šè³‡æ–™
    
    Args:
        client: BinanceClient å¯¦ä¾‹
        year: å¹´ä»½
        symbol: äº¤æ˜“å°
    
    Returns:
        è©²å¹´ä»½çš„ Kç·š DataFrame
    """
    # æ™‚é–“ç¯„åœ
    start_time = datetime(year, 1, 1)
    end_time = datetime(year + 1, 1, 1)
    
    # å¦‚æœæ˜¯ç•¶å‰å¹´ä»½ï¼ŒçµæŸæ™‚é–“è¨­ç‚ºç¾åœ¨
    if year == datetime.now().year:
        end_time = datetime.now()
    
    print(f"\nğŸ“¥ ä¸‹è¼‰ {year} å¹´è³‡æ–™")
    print(f"   æ™‚é–“ç¯„åœ: {start_time.date()} ~ {end_time.date()}")
    
    all_klines = []
    current_start = int(start_time.timestamp() * 1000)
    end_ts = int(end_time.timestamp() * 1000)
    
    # é ä¼°è«‹æ±‚æ¬¡æ•¸ï¼ˆ1å¹´ç´„ 525,600 åˆ†é˜ = 526 å€‹è«‹æ±‚ï¼‰
    estimated_requests = 530
    pbar = tqdm(total=estimated_requests, desc=f"  {year}", unit="req")
    
    request_count = 0
    
    while current_start < end_ts:
        try:
            klines = client.get_klines(
                symbol=symbol,
                interval='1m',
                start_time=current_start,
                limit=1000
            )
            
            if not klines:
                break
            
            all_klines.extend(klines)
            current_start = int(klines[-1][6]) + 1  # æœ€å¾Œä¸€æ ¹çš„æ”¶ç›¤æ™‚é–“ + 1ms
            
            request_count += 1
            pbar.update(1)
            
            # é¿å…é€Ÿç‡é™åˆ¶
            time.sleep(0.1)
            
        except Exception as e:
            print(f"\n   âš ï¸  éŒ¯èª¤: {e}")
            print(f"   â¸ï¸  ç­‰å¾… 5 ç§’å¾Œé‡è©¦...")
            time.sleep(5)
            continue
    
    pbar.close()
    
    # è½‰æ›ç‚º DataFrame
    if not all_klines:
        print(f"   âŒ æ²’æœ‰è³‡æ–™")
        return None
    
    df = pd.DataFrame(all_klines, columns=[
        'timestamp', 'open', 'high', 'low', 'close', 'volume',
        'close_time', 'quote_volume', 'trades', 'taker_buy_base',
        'taker_buy_quote', 'ignore'
    ])
    
    # è½‰æ›è³‡æ–™é¡å‹
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
    
    for col in ['open', 'high', 'low', 'close', 'volume', 'quote_volume', 'taker_buy_base', 'taker_buy_quote']:
        df[col] = df[col].astype(float)
    
    df['trades'] = df['trades'].astype(int)
    df = df.drop(columns=['ignore'])
    
    # å»é‡æ’åº
    df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
    
    print(f"   âœ… å®Œæˆï¼{len(df):,} æ ¹Kç·š")
    print(f"   å¯¦éš›ç¯„åœ: {df.iloc[0]['timestamp']} ~ {df.iloc[-1]['timestamp']}")
    
    return df


def main():
    """ä¸»å‡½æ•¸"""
    print("\nğŸš€ åˆ†å¹´ä¸‹è¼‰ BTC/USDT 1m Kç·šè³‡æ–™\n")
    print("=" * 80)
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    client = BinanceClient()
    from binance.client import Client
    client.client = Client(api_key="", api_secret="")  # Mainnet å…¬é–‹è³‡æ–™
    
    data_dir = Path("data/historical")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    symbol = "BTCUSDT"
    
    # ä¸‹è¼‰å¹´ä»½ç¯„åœï¼ˆ2020-2025ï¼‰
    years = [2020, 2021, 2022, 2023, 2024, 2025]
    
    print(f"ğŸ“… å°‡ä¸‹è¼‰ {len(years)} å¹´çš„è³‡æ–™: {years}\n")
    
    all_dfs = []
    stats = {
        'symbol': symbol,
        'interval': '1m',
        'years': {},
        'download_time': datetime.now().isoformat(),
    }
    
    # é€å¹´ä¸‹è¼‰
    for year in years:
        year_file = data_dir / f"{symbol}_1m_{year}.parquet"
        
        # æª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
        if year_file.exists():
            print(f"\nâœ… {year} å¹´è³‡æ–™å·²å­˜åœ¨ï¼Œè¼‰å…¥ä¸­...")
            df_year = pd.read_parquet(year_file)
            print(f"   å·²è¼‰å…¥ {len(df_year):,} æ ¹Kç·š")
            all_dfs.append(df_year)
            
            stats['years'][year] = {
                'rows': len(df_year),
                'start': df_year.iloc[0]['timestamp'].isoformat(),
                'end': df_year.iloc[-1]['timestamp'].isoformat(),
                'status': 'cached'
            }
            continue
        
        # ä¸‹è¼‰
        try:
            df_year = download_year_data(client, year, symbol)
            
            if df_year is not None and len(df_year) > 0:
                # å„²å­˜å¹´åº¦æª”æ¡ˆ
                df_year.to_parquet(year_file, index=False)
                file_size_mb = year_file.stat().st_size / 1024 / 1024
                print(f"   ğŸ’¾ å·²å„²å­˜: {year_file.name} ({file_size_mb:.2f} MB)")
                
                all_dfs.append(df_year)
                
                stats['years'][year] = {
                    'rows': len(df_year),
                    'start': df_year.iloc[0]['timestamp'].isoformat(),
                    'end': df_year.iloc[-1]['timestamp'].isoformat(),
                    'size_mb': round(file_size_mb, 2),
                    'status': 'downloaded'
                }
            
        except Exception as e:
            print(f"   âŒ {year} å¹´ä¸‹è¼‰å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # åˆä½µæ‰€æœ‰å¹´ä»½
    if not all_dfs:
        print("\nâŒ æ²’æœ‰ä»»ä½•è³‡æ–™")
        return
    
    print("\n" + "=" * 80)
    print("ğŸ“¦ åˆä½µæ‰€æœ‰å¹´ä»½è³‡æ–™...")
    
    df_final = pd.concat(all_dfs, ignore_index=True)
    df_final = df_final.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
    
    # å„²å­˜æœ€çµ‚æª”æ¡ˆ
    final_file = data_dir / f"{symbol}_1m.parquet"
    df_final.to_parquet(final_file, index=False)
    final_size_mb = final_file.stat().st_size / 1024 / 1024
    
    print(f"   âœ… å·²åˆä½µ {len(df_final):,} æ ¹Kç·š")
    print(f"   ğŸ’¾ å·²å„²å­˜: {final_file.name} ({final_size_mb:.2f} MB)")
    print(f"   æ™‚é–“ç¯„åœ: {df_final.iloc[0]['timestamp']} ~ {df_final.iloc[-1]['timestamp']}")
    
    # çµ±è¨ˆè³‡è¨Š
    stats['total_rows'] = len(df_final)
    stats['total_size_mb'] = round(final_size_mb, 2)
    stats['time_range'] = {
        'start': df_final.iloc[0]['timestamp'].isoformat(),
        'end': df_final.iloc[-1]['timestamp'].isoformat(),
        'days': (df_final.iloc[-1]['timestamp'] - df_final.iloc[0]['timestamp']).days
    }
    
    # å„²å­˜çµ±è¨ˆ
    stats_file = data_dir / 'download_1m_stats.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    # é¡¯ç¤ºæ‘˜è¦
    print("\n" + "=" * 80)
    print("âœ… ä¸‹è¼‰å®Œæˆï¼")
    print("=" * 80)
    print()
    print("ğŸ“Š å„å¹´ä»½çµ±è¨ˆ:")
    for year, info in stats['years'].items():
        status_icon = "âœ…" if info['status'] == 'downloaded' else "ğŸ“¦"
        print(f"   {status_icon} {year}: {info['rows']:>10,} rows")
    
    print()
    print(f"ğŸ“ˆ ç¸½è¨ˆ: {stats['total_rows']:,} æ ¹Kç·š")
    print(f"ğŸ’¾ å¤§å°: {stats['total_size_mb']:.2f} MB")
    print(f"ğŸ“… ç¯„åœ: {stats['time_range']['days']} å¤©")
    print()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·")
        print("ğŸ’¡ å·²ä¸‹è¼‰çš„å¹´ä»½è³‡æ–™æœƒä¿ç•™ï¼Œä¸‹æ¬¡åŸ·è¡Œæœƒè‡ªå‹•è·³é")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
