#!/usr/bin/env python3
"""
AI Trading Advisor - åˆ†æç•¶å‰äº¤æ˜“ç‹€æ…‹ä¸¦æä¾›ç²åˆ©å»ºè­°
è®€å–ï¼š
1. æœ€æ–°çš„ paper trading æ•¸æ“š
2. å¸‚å ´å¿«ç…§ï¼ˆçˆ†å€‰å£“åŠ›ã€OIï¼‰
3. ç•¶å‰æŒå€‰ç‹€æ…‹

è¼¸å‡ºï¼š
- å“ªäº›ç­–ç•¥è¡¨ç¾å¥½/å·®
- ç•¶å‰å¸‚å ´æ©Ÿæœƒåœ¨å“ªè£¡
- å»ºè­°èª¿æ•´å“ªäº›åƒæ•¸
"""

import uuid
import json
import os
import sys
import time
import pandas as pd
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

# ç‹€æ…‹æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„ AI çš„é•·æœŸé æ¸¬
STATE_FILE = "ai_advisor_state.json"
# ç­–ç•¥è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„ AI çš„å¤šéšæ®µè¨ˆç•«
PLAN_FILE = "ai_strategy_plan.json"
# å­¸ç¿’è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„æˆåŠŸèˆ‡å¤±æ•—çš„ç¶“é©—
MEMORY_FILE = "ai_learning_memory.json"
# å¸‚å ´è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„å‹•æ…‹å¸‚å ´é«”åˆ¶èˆ‡é•·æœŸåè¦‹
MARKET_MEMORY_FILE = "ai_market_memory.json"
# åœ˜éšŠé…ç½®æª”æ¡ˆï¼Œç”¨æ–¼å‹•æ…‹èª¿æ•´ AI åƒæ•¸
TEAM_CONFIG_FILE = "config/ai_team_config.json"
# ğŸ†• AI-Wolf é›™å‘æºé€šæ©‹æ¥æª”æ¡ˆ
BRIDGE_FILE = "ai_wolf_bridge.json"

def load_bridge():
    """è¼‰å…¥ AI-Wolf æ©‹æ¥è³‡æ–™"""
    if os.path.exists(BRIDGE_FILE):
        try:
            with open(BRIDGE_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "ai_to_wolf": {"command": "WAIT"},
        "wolf_to_ai": {"status": "IDLE"},
        "feedback_loop": {"total_trades": 0}
    }

def save_bridge(bridge):
    """å„²å­˜ AI-Wolf æ©‹æ¥è³‡æ–™"""
    bridge['last_updated'] = datetime.now().isoformat()
    with open(BRIDGE_FILE, 'w') as f:
        json.dump(bridge, f, indent=2)

def load_team_config():
    """è¼‰å…¥ AI åœ˜éšŠé…ç½®"""
    if os.path.exists(TEAM_CONFIG_FILE):
        try:
            with open(TEAM_CONFIG_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    # é»˜èªé…ç½®
    return {
        "team_dynamics": {"current_mvp": "Macro", "debate_intensity": "HIGH"},
        "agent_profiles": {
            "macro": {"name": "The Macro Seer", "bias": "Conservative"},
            "micro": {"name": "The Scalp Hunter", "bias": "Aggressive"},
            "strategist": {"name": "The Strategist", "bias": "Neutral"}
        },
        "dynamic_parameters": {"max_leverage": 50, "risk_level": "MODERATE"}
    }

def save_team_config(config):
    """å„²å­˜ AI åœ˜éšŠé…ç½®"""
    os.makedirs(os.path.dirname(TEAM_CONFIG_FILE), exist_ok=True)
    with open(TEAM_CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=2)

def find_latest_pt_session():
    """æ‰¾åˆ°æœ€æ–°çš„ paper trading æœƒè©±ç›®éŒ„"""
    pt_dir = Path("data/paper_trading")
    if not pt_dir.exists():
        return None
    
    # ç¢ºä¿åªé¸å–ç›®éŒ„ä¸”ç¬¦åˆå‘½åè¦å‰‡
    sessions = sorted([d for d in pt_dir.iterdir() if d.is_dir() and d.name.startswith("pt_")])
    return sessions[-1] if sessions else None


def load_signal_diagnostics(session_path):
    """è¼‰å…¥æœ€æ–°çš„ä¿¡è™Ÿè¨ºæ–·æ•¸æ“š (CSV)"""
    csv_file = session_path / "signal_diagnostics.csv"
    if not csv_file.exists():
        return None
    
    try:
        # è®€å–æœ€å¾Œ 50 è¡Œä»¥é€²è¡Œå¾®è§€ç‰¹å¾µåˆ†æ
        df = pd.read_csv(csv_file)
        return df.tail(50)
    except Exception as e:
        print(f"âš ï¸ è®€å– CSV å¤±æ•—: {e}")
        return None


def load_whale_flip_analysis(session_path):
    """è¼‰å…¥æœ€æ–°çš„ Whale Flip åˆ†ææ•¸æ“š (CSV)"""
    csv_file = session_path / "whale_flip_analysis.csv"
    if not csv_file.exists():
        return None
    
    try:
        # è®€å–æ›´å¤šè¡Œæ•¸ä»¥æ”¯æ´é•·æœŸåˆ†æ (ä¾‹å¦‚ 3000 è¡Œï¼Œç¢ºä¿è¦†è“‹ 4 å°æ™‚)
        df = pd.read_csv(csv_file)
        return df.tail(3000)
    except Exception as e:
        print(f"âš ï¸ è®€å– Whale Flip CSV å¤±æ•—: {e}")
        return None


def load_trading_data(session_path):
    """è¼‰å…¥äº¤æ˜“æ•¸æ“š"""
    json_file = session_path / "trading_data.json"
    if not json_file.exists():
        return None
    
    with open(json_file, 'r') as f:
        return json.load(f)


def load_market_snapshot():
    """è¼‰å…¥å¸‚å ´å¿«ç…§"""
    snapshot_path = Path("data/liquidation_pressure/latest_snapshot.json")
    if not snapshot_path.exists():
        return None
    
    with open(snapshot_path, 'r') as f:
        return json.load(f)


def load_advisor_state():
    """è¼‰å…¥ AI çš„é•·æœŸé æ¸¬ç‹€æ…‹"""
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, 'r') as f:
            return json.load(f)
    return {"last_prediction": None, "prediction_time": None, "entry_price": 0, "action": "WAIT"}


def save_advisor_state(state):
    """å„²å­˜ AI çš„é•·æœŸé æ¸¬ç‹€æ…‹"""
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2)

def load_strategy_plan():
    """è¼‰å…¥ AI çš„å¤šéšæ®µç­–ç•¥è¨ˆç•«"""
    if os.path.exists(PLAN_FILE):
        try:
            with open(PLAN_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "plan_id": str(uuid.uuid4()),
        "created_at": datetime.now().isoformat(),
        "outlook": "NEUTRAL",
        "reasoning": "Initializing...",
        "phases": []
    }

def save_strategy_plan(plan):
    """å„²å­˜ AI çš„å¤šéšæ®µç­–ç•¥è¨ˆç•«"""
    with open(PLAN_FILE, 'w') as f:
        json.dump(plan, f, indent=2)

def load_learning_memory():
    """è¼‰å…¥ AI çš„å­¸ç¿’è¨˜æ†¶"""
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "stats": {"total": 0, "correct": 0, "accuracy": 0.0},
        "mistakes": [], # è¨˜éŒ„å¤±æ•—çš„é æ¸¬ç‰¹å¾µ
        "successes": [] # è¨˜éŒ„æˆåŠŸçš„é æ¸¬ç‰¹å¾µ
    }

def save_learning_memory(memory):
    """å„²å­˜ AI çš„å­¸ç¿’è¨˜æ†¶"""
    with open(MEMORY_FILE, 'w') as f:
        json.dump(memory, f, indent=2)

def load_market_memory():
    """è¼‰å…¥å¸‚å ´è¨˜æ†¶ (Regime & Bias)"""
    if os.path.exists(MARKET_MEMORY_FILE):
        try:
            with open(MARKET_MEMORY_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "regime": {"current": "UNKNOWN", "since": datetime.now().isoformat(), "volatility_score": 0.0},
        "strategic_bias": {
            "direction": "NEUTRAL", 
            "strength": 0, 
            "since": datetime.now().isoformat(),
            "pending_change": None # ç”¨æ–¼é˜²æŠ–å‹• (Debounce)
        },
        "short_term_memory": {"last_vpin_spike": None, "last_obi_flip": None}
    }

def save_market_memory(memory):
    """å„²å­˜å¸‚å ´è¨˜æ†¶"""
    with open(MARKET_MEMORY_FILE, 'w') as f:
        json.dump(memory, f, indent=2)

def evaluate_past_prediction(current_price, previous_state, memory):
    """è©•ä¼°éå»çš„é æ¸¬æ˜¯å¦æº–ç¢ºï¼Œä¸¦æ›´æ–°è¨˜æ†¶"""
    if not previous_state.get("prediction_time") or not previous_state.get("entry_price"):
        return memory, None

    pred_time = datetime.fromisoformat(previous_state["prediction_time"])
    time_diff = (datetime.now() - pred_time).total_seconds() / 60.0 # åˆ†é˜
    
    # è‡³å°‘é 5 åˆ†é˜æ‰è©•ä¼°ï¼Œæˆ–è€…åƒ¹æ ¼æ³¢å‹•è¶…é 0.5%
    price_diff_pct = (current_price - previous_state["entry_price"]) / previous_state["entry_price"] * 100
    
    # ğŸ†• å‹•æ…‹æ­¢æ/æ­¢ç›ˆæª¢æ¸¬ï¼šå¦‚æœæ–¹å‘éŒ¯èª¤ä¸”æ³¢å‹•è¶…é 0.3% (é«˜æ§“æ¡¿ä¸‹ç´„ 15-30% æç›Š)ï¼Œç«‹å³åˆ¤å®šç‚ºå¤±æ•—
    is_emergency = False
    action = previous_state.get("action", "WAIT")
    
    if action == "LONG" and price_diff_pct < -0.3: is_emergency = True
    if action == "SHORT" and price_diff_pct > 0.3: is_emergency = True
    
    if not is_emergency and time_diff < 5 and abs(price_diff_pct) < 0.5:
        return memory, None # é‚„å¤ªæ—©ï¼Œä¸è©•ä¼°

    result = "NEUTRAL"
    
    # åˆ¤å®šå‹è² 
    if action == "LONG":
        if price_diff_pct > 0.2: result = "WIN"
        elif price_diff_pct < -0.2: result = "LOSS"
    elif action == "SHORT":
        if price_diff_pct < -0.2: result = "WIN"
        elif price_diff_pct > 0.2: result = "LOSS"
    elif action == "WAIT":
        # WAIT çš„è©•ä¼°æ¯”è¼ƒæ¨¡ç³Šï¼Œå‡è¨­å¦‚æœæ³¢å‹•å¾ˆå°å°±æ˜¯æ­£ç¢ºçš„
        if abs(price_diff_pct) < 0.3: result = "WIN"
        else: result = "LOSS" # éŒ¯éäº†è¡Œæƒ…

    if result == "NEUTRAL":
        return memory, None
        
    # ğŸ†• å¦‚æœæ˜¯ç·Šæ€¥æƒ…æ³ï¼Œå¼·åˆ¶æ¨™è¨˜ç‚ºåš´é‡å¤±æ•—
    if is_emergency:
        result = "SEVERE_LOSS"
        print(f"   ğŸš¨ [Emergency] Detected rapid loss! Price moved {price_diff_pct:.2f}% against {action}.")

    # æ›´æ–°çµ±è¨ˆ
    memory["stats"]["total"] += 1
    if result == "WIN":
        memory["stats"]["correct"] += 1
        # è¨˜éŒ„æˆåŠŸæ¨¡å¼ (åªä¿ç•™æœ€è¿‘ 20 ç­†)
        memory["successes"].append({
            "time": previous_state["prediction_time"],
            "action": action,
            "context_summary": previous_state.get("last_prediction", "")[:50]
        })
        if len(memory["successes"]) > 20: memory["successes"].pop(0)
    else:
        # è¨˜éŒ„å¤±æ•—æ¨¡å¼ (åªä¿ç•™æœ€è¿‘ 20 ç­†)
        memory["mistakes"].append({
            "time": previous_state["prediction_time"],
            "action": action,
            "severity": "HIGH" if result == "SEVERE_LOSS" else "NORMAL",
            "reason": f"Price moved {price_diff_pct:.2f}% against prediction",
            "context_summary": previous_state.get("last_prediction", "")[:50]
        })
        if len(memory["mistakes"]) > 20: memory["mistakes"].pop(0)

    memory["stats"]["accuracy"] = round(memory["stats"]["correct"] / memory["stats"]["total"] * 100, 2)
    
    # é‡ç½®é æ¸¬æ™‚é–“ï¼Œé¿å…é‡è¤‡è©•ä¼°
    previous_state["prediction_time"] = None 
    save_advisor_state(previous_state)
    save_learning_memory(memory)
    
    return memory, result

def extract_micro_features(signals_df):
    """æå–å¾®è§€ç‰¹å¾µ (æ¯«ç§’ç´šç‰¹å¾µæ¨¡æ“¬)"""
    if signals_df is None or signals_df.empty:
        return {}
    
    # ä½¿ç”¨æœ€å¾Œ 20 ç­†æ•¸æ“š (å‡è¨­æ¯ç­†é–“éš”å¾ˆçŸ­)
    recent = signals_df.tail(20)
    
    features = {
        "vpin_spike": False,
        "obi_flip": False,
        "volatility_increasing": False,
        "avg_vpin": 0.0,
        "avg_obi": 0.0
    }
    
    if 'vpin' in recent.columns:
        vpin_values = recent['vpin'].astype(float)
        features["avg_vpin"] = vpin_values.mean()
        features["vpin_max"] = vpin_values.max()
        # æª¢æ¸¬ VPIN æ˜¯å¦åœ¨çŸ­æ™‚é–“å…§æ€¥åŠ‡ä¸Šå‡ (Spike)
        if vpin_values.max() - vpin_values.min() > 0.3 and vpin_values.iloc[-1] > 0.7:
            features["vpin_spike"] = True
            
    if 'obi' in recent.columns:
        obi_values = recent['obi'].astype(float)
        features["avg_obi"] = obi_values.mean()
        # æª¢æ¸¬ OBI æ˜¯å¦ç™¼ç”Ÿæ­£è² ç¿»è½‰ (Flip)
        if (obi_values.max() > 0.2 and obi_values.min() < -0.2):
            features["obi_flip"] = True
            
    return features

def update_market_regime(signals_df, market_memory):
    """æ›´æ–°å¸‚å ´é«”åˆ¶ (Trending vs Ranging) ä¸¦å¯«å…¥è¨˜æ†¶"""
    if signals_df is None or signals_df.empty:
        return "UNKNOWN", market_memory
    
    # ä½¿ç”¨ VPIN å’Œ OBI çš„æ³¢å‹•æ€§ä¾†åˆ¤æ–·
    recent = signals_df.tail(50)
    vpin_std = recent['vpin'].std()
    obi_abs_mean = recent['obi'].abs().mean()
    
    # è¨ˆç®—ç•¶å‰åˆ†æ•¸
    volatility_score = float(vpin_std) if not pd.isna(vpin_std) else 0.0
    trend_score = float(obi_abs_mean) if not pd.isna(obi_abs_mean) else 0.0
    
    # åˆ¤æ–·ç•¶å‰ç‹€æ…‹
    current_regime = "RANGING"
    if volatility_score > 0.1 or trend_score > 0.5:
        current_regime = "VOLATILE"
    elif trend_score > 0.3:
        current_regime = "TRENDING"
        
    # æ›´æ–°è¨˜æ†¶ (ç°¡å–®çš„æ»¯å¾Œé‚è¼¯ï¼Œé¿å…é »ç¹åˆ‡æ›)
    last_regime = market_memory["regime"].get("current", "UNKNOWN")
    
    # å¦‚æœç‹€æ…‹æ”¹è®Šï¼Œè¨˜éŒ„æ™‚é–“
    if current_regime != last_regime:
        market_memory["regime"]["current"] = current_regime
        market_memory["regime"]["since"] = datetime.now().isoformat()
    
    market_memory["regime"]["volatility_score"] = volatility_score
    market_memory["regime"]["trend_score"] = trend_score
    
    return current_regime, market_memory

def summarize_mode_performance(trading_data):
    """ç¸½çµå…¶ä»–æ¨¡å¼çš„è¡¨ç¾ï¼Œä»¥åˆ¤æ–·å¸‚å ´ç‰¹æ€§"""
    if not trading_data or 'modes' not in trading_data:
        return "No trading data available."
    
    modes = trading_data['modes']
    summary = []
    
    # åˆ†é¡æ¨¡å¼
    trend_modes = ['M1', 'M7', 'M8', 'M9']
    mean_reversion_modes = ['M0', 'M2', 'M6']
    whale_modes = ['M_WHALE', 'M_LP_WHALE']
    
    trend_pnl = 0
    mean_pnl = 0
    
    for name, data in modes.items():
        pnl = data.get('pnl_usdt', 0)
        # ç°¡å–®çš„åç¨±åŒ¹é…
        is_trend = any(m in name for m in trend_modes)
        is_mean = any(m in name for m in mean_reversion_modes)
        
        if is_trend: trend_pnl += pnl
        if is_mean: mean_pnl += pnl
        
        if pnl != 0:
            summary.append(f"{name}: ${pnl:.2f}")
            
    regime_hint = "UNCLEAR"
    if trend_pnl > mean_pnl and trend_pnl > 0:
        regime_hint = "TRENDING (Trend strategies are winning)"
    elif mean_pnl > trend_pnl and mean_pnl > 0:
        regime_hint = "RANGING (Mean reversion strategies are winning)"
    elif trend_pnl < 0 and mean_pnl < 0:
        regime_hint = "CHOPPY/DIFFICULT (All strategies losing)"
        
    return f"Market Regime Hint: {regime_hint}. Details: {', '.join(summary)}"

def get_llm_client(model_type="openai"):
    """ç²å– LLM å®¢æˆ¶ç«¯ (OpenAI æˆ– Ollama)"""
    if model_type == "ollama":
        # Ollama ä¸éœ€è¦ API Keyï¼Œbase_url æŒ‡å‘æœ¬åœ°
        return OpenAI(
            base_url='http://localhost:11434/v1',
            api_key='ollama', # required, but unused
        )
    else:
        # é»˜èªä½¿ç”¨ OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ æœªæ‰¾åˆ° OPENAI_API_KEY")
            return None
        return OpenAI(api_key=api_key)

def analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    """ä½¿ç”¨ AI åˆ†æç•¶å‰äº¤æ˜“ç‹€æ³ä¸¦æä¾›å»ºè­°"""
    
    # è®€å–é…ç½®ä»¥æ±ºå®šä½¿ç”¨å“ªå€‹æ¨¡å‹
    team_config = load_team_config()
    model_choice = team_config.get("model_config", {}).get("provider", "openai") # openai or ollama
    
    client = get_llm_client(model_choice)
    if not client: return "âŒ LLM Client Init Failed"
    
    # è¼‰å…¥è¨˜æ†¶èˆ‡è¨ˆç•«
    current_plan = load_strategy_plan()
    learning_memory = load_learning_memory()
    market_memory = load_market_memory()
    
    # 1. æå–é—œéµå¸‚å ´æŒ‡æ¨™
    try:
        latest_oi = market_snapshot['open_interest'][-1]
        latest_ls = market_snapshot['global_long_short'][-1]
        
        oi_val = float(latest_oi['sumOpenInterest'])
        oi_usdt = float(latest_oi['sumOpenInterestValue'])
        price = oi_usdt / oi_val if oi_val > 0 else 0
        ls_ratio = float(latest_ls['longShortRatio'])
        
        # ğŸ†• æå–çˆ†å€‰å£“åŠ› (Liquidation Pressure)
        liq_pressure = market_snapshot.get('liquidation_pressure', {})
        long_liq = liq_pressure.get('L_long_liq', 0)
        short_liq = liq_pressure.get('L_short_liq', 0)
        
    except:
        price = 0
        oi_val = 0
        ls_ratio = 0
        long_liq = 0
        short_liq = 0
    
    # 0. è‡ªæˆ‘è©•ä¼°èˆ‡å­¸ç¿’
    learning_memory, eval_result = evaluate_past_prediction(price, previous_state, learning_memory)
    if eval_result:
        print(f"   ğŸ“ [Self-Learning] Previous prediction result: {eval_result}. Accuracy: {learning_memory['stats']['accuracy']}%")

    # 2. æå–ä¿¡è™Ÿæ‘˜è¦ & å¾®è§€ç‰¹å¾µ & æ›´æ–°å¸‚å ´é«”åˆ¶
    signal_summary = ""
    micro_features = extract_micro_features(signals_df)
    market_regime, market_memory = update_market_regime(signals_df, market_memory)
    
    if signals_df is not None and not signals_df.empty:
        latest_signals = signals_df.tail(5)[['mode', 'action', 'reason', 'signal_score', 'obi', 'vpin']].to_dict('records')
        signal_summary = json.dumps(latest_signals, ensure_ascii=False)

    # 3. æå– Whale Flip æ•¸æ“š (å¤šé‡æ™‚é–“æ¡†æ¶)
    whale_short_term = {"net_qty": 0, "dominance": 0}
    whale_long_term = {"net_qty": 0, "trend": "NEUTRAL"}
    
    if whale_flip_df is not None and not whale_flip_df.empty:
        # ç¢ºä¿ timestamp æ¬„ä½æ˜¯ datetime æ ¼å¼
        if 'timestamp' in whale_flip_df.columns:
            whale_flip_df['timestamp'] = pd.to_datetime(whale_flip_df['timestamp'])
            
        # çŸ­æœŸ (æœ€è¿‘ 15 åˆ†é˜)
        # ä½¿ç”¨æ™‚é–“éæ¿¾è€Œéå›ºå®šè¡Œæ•¸
        current_time = pd.Timestamp.now()
        short_term_start = current_time - pd.Timedelta(minutes=15)
        
        if 'timestamp' in whale_flip_df.columns:
            recent_whales = whale_flip_df[whale_flip_df['timestamp'] >= short_term_start]
        else:
            recent_whales = whale_flip_df.tail(20) # Fallback
            
        if 'net_qty' in recent_whales.columns and not recent_whales.empty:
            whale_short_term["net_qty"] = recent_whales['net_qty'].sum()
            whale_short_term["dominance"] = recent_whales['dominance'].mean()
            
        # é•·æœŸ (çœŸæ­£é–å®šéå» 4 å°æ™‚)
        long_term_start = current_time - pd.Timedelta(hours=4)
        
        if 'timestamp' in whale_flip_df.columns:
            long_term_whales = whale_flip_df[whale_flip_df['timestamp'] >= long_term_start]
        else:
            long_term_whales = whale_flip_df.tail(1000) # Fallback
            
        if 'net_qty' in long_term_whales.columns and not long_term_whales.empty:
            net_qty_sum = long_term_whales['net_qty'].sum()
            whale_long_term["net_qty"] = net_qty_sum
            
            # æ ¹æ“š 4 å°æ™‚ç´¯ç©é‡åˆ¤æ–·è¶¨å‹¢ (é–€æª»å€¼éœ€è¦éš¨æ™‚é–“çª—å£èª¿æ•´)
            # 4å°æ™‚çš„ç´¯ç©é‡é€šå¸¸è¼ƒå¤§ï¼Œæé«˜é–€æª»ä»¥éæ¿¾é›œè¨Š
            if net_qty_sum > 500: whale_long_term["trend"] = "STRONG_ACCUMULATION"
            elif net_qty_sum > 150: whale_long_term["trend"] = "MILD_ACCUMULATION"
            elif net_qty_sum < -500: whale_long_term["trend"] = "STRONG_DISTRIBUTION"
            elif net_qty_sum < -150: whale_long_term["trend"] = "MILD_DISTRIBUTION"

    # 4. æ§‹å»º AI Prompt (å‹•æ…‹ä¿¡è™Ÿ + é•·çŸ­æœŸè¨˜æ†¶ + å …å®šæ±ºç­– + é«˜æ§“æ¡¿åˆ·å–®)
    # é€™è£¡å°‡è¢«æ‹†åˆ†ç‚ºå¤šå€‹ Agent çš„ Prompt
    pass

def get_agent_opinion(client, agent_name, system_prompt, user_context, model_name="gpt-4o-mini"):
    """ç²å–å–®å€‹ Agent çš„æ„è¦‹"""
    try:
        response = client.chat.completions.create(
            model=model_name, 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_context}
            ],
            temperature=0.5, 
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Agent {agent_name} failed: {e}"

def run_council_meeting(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    """å¬é–‹ AI æˆ°ç•¥å§”å“¡æœƒæœƒè­° (4 Agents Debate)"""
    
    # è®€å–é…ç½®ä»¥æ±ºå®šä½¿ç”¨å“ªå€‹æ¨¡å‹
    team_config = load_team_config()
    model_config = team_config.get("model_config", {})
    provider = model_config.get("provider", "openai") # openai or ollama
    model_name = model_config.get("model_name", "gpt-4o-mini") # gpt-4o-mini or qwen3:32b
    
    client = get_llm_client(provider)
    if not client: return "âŒ LLM Client Init Failed"
    
    # è¼‰å…¥è¨˜æ†¶èˆ‡è¨ˆç•«
    current_plan = load_strategy_plan()
    learning_memory = load_learning_memory()
    market_memory = load_market_memory()
    team_config = load_team_config()
    
    # --- æ•¸æ“šæº–å‚™ (èˆ‡ä¹‹å‰ç›¸åŒ) ---
    # ğŸ†• å„ªå…ˆè®€å– Bridge çš„å³æ™‚æ•¸æ“š
    bridge = load_bridge()
    wolf_data = bridge.get('wolf_to_ai', {})
    rt_whale = wolf_data.get('whale_status', {})
    rt_micro = wolf_data.get('market_microstructure', {})
    
    try:
        latest_oi = market_snapshot['open_interest'][-1]
        latest_ls = market_snapshot['global_long_short'][-1]
        oi_val = float(latest_oi['sumOpenInterest'])
        oi_usdt = float(latest_oi['sumOpenInterestValue'])
        price = oi_usdt / oi_val if oi_val > 0 else 0
        ls_ratio = float(latest_ls['longShortRatio'])
        liq_pressure = market_snapshot.get('liquidation_pressure', {})
        long_liq = liq_pressure.get('L_long_liq', 0)
        short_liq = liq_pressure.get('L_short_liq', 0)
    except:
        price = 0; oi_val = 0; ls_ratio = 0; long_liq = 0; short_liq = 0
    
    # è‡ªæˆ‘è©•ä¼°
    learning_memory, eval_result = evaluate_past_prediction(price, previous_state, learning_memory)
    
    # ç‰¹å¾µæå–
    micro_features = extract_micro_features(signals_df)
    market_regime, market_memory = update_market_regime(signals_df, market_memory)
    mode_performance_summary = summarize_mode_performance(trading_data)
    
    signal_summary = ""
    if signals_df is not None and not signals_df.empty:
        latest_signals = signals_df.tail(5)[['mode', 'action', 'reason', 'signal_score', 'obi', 'vpin']].to_dict('records')
        signal_summary = json.dumps(latest_signals, ensure_ascii=False)

    whale_short_term = {"net_qty": 0, "dominance": 0}
    whale_long_term = {"net_qty": 0, "trend": "NEUTRAL"}
    if whale_flip_df is not None and not whale_flip_df.empty:
        recent_whales = whale_flip_df.tail(5)
        if 'net_qty' in recent_whales.columns:
            whale_short_term["net_qty"] = recent_whales['net_qty'].sum()
            whale_short_term["dominance"] = recent_whales['dominance'].mean()
        long_term_whales = whale_flip_df.tail(300)
        if 'net_qty' in long_term_whales.columns:
            net_qty_sum = long_term_whales['net_qty'].sum()
            whale_long_term["net_qty"] = net_qty_sum
            if net_qty_sum > 200: whale_long_term["trend"] = "STRONG_ACCUMULATION"
            elif net_qty_sum > 50: whale_long_term["trend"] = "MILD_ACCUMULATION"
            elif net_qty_sum < -200: whale_long_term["trend"] = "STRONG_DISTRIBUTION"
            elif net_qty_sum < -50: whale_long_term["trend"] = "MILD_DISTRIBUTION"

    # --- å®šç¾© Agents (ä½¿ç”¨ team_config) ---
    profiles = team_config.get("agent_profiles", {})
    params = team_config.get("dynamic_parameters", {})
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ­£åœ¨é€²è¡Œçš„ Grand Strategy
    grand_strategy = current_plan.get("grand_strategy", {"active": False})
    
    # 1. ğŸ‘´ The Macro Seer (é•·æœŸ) - æ”¹ç‚ºã€Œä¸»åŠ›é æ¸¬æ¨¡å¼ã€
    p_macro = profiles.get("macro", {})
    macro_prompt = f"""
You are '{p_macro.get('name', 'The Whale Predictor')}'. Your Role: **Grand Strategist**.
Your Focus: **Long-term Vision (1-5 Hours)**.
Your Bias: {p_macro.get('bias', 'Proactive')}.
Weight in Council: {p_macro.get('weight', 1.0)}.

Your Goal:
1. Analyze the "Big Picture" using Whale Trends (4H) and Other Modes' Performance.
2. Formulate a **Grand Strategy** for the next 1-5 hours.
3. **CRITICAL RULE**: If 'REAL-TIME WHALE STATUS' contradicts 'Whale Trend (4H)', you MUST trust the REAL-TIME status.
   - Example: If 4H says "Accumulation" but Real-Time says "NetQty -10 BTC", you must assume the trend has REVERSED to BEARISH.

Input Data:
- **REAL-TIME WHALE STATUS (LIVE & AUTHORITATIVE)**: Direction={rt_whale.get('current_direction')}, NetQty={rt_whale.get('net_qty_btc', 0)} BTC, Dominance={rt_whale.get('dominance', 0)}
- Whale Trend (4H Historical - Lagging): {whale_long_term['trend']} (Net: {whale_long_term['net_qty']:.2f} BTC)
- Other Modes Performance: {mode_performance_summary}
- Market Regime: {market_regime}

Output:
- Grand Strategy Direction: BULLISH / BEARISH / NEUTRAL
- Target Duration: 1-5 hours
- Key Thesis: Why? (e.g., "Real-time selling overrides historical accumulation")
- Invalidation Level: Price level that proves you wrong.
"""
    macro_context = f"""
Current Price: {price}
LS Ratio: {ls_ratio}
Liquidation Pressure: Long={long_liq}, Short={short_liq}
Current Grand Strategy: {json.dumps(grand_strategy)}
"""

    # 2. âš¡ The Market Reaction Tracker (çŸ­æœŸ) - æ”¹ç‚ºã€Œé©—è­‰èˆ‡ä¿®æ­£æ¨¡å¼ã€
    p_micro = profiles.get("micro", {})
    micro_prompt = f"""
You are '{p_micro.get('name', 'The Reality Checker')}'. Your Role: **Tactical Navigator**.
Your Focus: **Validate the Grand Strategy**.
Your Bias: {p_micro.get('bias', 'Adaptive')}.
Weight in Council: {p_micro.get('weight', 1.0)}.

Your Goal:
1. Check if the current price action supports or threatens the Grand Strategy.
2. **Avoid Flip-Flopping**: Only recommend aborting the plan if there is a MAJOR structural break.
3. If the plan is working (or just noise), recommend HOLD or ADD.

Input Data:
- Grand Strategy: {json.dumps(grand_strategy)}
- **REAL-TIME MICROSTRUCTURE**: OBI={rt_micro.get('obi', 0):.2f}, VPIN={rt_micro.get('vpin', 0):.2f}, Spread={rt_micro.get('spread_bps', 0)}bps
- Whale Activity (15m): Net {whale_short_term['net_qty']:.2f} BTC
- Micro Features: VPIN={micro_features.get('avg_vpin', 0):.2f}, OBI={micro_features.get('avg_obi', 0):.2f}

Output:
- Status: ON_TRACK / MINOR_DEVIATION / MAJOR_THREAT
- Recommendation: CONTINUE / PAUSE / ABORT
- Reasoning: Specific micro-structure evidence.
"""
    micro_context = f"""
Recent Signals: {signal_summary}
Current Price: {price}
"""

    # 3. âš–ï¸ The Strategist (æ··åˆ)
    p_strat = profiles.get("strategist", {})
    hybrid_prompt = f"""
You are '{p_strat.get('name', 'The Strategist')}'. {p_strat.get('role', 'Risk Manager')}.
Your Focus: **Execution Quality & Discipline**.
Your Bias: {p_strat.get('bias', 'Neutral')}.
Weight in Council: {p_strat.get('weight', 1.0)}.

Your Goal:
1. Evaluate if we are changing goals too often.
2. Ensure we stick to the plan unless invalidated.
3. Monitor progress: Profitability, Time Elapsed.

Input Data:
- Current Plan: {json.dumps(current_plan)}
- Market Bias: {market_memory['strategic_bias']['direction']}

Output:
- Discipline Check: PASS / FAIL (Are we flip-flopping?)
- Action: MAINTAIN_COURSE / REVISE_PLAN
"""
    hybrid_context = f"""
Time since plan start: {grand_strategy.get('start_time', 'N/A')}
"""

    # --- åŸ·è¡Œè¾¯è«– (å¹³è¡Œèª¿ç”¨) ---
    print(f"   ğŸ—£ï¸  Council is debating (Model: {model_name})...")
    # é€™è£¡ç‚ºäº†ç°¡å–®ç”¨é †åºèª¿ç”¨ï¼Œå¯¦éš›ç”Ÿç”¢ç’°å¢ƒå¯ç”¨ asyncio
    macro_opinion = get_agent_opinion(client, "Macro", macro_prompt, macro_context, model_name) or "No opinion"
    micro_opinion = get_agent_opinion(client, "Micro", micro_prompt, micro_context, model_name) or "No opinion"
    hybrid_opinion = get_agent_opinion(client, "Hybrid", hybrid_prompt, hybrid_context, model_name) or "No opinion"

    # --- 4. ğŸ‘‘ The Supreme Commander (è£åˆ¤) ---
    commander_prompt = f"""
You are 'The Supreme Commander'. You make the FINAL DECISION based on a Long-Term Vision.

**OBJECTIVE**: Execute a coherent strategy over 1-5 hours. Avoid frequent direction changes.
**METRICS**: Profitability, Few Corrections, Successful Execution.

**SANITY CHECK (MANDATORY)**:
- If Real-Time Whale NetQty is NEGATIVE (e.g., <-5 BTC), you CANNOT be BULLISH.
- If Real-Time Whale NetQty is POSITIVE (e.g., >+5 BTC), you CANNOT be BEARISH.
- Ignore the "Advisors" if they contradict this Real-Time Truth.

Current Grand Strategy:
{json.dumps(grand_strategy)}

Advisor Opinions:
[Macro]: {macro_opinion}
[Micro]: {micro_opinion}
[Strategist]: {hybrid_opinion}

**DECISION LOGIC**:
1. **IF Grand Strategy is ACTIVE**:
   - Check Micro's "Status".
   - If "MAJOR_THREAT" or Invalidation Level hit -> **ABORT/CUT_LOSS**.
   - If "ON_TRACK" or "MINOR_DEVIATION" -> **HOLD** or **ADD** (Pyramid).
   - Do NOT change direction just because of small noise.
   - If Time Expired -> **EXIT/RE-EVALUATE**.

2. **IF Grand Strategy is INACTIVE (or Aborted)**:
   - Create a NEW Grand Strategy based on Macro's input.
   - Set a clear Direction, Target, and Invalidation Level.

**OUTPUT FORMAT (JSON)**:
{{
  "strategic_bias": "BULLISH|BEARISH",
  "tactical_action": "LONG|SHORT|HOLD|ADD_LONG|ADD_SHORT|CUT_LOSS",
  "recommended_leverage": 1-50,
  "conviction_score": 50-100,
  "whale_reversal_price": 87500,
  "grand_strategy_update": {{
     "active": true,
     "direction": "...",
     "thesis": "...",
     "target_duration_hours": 3,
     "start_time": "{datetime.now().isoformat()}", 
     "invalidation_price": 0
  }},
  "analysis": "Reasoning...",
  "parameter_updates": {{ ... }}
}}
*Note: If maintaining existing strategy, keep 'start_time' unchanged in 'grand_strategy_update'.*
"""
    commander_context = f"""
Current Price: {price}
Market Regime: {market_regime}
Other Modes: {mode_performance_summary}
REAL-TIME WHALE: {rt_whale}
REAL-TIME MICRO: {rt_micro}
"""

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": commander_prompt},
                {"role": "user", "content": commander_context}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        result = json.loads(content)
        
        # --- è™•ç†çµæœ (èˆ‡ä¹‹å‰ç›¸åŒ) ---
        analysis_text = result.get('analysis') or "No analysis provided"
        
        new_state = {
            "last_prediction": analysis_text[:100] + "...", 
            "prediction_time": datetime.now().isoformat(),
            "entry_price": price,
            "action": result.get('tactical_action') or 'WAIT',
            "strategic_bias": result.get('strategic_bias') or 'NEUTRAL',
            "confidence": result.get('conviction_score') or 50,
            "whale_reversal_price": result.get('whale_reversal_price', 0),  # ğŸ†• æ–°å¢åè½‰åƒ¹æ ¼
            "full_analysis": f"ğŸ‘‘ COMMANDER DECISION:\n{analysis_text}\n\nğŸ—£ï¸ DEBATE HIGHLIGHTS:\nWhale Predictor: {macro_opinion[:100]}...\nReality Checker: {micro_opinion[:100]}..."
        }
        save_advisor_state(new_state)
        
        # ğŸ†• æ›´æ–° Bridge: AI â†’ Wolf æŒ‡ä»¤
        bridge = load_bridge()
        wolf_feedback = bridge.get('wolf_to_ai', {})
        
        bridge['ai_to_wolf'] = {
            "command": result.get('tactical_action') or 'WAIT',
            "direction": result.get('strategic_bias') or 'NEUTRAL',
            "confidence": result.get('conviction_score') or 50,
            "leverage": result.get('recommended_leverage') or 1,
            "whale_reversal_price": result.get('whale_reversal_price', 0),
            "take_profit_pct": 2.5,  # å¯å‹•æ…‹èª¿æ•´
            "stop_loss_pct": 1.2,
            "reasoning": analysis_text[:200],
            "timestamp": datetime.now().isoformat()
        }
        save_bridge(bridge)

        # ğŸ”„ å¼·åˆ¶åŒæ­¥ Strategy Plan (ç¢ºä¿èˆ‡ Bridge åŒæ­¥)
        # å³ä½¿ LLM æ²’æœ‰è¿”å›å®Œæ•´çš„ strategic_planï¼Œä¹Ÿè¦æ ¹æ“šç•¶å‰æ±ºç­–æ›´æ–°é—œéµæ¬„ä½
        try:
            current_plan = load_strategy_plan()
            
            # 1. æå– LLM çš„è¨ˆç•«ç´°ç¯€ (å¦‚æœæœ‰çš„è©±)
            if 'strategic_plan' in result and isinstance(result['strategic_plan'], dict):
                plan_update = result['strategic_plan']
                current_plan.update(plan_update)
            
            # ğŸ†• æ›´æ–° Grand Strategy
            if 'grand_strategy_update' in result and isinstance(result['grand_strategy_update'], dict):
                current_plan['grand_strategy'] = result['grand_strategy_update']
                
            # 2. å¼·åˆ¶è¦†è“‹é—œéµç‹€æ…‹ (ä»¥ Bridge æ±ºç­–ç‚ºæº–)
            current_plan['market_bias'] = result.get('strategic_bias', 'NEUTRAL')
            current_plan['phase'] = result.get('tactical_action', 'WAIT')
            current_plan['max_leverage'] = result.get('recommended_leverage', 1)
            current_plan['risk_level'] = team_config['dynamic_parameters'].get('risk_level', 'MODERATE')
            
            # 3. æ›´æ–°å…ƒæ•¸æ“š
            current_plan['created_at'] = datetime.now().isoformat()
            current_plan['plan_id'] = str(uuid.uuid4())
            
            save_strategy_plan(current_plan)
            print(f"   ğŸ“ [Plan Synced] Strategy Plan updated to {current_plan['market_bias']} / {current_plan['phase']}")
        except Exception as e:
            print(f"   âš ï¸ Failed to sync strategy plan: {e}")
        
        # ğŸ†• è®€å– Wolf çš„å®Œæ•´å›é¥‹ä¸¦åšæ™ºèƒ½èª¿æ•´
        feedback_loop = bridge.get('feedback_loop', {})
        failure_streak = feedback_loop.get('failure_streak', 0)
        
        # ğŸš¨ CIRCUIT BREAKER (ç†”æ–·æ©Ÿåˆ¶)
        if failure_streak >= 5:
            print(f"   ğŸš¨ [CIRCUIT BREAKER] Failure streak {failure_streak} detected! Forcing HOLD and RESET.")
            bridge['ai_to_wolf']['command'] = 'HOLD'
            bridge['ai_to_wolf']['reasoning'] = f"CIRCUIT BREAKER: Too many consecutive losses ({failure_streak}). Pausing to realign."
            save_bridge(bridge)
            
            # é‡ç½® Grand Strategy
            current_plan['grand_strategy'] = {"active": False}
            save_strategy_plan(current_plan)
            return "CIRCUIT BREAKER TRIGGERED"

        if wolf_feedback.get('status') == 'IN_POSITION':
            pnl_pct = wolf_feedback.get('current_pnl_pct', 0)
            
            # ğŸ“Š Priority 1: åˆ†æé¯¨é­šç‹€æ…‹
            whale_status = wolf_feedback.get('whale_status', {})
            whale_direction = whale_status.get('current_direction')
            whale_dominance = whale_status.get('dominance', 0)
            whale_flip_count = whale_status.get('flip_count_30min', 0)
            
            # ğŸ“ˆ Priority 1: åˆ†æå¸‚å ´å¾®çµæ§‹
            micro = wolf_feedback.get('market_microstructure', {})
            obi = micro.get('obi', 0)
            vpin = micro.get('vpin', 0)
            funding_rate = micro.get('funding_rate', 0)
            
            # ğŸŒŠ Priority 1: åˆ†ææ³¢å‹•ç’°å¢ƒ
            volatility = wolf_feedback.get('volatility', {})
            atr_pct = volatility.get('atr_pct', 0)
            is_dead_market = volatility.get('is_dead_market', False)
            regime = volatility.get('regime', 'UNKNOWN')
            
            # ğŸ¯ Priority 2: æª¢æŸ¥é æ¸¬æº–ç¢ºåº¦
            feedback_loop = bridge.get('feedback_loop', {})
            prediction_accuracy = feedback_loop.get('prediction_accuracy', {})
            direction_accuracy = prediction_accuracy.get('direction_accuracy_pct', 0)
            
            # ğŸš¨ Priority 3: é¢¨éšªè­¦ç¤º
            risk_indicators = wolf_feedback.get('risk_indicators', {})
            liquidation_pressure = risk_indicators.get('liquidation_pressure', 0)
            whale_trap_prob = risk_indicators.get('whale_trap_probability', 0)
            
            # æ™ºèƒ½æ±ºç­–é‚è¼¯
            warnings = []
            profit_adjustments = []
            
            # ğŸ¯ å‹•æ…‹èª¿æ•´æ­¢ç›ˆé…ç½®
            profit_config_file = "ai_profit_config.json"
            if os.path.exists(profit_config_file):
                try:
                    with open(profit_config_file, 'r') as f:
                        profit_config = json.load(f)
                    
                    # æ ¹æ“šå¸‚å ´ç‹€æ³å’Œç¸¾æ•ˆèª¿æ•´æ­¢ç›ˆç›®æ¨™
                    win_rate = feedback_loop.get('win_rate', 0)
                    total_trades = feedback_loop.get('total_trades', 0)
                    
                    should_update_config = False
                    
                    # æ ¹æ“šå‹ç‡å‹•æ…‹èª¿æ•´
                    if total_trades >= 5:
                        dynamic_profit = profit_config.get('dynamic_profit_taking', {})
                        base_targets = dynamic_profit.get('base_targets', {})
                        
                        if win_rate >= 70 and base_targets.get('standard', 0.8) < 2.0:
                            # å‹ç‡é«˜,æé«˜æ­¢ç›ˆç›®æ¨™
                            base_targets['standard'] = 1.5
                            base_targets['dead_market_reversal'] = 0.8
                            base_targets['reversal_ambush'] = 2.0
                            profit_adjustments.append(f"ğŸ“ˆ High win rate ({win_rate:.0f}%) â†’ Increased profit targets")
                            should_update_config = True
                        elif win_rate < 30 and base_targets.get('standard', 0.8) > 0.5:
                            # å‹ç‡ä½,é™ä½æ­¢ç›ˆç›®æ¨™
                            base_targets['standard'] = 0.5
                            base_targets['dead_market_reversal'] = 0.3
                            base_targets['reversal_ambush'] = 0.7
                            profit_adjustments.append(f"ğŸ“‰ Low win rate ({win_rate:.0f}%) â†’ Reduced profit targets")
                            should_update_config = True
                    
                    # æ ¹æ“šæ³¢å‹•ç‡èª¿æ•´
                    if atr_pct > 0.1:
                        # é«˜æ³¢å‹•,å¯ä»¥æé«˜ç›®æ¨™
                        progressive = profit_config.get('dynamic_profit_taking', {}).get('progressive_targets', {})
                        high_stage = progressive.get('stages', {}).get('high', {})
                        if high_stage.get('max_target', 6.0) < 8.0:
                            high_stage['max_target'] = 8.0
                            profit_adjustments.append(f"âš¡ High volatility (ATR: {atr_pct:.4f}%) â†’ Max target 8%")
                            should_update_config = True
                    elif atr_pct < 0.02:
                        # ä½æ³¢å‹•,é™ä½ç›®æ¨™
                        progressive = profit_config.get('dynamic_profit_taking', {}).get('progressive_targets', {})
                        high_stage = progressive.get('stages', {}).get('high', {})
                        if high_stage.get('max_target', 6.0) > 3.0:
                            high_stage['max_target'] = 3.0
                            profit_adjustments.append(f"ğŸ’¤ Low volatility (ATR: {atr_pct:.4f}%) â†’ Max target 3%")
                            should_update_config = True
                    
                    # å„²å­˜æ›´æ–°
                    if should_update_config:
                        profit_config['last_updated'] = datetime.now().isoformat()
                        history = profit_config.get('ai_adjustment_history', [])
                        history.append({
                            "timestamp": datetime.now().isoformat(),
                            "reason": f"Auto-adjustment based on WR={win_rate:.0f}%, ATR={atr_pct:.4f}%",
                            "changes": profit_adjustments
                        })
                        profit_config['ai_adjustment_history'] = history[-20:]  # ä¿ç•™æœ€è¿‘ 20 æ¬¡
                        
                        with open(profit_config_file, 'w') as f:
                            json.dump(profit_config, f, indent=2)
                except Exception as e:
                    print(f"   âš ï¸ Failed to adjust profit config: {e}")
            
            # æª¢æŸ¥ 1: PnL + é¯¨é­šåè½‰
            if pnl_pct < -0.5:
                if whale_direction and whale_direction != bridge['ai_to_wolf']['direction']:
                    warnings.append(f"âš ï¸ WHALE FLIPPED! Now {whale_direction} (Dom: {whale_dominance:.2f})")
                elif whale_flip_count >= 2:
                    warnings.append(f"âš ï¸ Whale churning ({whale_flip_count} flips) - possible trap")
                else:
                    warnings.append(f"âš ï¸ Position underwater: {pnl_pct:.2f}%")
            
            # æª¢æŸ¥ 2: æ­»æ°´ç›¤è­¦å‘Š
            if is_dead_market and atr_pct < 0.01:
                warnings.append(f"ğŸ’¤ Dead market (ATR: {atr_pct:.4f}%) - low win probability")
            
            # æª¢æŸ¥ 3: æ¥µç«¯é¢¨éšª
            if liquidation_pressure > 70:
                warnings.append(f"ğŸ”´ High liquidation risk: {liquidation_pressure}/100")
            
            if whale_trap_prob > 0.6:
                warnings.append(f"ğŸª¤ Whale trap probability: {whale_trap_prob:.0%}")
            
            # æª¢æŸ¥ 4: é æ¸¬æº–ç¢ºåº¦ä½
            if direction_accuracy < 40 and feedback_loop.get('total_trades', 0) >= 5:
                warnings.append(f"ğŸ“‰ Low prediction accuracy: {direction_accuracy:.0f}%")
            
            # æª¢æŸ¥ 5: ç²åˆ© + ç’°å¢ƒç¢ºèª
            if pnl_pct > 1.0:
                if whale_direction == bridge['ai_to_wolf']['direction']:
                    warnings.append(f"âœ… Profitable + Whale aligned ({whale_dominance:.2f} dom) - hold/add")
                else:
                    warnings.append(f"âš ï¸ Profitable but whale diverging - consider partial exit")
            
            # è¼¸å‡ºæ‰€æœ‰è­¦å‘Š
            if profit_adjustments:
                print(f"   ğŸ¯ Profit Config Auto-Adjustments:")
                for adj in profit_adjustments:
                    print(f"      {adj}")
            
            for warning in warnings:
                print(f"   {warning}")
            
            # è¼¸å‡ºé—œéµå¸‚å ´æŒ‡æ¨™
            print(f"   ğŸ“Š Market: {regime} | ATR: {atr_pct:.4f}% | OBI: {obi:.2f} | VPIN: {vpin:.2f} | Fund: {funding_rate:.4f}")
        
        # æ›´æ–°å¸‚å ´è¨˜æ†¶ (Bias) - å¸¶é˜²æŠ–å‹•
        suggested_bias = result.get('strategic_bias') or 'NEUTRAL'
        current_bias = market_memory["strategic_bias"]["direction"]
        
        if suggested_bias != current_bias:
            pending = market_memory["strategic_bias"].get("pending_change")
            if pending and pending["direction"] == suggested_bias:
                pending["count"] += 1
                if pending["count"] >= 3:
                    market_memory["strategic_bias"]["direction"] = suggested_bias
                    market_memory["strategic_bias"]["since"] = datetime.now().isoformat()
                    market_memory["strategic_bias"]["pending_change"] = None
                    print(f"   ğŸ”„ [Bias Flip] Confirmed change to {suggested_bias}")
                else:
                    print(f"   â³ [Bias Stability] Potential flip to {suggested_bias} detected ({pending['count']}/3)... Holding {current_bias}")
            else:
                market_memory["strategic_bias"]["pending_change"] = {
                    "direction": suggested_bias,
                    "count": 1,
                    "last_check": datetime.now().isoformat()
                }
                print(f"   â³ [Bias Stability] Potential flip to {suggested_bias} detected (1/3)... Holding {current_bias}")
                new_state["strategic_bias"] = current_bias # å¼·åˆ¶ä¿æŒ
        else:
             if market_memory["strategic_bias"].get("pending_change"):
                market_memory["strategic_bias"]["pending_change"] = None
        
        save_market_memory(market_memory)
            
        # è™•ç†åƒæ•¸æ›´æ–°
        if 'parameter_updates' in result and result['parameter_updates']:
            updates = result['parameter_updates']
            print(f"   âš™ï¸ [Auto-Tuning] Commander suggested updates: {updates}")
            # æ›´æ–° team_config
            for k, v in updates.items():
                if k in team_config['dynamic_parameters']:
                    team_config['dynamic_parameters'][k] = v
            team_config['recent_adjustments'].append({
                "time": datetime.now().isoformat(),
                "updates": updates,
                "reason": "Commander Decision"
            })
            save_team_config(team_config)
            
        # æ ¼å¼åŒ–è¼¸å‡ºï¼Œè®“ç”¨æˆ¶çœ‹åˆ°è¾¯è«–äº®é»
        analysis_preview = (result.get('analysis') or "No analysis")[:120]
        debate_highlights = (
            f"\n   ğŸ‘‰ [Macro]: {macro_opinion[:80]}..."
            f"\n   ğŸ‘‰ [Micro]: {micro_opinion[:80]}..."
            f"\n   ğŸ‘‰ [Strat]: {hybrid_opinion[:80]}..."
        )
        
        return f"[{result.get('strategic_bias')} | {result.get('tactical_action')} (Lev x{result.get('recommended_leverage', 1)})] {analysis_preview}...{debate_highlights}"

    except Exception as e:
        return f"âŒ Commander failed: {e}"

def analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    # ç‚ºäº†å…¼å®¹èˆŠä»£ç¢¼æ¥å£ï¼Œé€™è£¡ç›´æ¥è½‰ç™¼çµ¦ run_council_meeting
    return run_council_meeting(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state)



def main():
    print("="*60)
    print("ğŸ¤– AI Whale Hunter (Trap Master Mode)")
    print("="*60)
    
    while True:
        try:
            # 1. è¼‰å…¥æ•¸æ“š
            session_path = find_latest_pt_session()
            if not session_path:
                print("âŒ No session found.")
                time.sleep(60)
                continue
                
            trading_data = load_trading_data(session_path)
            market_snapshot = load_market_snapshot()
            signals_df = load_signal_diagnostics(session_path)
            whale_flip_df = load_whale_flip_analysis(session_path)
            prev_state = load_advisor_state()
            
            # 2. AI åˆ†æ
            print(f"\n[{datetime.now().strftime('%H:%M:%S')}] ğŸ” Analyzing Session: {session_path.name}")
            analysis = analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, prev_state)
            
            print("\n" + analysis)
            print("\n" + "-"*60)
            print("ğŸ’¤ Observing fluctuations... (Next check in 15s)")
            
            time.sleep(15)
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ AI Advisor Stopped.")
            break
        except Exception as e:
            print(f"âš ï¸ Error: {e}")
            time.sleep(60)

if __name__ == "__main__":
    main()

