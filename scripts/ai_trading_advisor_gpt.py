#!/usr/bin/env python3
"""
AI Trading Advisor - åˆ†æç•¶å‰äº¤æ˜“ç‹€æ…‹ä¸¦æä¾›ç²åˆ©å»ºè­°
è®€å–ï¼š
1. æœ€æ–°çš„ paper trading æ•¸æ“š
2. å¸‚å ´å¿«ç…§ï¼ˆçˆ†å€‰å£“åŠ›ã€OIï¼‰
3. ç•¶å‰æŒå€‰ç‹€æ…‹

è¼¸å‡ºï¼š
- å“ªäº›ç­–ç•¥è¡¨ç¾å¥½/å·®
- ç•¶å‰å¸‚å ´æ©Ÿæœƒåœ¨å“ªè£¡
- å»ºè­°èª¿æ•´å“ªäº›åƒæ•¸

ä½¿ç”¨æ–¹å¼ï¼š
  python scripts/ai_trading_advisor_gpt.py [hours]
  ä¾‹å¦‚: python scripts/ai_trading_advisor_gpt.py 8  # é‹è¡Œ 8 å°æ™‚å¾Œè‡ªå‹•åœæ­¢
"""

import uuid
import json
import os
import sys
import time
import argparse
import pandas as pd
import io
import threading
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• çµ‚ç«¯æ©Ÿè¼¸å‡ºæ—¥èªŒè¨˜éŒ„å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TeeLogger:
    """
    åŒæ™‚è¼¸å‡ºåˆ°çµ‚ç«¯æ©Ÿå’Œæ—¥èªŒæª”æ¡ˆçš„è¨˜éŒ„å™¨
    æ¯ 30 ç§’è‡ªå‹• flush åˆ°æª”æ¡ˆï¼Œé¿å…æ•ˆèƒ½å•é¡Œ
    """
    def __init__(self, log_dir="logs/ai_terminal", flush_interval=30):
        self.terminal = sys.stdout
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # å»ºç«‹æ—¥èªŒæª”æ¡ˆ (æŒ‰æ—¥æœŸå‘½å)
        self.log_file_path = self.log_dir / f"ai_advisor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        self.log_file = open(self.log_file_path, 'w', encoding='utf-8')
        
        # ç·©è¡å€
        self.buffer = []
        self.buffer_lock = threading.Lock()
        self.flush_interval = flush_interval
        self.last_flush_time = time.time()
        
        print(f"ğŸ“ çµ‚ç«¯æ©Ÿè¼¸å‡ºå°‡è¨˜éŒ„åˆ°: {self.log_file_path}")
    
    def write(self, message):
        self.terminal.write(message)
        
        # æ·»åŠ åˆ°ç·©è¡å€
        with self.buffer_lock:
            if message.strip():  # åªè¨˜éŒ„éç©ºå…§å®¹
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.buffer.append(f"[{timestamp}] {message}")
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦ flush
        if time.time() - self.last_flush_time >= self.flush_interval:
            self.flush()
    
    def flush(self):
        self.terminal.flush()
        
        # å¯«å…¥ç·©è¡å€å…§å®¹åˆ°æª”æ¡ˆ
        with self.buffer_lock:
            if self.buffer:
                try:
                    for line in self.buffer:
                        self.log_file.write(line)
                        if not line.endswith('\n'):
                            self.log_file.write('\n')
                    self.log_file.flush()
                    self.buffer.clear()
                except Exception as e:
                    self.terminal.write(f"âš ï¸ æ—¥èªŒå¯«å…¥å¤±æ•—: {e}\n")
        
        self.last_flush_time = time.time()
    
    def close(self):
        self.flush()
        self.log_file.close()
        print(f"\nğŸ“ æ—¥èªŒå·²å„²å­˜åˆ°: {self.log_file_path}")

# å…¨åŸŸæ—¥èªŒè¨˜éŒ„å™¨
_tee_logger = None

def setup_terminal_logging():
    """å•Ÿç”¨çµ‚ç«¯æ©Ÿè¼¸å‡ºæ—¥èªŒè¨˜éŒ„"""
    global _tee_logger
    if _tee_logger is None:
        _tee_logger = TeeLogger()
        sys.stdout = _tee_logger
    return _tee_logger

def close_terminal_logging():
    """é—œé–‰çµ‚ç«¯æ©Ÿè¼¸å‡ºæ—¥èªŒè¨˜éŒ„"""
    global _tee_logger
    if _tee_logger is not None:
        sys.stdout = _tee_logger.terminal
        _tee_logger.close()
        _tee_logger = None

# ç‹€æ…‹æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„ AI çš„é•·æœŸé æ¸¬
STATE_FILE = "ai_advisor_state.json"
# ç­–ç•¥è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„ AI çš„å¤šéšæ®µè¨ˆç•«
PLAN_FILE = "ai_strategy_plan.json"
# å­¸ç¿’è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„æˆåŠŸèˆ‡å¤±æ•—çš„ç¶“é©—
MEMORY_FILE = "ai_learning_memory.json"
# å¸‚å ´è¨˜æ†¶æª”æ¡ˆï¼Œç”¨æ–¼è¨˜éŒ„å‹•æ…‹å¸‚å ´é«”åˆ¶èˆ‡é•·æœŸåè¦‹
MARKET_MEMORY_FILE = "ai_market_memory.json"
# åœ˜éšŠé…ç½®æª”æ¡ˆï¼Œç”¨æ–¼å‹•æ…‹èª¿æ•´ AI åƒæ•¸
TEAM_CONFIG_FILE = "config/ai_team_config.json"
# ğŸ†• AI-Wolf é›™å‘æºé€šæ©‹æ¥æª”æ¡ˆ
BRIDGE_FILE = "ai_wolf_bridge.json"

# ğŸ¯ é«˜ç²¾æº–ç‹™æ“Šç­–ç•¥é…ç½® 
# ğŸ”§ v3.1: ã€Œå»ºè­°ç¯„åœã€è€Œéã€Œå¼·åˆ¶ç›®æ¨™ã€
# é‡è¦ï¼šäº¤æ˜“æ¬¡æ•¸æ‡‰è©²æ˜¯ã€Œçµæœã€è€Œä¸æ˜¯ã€Œç›®æ¨™ã€
# å¸‚å ´æ²’è¨Šè™Ÿå°±ä¸åšï¼Œæœ‰è¨Šè™Ÿæ‰é€²å ´ï¼Œé¿å…è¢«ä¸»åŠ›æ”¶å‰²
SNIPER_CONFIG = {
    "enabled": True,
    
    # === äº¤æ˜“é »ç‡ã€Œå»ºè­°ç¯„åœã€(ä¸æ˜¯å¼·åˆ¶ç›®æ¨™!) ===
    "suggested_trades_per_8h": "7-15",  # ğŸ”§ åƒ…ä¾›åƒè€ƒï¼Œå¯¦éš›ä¾å¸‚å ´
    "min_interval_minutes": 25,       # æœ€å°‘é–“éš” 25 åˆ†é˜ (é¿å…éåº¦äº¤æ˜“)
    "max_wait_for_signal": "unlimited", # ğŸ”§ æ²’è¨Šè™Ÿå°±ç„¡é™ç­‰å¾…
    
    # === æ§“æ¡¿è¨­å®š ===
    "base_leverage": 60,              # åŸºç¤æ§“æ¡¿ 60x
    "max_leverage": 80,               # æœ€å¤§æ§“æ¡¿ 80x
    "min_leverage": 50,               # æœ€å°æ§“æ¡¿ 50x
    
    # === é€²å ´é–€æª» (å¿…é ˆå…¨éƒ¨æ»¿è¶³æ‰é€²å ´) ===
    "entry_requirements": {
        "min_confidence": 72,         # ğŸ”§ æé«˜åˆ° 72% (åŸ 70ï¼Œæå‡å“è³ª)
        "min_confluence": 3,          # ğŸ”§ æé«˜åˆ° 3 å€‹æŒ‡æ¨™ä¸€è‡´ (åŸ 2)
        "max_vpin": 0.70,             # ğŸ”§ æ”¶ç·Šåˆ° 0.70 (åŸ 0.75)
        "min_whale_dominance": 0.55,  # ğŸ”§ æé«˜åˆ° 55% (åŸ 50%)
        "whale_alignment": True,      # å¿…é ˆèˆ‡é¯¨é­šæ–¹å‘ä¸€è‡´
        "require_funding_alignment": False,
    },
    
    # === é¢¨éšªéæ¿¾ (ä»»ä¸€è§¸ç™¼å°±ä¸é€²å ´) ===
    "risk_filters": {
        "max_spread_bps": 6,          # ğŸ”§ æ”¶ç·Šåˆ° 6bps (åŸ 8)
        "avoid_high_volatility": True,
        "avoid_liquidation_cascade": True,
        "avoid_whale_trap": True,
        "whale_trap_threshold": 0.55, # ğŸ”§ æ”¶ç·Šé™·é˜±é–¾å€¼åˆ° 55% (åŸ 60%)
        "avoid_funding_extreme": False,
    },
    
    # === æ­¢ç›ˆæ­¢æ (ROI%) - ğŸ¯ ç›®æ¨™ +5~10% ===
    "targets": {
        "take_profit_pct": 8.0,       # ğŸ”§ ç›®æ¨™æ­¢ç›ˆ 8% ROI (åŸ 10%ï¼Œæ›´å®¹æ˜“é”æˆ)
        "stop_loss_pct": 2.5,         # ğŸ”§ æ­¢æ 2.5% ROI (åŸ 3.5%ï¼Œç›ˆè™§æ¯” 3.2:1)
        "trailing_activation": 5.0,   # ğŸ”§ 5% å¾Œå•Ÿå‹•è¿½è¹¤æ­¢æ (åŸ 7%)
        "trailing_distance": 2.0,     # ğŸ”§ å¾é«˜é»å›æ’¤ 2% å°±å¹³å€‰ (åŸ 2.5%)
    },
    
    # === æ™‚é–“æ§åˆ¶ ===
    "timing": {
        "min_holding_seconds": 90,    # ğŸ”§ æœ€å°‘æŒå€‰ 90 ç§’ (åŸ 60 ç§’)
        "max_holding_minutes": 45,    # ğŸ”§ æœ€å¤šæŒå€‰ 45 åˆ†é˜ (åŸ 30ï¼Œè®“åˆ©æ½¤æœ‰æ™‚é–“ç™¼å±•)
        "cooldown_after_trade": 180,  # ğŸ”§ äº¤æ˜“å¾Œå†·å» 3 åˆ†é˜ (åŸ 2 åˆ†é˜)
    },
}

# ğŸ†• ç¿»è½‰å†·å»é…ç½® (é¿å…é »ç¹ç¿»å€‰æµªè²»æ‰‹çºŒè²»)
# ğŸ”§ v3.0: é…åˆ 8 å°æ™‚ 12 æ¬¡äº¤æ˜“ç›®æ¨™
FLIP_COOLDOWN_CONFIG = {
    "enabled": True,
    "cooldown_seconds": 120,           # ğŸ”§ å»¶é•·åˆ° 120 ç§’ (åŸ 60 ç§’ï¼Œæ¸›å°‘ç¿»å€‰)
    "min_profit_to_flip": 4.0,         # ğŸ”§ é™åˆ° 4% æ‰å…è¨±ç¿»è½‰ (åŸ 5%ï¼Œæ›´å®¹æ˜“é”æˆ)
    "max_loss_force_flip": -2.0,       # ğŸ”§ è™§æ 2% å¼·åˆ¶æ­¢æ (åŸ 3%ï¼Œæ›´å¿«æ­¢æ)
    "confidence_override": 78,         # ğŸ”§ æé«˜åˆ° 78% (åŸ 80%)
    "whale_flip_override": True,       # é¯¨é­šæ–¹å‘ç¿»è½‰æ™‚å¯ä»¥ç„¡è¦–å†·å»
}

# ğŸ†• æ±ºç­–ç©©å®šæ€§æ©Ÿåˆ¶ (é˜²æ­¢ AI åè¦†ç„¡å¸¸)
# ğŸ”§ v3.0: å„ªåŒ–ç‚º 5 ç§’åˆ¤æ–·é€±æœŸ
DECISION_STABILITY = {
    "enabled": True,
    "required_confirmations": 2,       # ğŸ”§ é€£çºŒ 2 æ¬¡åŒæ–¹å‘åˆ¤æ–·æ‰åŸ·è¡Œ (åŸ 3 æ¬¡ï¼Œé…åˆ 5 ç§’é–“éš”)
    "confirmation_window_seconds": 15, # ğŸ”§ 15 ç§’å…§çš„åˆ¤æ–·æ‰ç®—æ•¸ (åŸ 30 ç§’ï¼Œ= 3 æ¬¡åˆ¤æ–·æ©Ÿæœƒ)
    "pending_decisions": {},           # å…§å­˜ï¼šè¿½è¹¤å¾…ç¢ºèªçš„æ±ºç­–
}


def calculate_dynamic_leverage(confidence: int, whale_dominance: float, vpin: float) -> int:
    """
    ğŸ¯ æ ¹æ“šå¸‚å ´æ¢ä»¶å‹•æ…‹è¨ˆç®—æ§“æ¡¿
    
    é«˜ä¿¡å¿ƒ + é«˜é¯¨é­šä¸»å° + ä½æ¯’æ€§ = é«˜æ§“æ¡¿
    """
    base = SNIPER_CONFIG["base_leverage"]
    max_lev = SNIPER_CONFIG["max_leverage"]
    min_lev = SNIPER_CONFIG["min_leverage"]
    
    # ä¿¡å¿ƒåº¦åŠ æˆ (75-100 â†’ 0-25 åˆ†)
    confidence_bonus = max(0, (confidence - 75)) 
    
    # é¯¨é­šä¸»å°åº¦åŠ æˆ (0.6-1.0 â†’ 0-20 åˆ†)
    whale_bonus = max(0, (whale_dominance - 0.6) * 50)
    
    # VPIN æ‡²ç½° (0.5-0.7 â†’ 0-10 åˆ†æ‰£é™¤)
    vpin_penalty = max(0, (vpin - 0.5) * 50)
    
    # è¨ˆç®—æœ€çµ‚æ§“æ¡¿
    leverage = base + confidence_bonus + whale_bonus - vpin_penalty
    leverage = max(min_lev, min(max_lev, int(leverage)))
    
    return leverage


def check_sniper_entry_conditions(bridge: dict, confidence: int) -> tuple:
    """
    ğŸ¯ æª¢æŸ¥æ˜¯å¦æ»¿è¶³é«˜ç²¾æº–ç‹™æ“Šé€²å ´æ¢ä»¶
    
    Returns:
        (can_enter: bool, reason: str, recommended_leverage: int)
    """
    if not SNIPER_CONFIG.get("enabled", True):
        return (True, "sniper_disabled", SNIPER_CONFIG["base_leverage"])
    
    wolf_to_ai = bridge.get("wolf_to_ai", {})
    reqs = SNIPER_CONFIG["entry_requirements"]
    filters = SNIPER_CONFIG["risk_filters"]
    
    # æå–å¸‚å ´æ•¸æ“š
    whale_status = wolf_to_ai.get("whale_status", {})
    whale_dominance = whale_status.get("dominance", 0)
    whale_direction = whale_status.get("current_direction")
    
    micro = wolf_to_ai.get("market_microstructure", {})
    obi = micro.get("obi", 0)
    vpin = micro.get("vpin", 0)
    spread_bps = micro.get("spread_bps", 0)
    funding_rate = micro.get("funding_rate", 0)
    
    volatility = wolf_to_ai.get("volatility", {})
    atr_pct = volatility.get("atr_pct", 0)
    
    risk = wolf_to_ai.get("risk_indicators", {})
    liquidation_pressure = risk.get("liquidation_pressure", 0)
    whale_trap_prob = risk.get("whale_trap_probability", 0)
    cascade_risk = risk.get("cascade_risk", "LOW")
    
    # ğŸ†• æå–é¯¨é­šè¨Šè™Ÿå“è³ªåˆ†æ
    whale_effectiveness = wolf_to_ai.get("whale_signal_effectiveness", {})
    quality_score = whale_effectiveness.get("quality_score", 0)
    quality_grade = whale_effectiveness.get("signal_quality", {}).get("grade", "D")
    quality_factors = whale_effectiveness.get("quality_factors", [])
    warning_factors = whale_effectiveness.get("warning_factors", [])
    whale_recommendation = whale_effectiveness.get("recommendation", "WAIT")
    whale_signal_strength = whale_effectiveness.get("signal_strength", "NONE")
    
    rejections = []
    bonuses = []
    
    # === é€²å ´é–€æª»æª¢æŸ¥ ===
    if confidence < reqs["min_confidence"]:
        rejections.append(f"ä½ä¿¡å¿ƒ ({confidence}% < {reqs['min_confidence']}%)")
    
    if whale_dominance < reqs["min_whale_dominance"]:
        rejections.append(f"é¯¨é­šä¸»å°åº¦ä½ ({whale_dominance:.2f} < {reqs['min_whale_dominance']})")
    
    # ğŸ”§ v2.1 VPIN é‚è¼¯èª¿æ•´ï¼š
    # é«˜ VPIN è¡¨ç¤ºæœ‰ã€ŒçŸ¥æƒ…äº¤æ˜“è€…ã€ï¼Œå¦‚æœæˆ‘å€‘è·Ÿé¯¨é­šæ–¹å‘ä¸€è‡´ï¼Œé«˜ VPIN åè€Œæ˜¯å„ªå‹¢ï¼
    # åªæœ‰ç•¶é¯¨é­šä¸»å°åº¦ä½æˆ–æ–¹å‘ä¸æ˜æ™‚ï¼Œé«˜ VPIN æ‰æ˜¯é¢¨éšª
    # åŸç‰ˆ +47.66% æ™‚æœŸæ²’æœ‰ VPIN é˜»æ“‹ï¼
    if vpin > reqs["max_vpin"]:
        # ğŸ”§ v2.1: é™ä½é–€æª»åˆ° 70% (åŸæœ¬æ˜¯ 80%)ï¼Œè®“æ›´å¤šç¬¦åˆæ¢ä»¶çš„è¨Šè™Ÿé€šé
        if whale_dominance >= 0.70 and whale_direction in ['LONG', 'SHORT']:
            if vpin > 0.95:
                rejections.append(f"VPIN æ¥µç«¯æ¯’æ€§ ({vpin:.2f} > 0.95)")
            else:
                bonuses.append(f"é«˜ VPIN + é¯¨é­šä¸»å° (è·Ÿéš¨çŸ¥æƒ…è€…)")
        else:
            rejections.append(f"VPIN æ¯’æ€§é«˜ ({vpin:.2f} > {reqs['max_vpin']})")
    
    # ğŸ†• é¯¨é­šè¨Šè™Ÿå“è³ªæª¢æŸ¥ (æ ¸å¿ƒæ”¹é€²ï¼)
    # ä¸å†åªçœ‹æ­·å²æœ‰æ•ˆç‡ï¼Œè€Œæ˜¯çœ‹ç•¶å‰è¨Šè™Ÿçš„ç‰¹å¾µå“è³ª
    if quality_score > 0:  # æœ‰å“è³ªè©•åˆ†
        if quality_score < 30:
            rejections.append(f"é¯¨é­šè¨Šè™Ÿå“è³ªå·® (Q={quality_score}, Grade={quality_grade})")
        elif quality_score < 50 and whale_signal_strength != "STRONG":
            rejections.append(f"é¯¨é­šè¨Šè™Ÿå“è³ªä½ (Q={quality_score}, éœ€æ›´å¤šç¢ºèª)")
        elif quality_score >= 70:
            bonuses.append(f"é¯¨é­šè¨Šè™Ÿå“è³ªå„ª (Q={quality_score}, Grade={quality_grade})")
    
    # ğŸ†• æª¢æŸ¥è­¦å‘Šå› ç´ 
    critical_warnings = [w for w in warning_factors if "âš ï¸" in w or "çŸ›ç›¾" in w]
    if len(critical_warnings) >= 2:
        rejections.append(f"å¤šå€‹è­¦å‘Šä¿¡è™Ÿ: {', '.join(critical_warnings[:2])}")
    
    # ğŸ†• æª¢æŸ¥åƒ¹æ ¼åæ‡‰ï¼ˆå¦‚æœæœ‰ç•¶å‰è¨Šè™Ÿï¼‰
    current_signal = whale_effectiveness.get("current_signal", {})
    if current_signal:
        elapsed = current_signal.get("elapsed_seconds", 0)
        impact = current_signal.get("impact_in_direction", 0)
        
        # è¨Šè™Ÿç™¼å‡ºè¶…é 45 ç§’ä½†åƒ¹æ ¼å½±éŸ¿ < 0.02%ï¼Œå¾ˆå¯èƒ½æ˜¯å‡è¨Šè™Ÿ
        if elapsed > 45 and impact < 0.02:
            rejections.append(f"é¯¨é­šè¨Šè™Ÿç„¡åƒ¹æ ¼åæ‡‰ ({elapsed:.0f}s, å½±éŸ¿={impact:.3f}%)")
        elif elapsed > 15 and impact >= 0.05:
            bonuses.append(f"åƒ¹æ ¼å¿«é€Ÿåæ‡‰ ({elapsed:.0f}s, +{impact:.2f}%)")
    
    # === é¢¨éšªéæ¿¾ ===
    if filters["avoid_high_volatility"] and atr_pct > 0.5:
        rejections.append(f"æ¥µç«¯æ³¢å‹• (ATR: {atr_pct:.4f}%)")
    
    if filters["avoid_liquidation_cascade"] and cascade_risk in ["HIGH", "EXTREME"]:
        rejections.append(f"æ¸…ç®—é€£é–é¢¨éšª ({cascade_risk})")
    
    if filters["avoid_whale_trap"] and whale_trap_prob > 0.5:
        rejections.append(f"é¯¨é­šé™·é˜±é¢¨éšª ({whale_trap_prob:.0%})")
    
    if filters["max_spread_bps"] and spread_bps > filters["max_spread_bps"]:
        rejections.append(f"é»å·®éå¤§ ({spread_bps:.1f}bps)")
    
    if filters["avoid_funding_extreme"] and abs(funding_rate) > 0.001:
        rejections.append(f"Funding æ¥µç«¯ ({funding_rate:.4f})")
    
    # è¨ˆç®—å‹•æ…‹æ§“æ¡¿
    leverage = calculate_dynamic_leverage(confidence, whale_dominance, vpin)
    
    # ğŸ†• æ ¹æ“šå“è³ªåˆ†æ•¸èª¿æ•´æ§“æ¡¿
    if quality_score >= 80:
        leverage = min(leverage + 15, SNIPER_CONFIG["max_leverage"])  # A ç´š +15x
    elif quality_score >= 70:
        leverage = min(leverage + 10, SNIPER_CONFIG["max_leverage"])  # B+ ç´š +10x
    elif quality_score < 40:
        leverage = max(leverage - 10, SNIPER_CONFIG["min_leverage"])  # ä½å“è³ª -10x
    
    if rejections:
        return (False, " | ".join(rejections), leverage)
    
    # æ§‹å»ºé€šéåŸå› 
    pass_reasons = ["all_conditions_met"]
    if bonuses:
        pass_reasons.extend(bonuses)
    
    return (True, " | ".join(pass_reasons), leverage)

def load_bridge():
    """è¼‰å…¥ AI-Wolf æ©‹æ¥è³‡æ–™"""
    if os.path.exists(BRIDGE_FILE):
        try:
            with open(BRIDGE_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "ai_to_wolf": {"command": "WAIT"},
        "wolf_to_ai": {"status": "IDLE"},
        "feedback_loop": {"total_trades": 0}
    }


def check_decision_stability(command: str, confidence: int) -> tuple:
    """
    ğŸ§  æ±ºç­–ç©©å®šæ€§æª¢æŸ¥ - é˜²æ­¢ AI åè¦†ç„¡å¸¸
    
    éœ€è¦é€£çºŒ N æ¬¡åŒæ–¹å‘åˆ¤æ–·æ‰åŸ·è¡Œï¼Œé¿å… 5 ç§’ä¸€æ¬¡åˆ¤æ–·é€ æˆå¤±æ†¶åè¦†
    
    Returns:
        (is_stable, reason, confirmed_command)
    """
    if not DECISION_STABILITY.get("enabled", True):
        return True, "stability_disabled", command
    
    # åªå°æ–¹å‘æ€§æ±ºç­–åšç©©å®šæ€§æª¢æŸ¥
    if command not in ["LONG", "SHORT", "CUT_LOSS"]:
        return True, "non_directional", command
    
    required = DECISION_STABILITY.get("required_confirmations", 3)
    window = DECISION_STABILITY.get("confirmation_window_seconds", 30)
    pending = DECISION_STABILITY.get("pending_decisions", {})
    
    current_time = time.time()
    
    # æ¸…ç†éæœŸçš„å¾…ç¢ºèªæ±ºç­–
    expired_keys = [k for k, v in pending.items() 
                    if current_time - v.get("first_time", 0) > window]
    for k in expired_keys:
        del pending[k]
    
    # æª¢æŸ¥ç•¶å‰æ±ºç­–
    if command in pending:
        decision = pending[command]
        decision["count"] += 1
        decision["last_time"] = current_time
        decision["confidences"].append(confidence)
        
        if decision["count"] >= required:
            # é”åˆ°ç¢ºèªæ¬¡æ•¸ï¼Œå…è¨±åŸ·è¡Œ
            avg_confidence = sum(decision["confidences"]) / len(decision["confidences"])
            del pending[command]  # æ¸…é™¤å·²ç¢ºèªçš„æ±ºç­–
            return True, f"confirmed ({decision['count']}x in {current_time - decision['first_time']:.0f}s, avg_conf={avg_confidence:.0f})", command
        else:
            # é‚„éœ€è¦æ›´å¤šç¢ºèª
            return False, f"pending ({decision['count']}/{required})", "HOLD"
    else:
        # æ–°çš„æ±ºç­–æ–¹å‘ï¼Œé–‹å§‹è¨ˆæ•¸
        # å¦‚æœä¹‹å‰æœ‰å…¶ä»–æ–¹å‘çš„å¾…ç¢ºèªï¼Œæ¸…é™¤å®ƒ
        other_directions = [k for k in pending.keys() if k != command]
        for k in other_directions:
            del pending[k]
        
        pending[command] = {
            "first_time": current_time,
            "last_time": current_time,
            "count": 1,
            "confidences": [confidence]
        }
        return False, f"new_decision (1/{required})", "HOLD"


def check_flip_cooldown(bridge: dict, new_command: str, new_confidence: int = 50) -> tuple:
    """
    ğŸ†• æª¢æŸ¥æ˜¯å¦åœ¨ç¿»è½‰å†·å»æœŸå…§
    
    Args:
        bridge: ç•¶å‰ bridge è³‡æ–™
        new_command: æ–°çš„æŒ‡ä»¤ (LONG/SHORT/HOLD/CUT_LOSS)
        new_confidence: æ–°æŒ‡ä»¤çš„ä¿¡å¿ƒåº¦
    
    Returns:
        (should_flip: bool, reason: str, adjusted_command: str)
    """
    if not FLIP_COOLDOWN_CONFIG.get("enabled", True):
        return (True, "cooldown_disabled", new_command)
    
    # åªæª¢æŸ¥ LONG <-> SHORT çš„ç¿»è½‰
    if new_command not in ["LONG", "SHORT"]:
        return (True, "not_directional", new_command)
    
    ai_to_wolf = bridge.get("ai_to_wolf", {})
    last_command = ai_to_wolf.get("command", "WAIT")
    last_timestamp = ai_to_wolf.get("timestamp")
    
    # æª¢æŸ¥æ˜¯å¦æ˜¯æ–¹å‘ç¿»è½‰
    is_flip = (last_command == "LONG" and new_command == "SHORT") or \
              (last_command == "SHORT" and new_command == "LONG")
    
    if not is_flip:
        return (True, "same_direction", new_command)
    
    # === ç¿»è½‰å†·å»æª¢æŸ¥ ===
    cooldown_seconds = FLIP_COOLDOWN_CONFIG.get("cooldown_seconds", 120)
    
    # æª¢æŸ¥æ™‚é–“å†·å»
    if last_timestamp:
        try:
            last_time = datetime.fromisoformat(last_timestamp)
            elapsed = (datetime.now() - last_time).total_seconds()
            
            if elapsed < cooldown_seconds:
                # åœ¨å†·å»æœŸå…§ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰ override æ¢ä»¶
                
                # Override 1: é«˜ä¿¡å¿ƒåº¦
                confidence_override = FLIP_COOLDOWN_CONFIG.get("confidence_override", 90)
                if new_confidence >= confidence_override:
                    return (True, f"high_confidence_override ({new_confidence}%)", new_command)
                
                # Override 2: é¯¨é­šç¿»è½‰
                wolf_to_ai = bridge.get("wolf_to_ai", {})
                whale_status = wolf_to_ai.get("whale_status", {})
                whale_direction = whale_status.get("current_direction")
                if FLIP_COOLDOWN_CONFIG.get("whale_flip_override", True):
                    if (new_command == "LONG" and whale_direction == "LONG") or \
                       (new_command == "SHORT" and whale_direction == "SHORT"):
                        return (True, f"whale_aligned_override ({whale_direction})", new_command)
                
                # Override 3: å¤§è™§æå¼·åˆ¶æ­¢æ
                current_pnl = wolf_to_ai.get("current_pnl_pct", 0)
                max_loss_force = FLIP_COOLDOWN_CONFIG.get("max_loss_force_flip", -3.0)
                if current_pnl < max_loss_force:
                    return (True, f"loss_override ({current_pnl:.2f}%)", new_command)
                
                # Override 4: æœ‰åˆ©æ½¤ä½†é”åˆ°é–€æª»
                min_profit = FLIP_COOLDOWN_CONFIG.get("min_profit_to_flip", 0.5)
                if current_pnl >= min_profit:
                    return (True, f"profit_secured_override ({current_pnl:.2f}%)", new_command)
                
                # æ²’æœ‰ overrideï¼Œé˜»æ­¢ç¿»è½‰
                remaining = cooldown_seconds - elapsed
                return (False, f"cooldown_active ({remaining:.0f}s remaining)", "HOLD")
        except Exception as e:
            print(f"   âš ï¸ Flip cooldown check error: {e}")
    
    return (True, "no_previous_trade", new_command)

def save_bridge(bridge):
    """å„²å­˜ AI-Wolf æ©‹æ¥è³‡æ–™"""
    bridge['last_updated'] = datetime.now().isoformat()
    with open(BRIDGE_FILE, 'w') as f:
        json.dump(bridge, f, indent=2)

def load_team_config():
    """è¼‰å…¥ AI åœ˜éšŠé…ç½®"""
    if os.path.exists(TEAM_CONFIG_FILE):
        try:
            with open(TEAM_CONFIG_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    # é»˜èªé…ç½®
    return {
        "team_dynamics": {"current_mvp": "Macro", "debate_intensity": "HIGH"},
        "agent_profiles": {
            "macro": {"name": "The Macro Seer", "bias": "Conservative"},
            "micro": {"name": "The Scalp Hunter", "bias": "Aggressive"},
            "strategist": {"name": "The Strategist", "bias": "Neutral"}
        },
        "dynamic_parameters": {"max_leverage": 50, "risk_level": "MODERATE"}
    }

def save_team_config(config):
    """å„²å­˜ AI åœ˜éšŠé…ç½®"""
    os.makedirs(os.path.dirname(TEAM_CONFIG_FILE), exist_ok=True)
    with open(TEAM_CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=2)

def find_latest_pt_session():
    """æ‰¾åˆ°æœ€æ–°çš„ paper trading æœƒè©±ç›®éŒ„"""
    pt_dir = Path("data/paper_trading")
    if not pt_dir.exists():
        return None
    
    # ç¢ºä¿åªé¸å–ç›®éŒ„ä¸”ç¬¦åˆå‘½åè¦å‰‡
    sessions = sorted([d for d in pt_dir.iterdir() if d.is_dir() and d.name.startswith("pt_")])
    return sessions[-1] if sessions else None


def load_signal_diagnostics(session_path):
    """è¼‰å…¥æœ€æ–°çš„ä¿¡è™Ÿè¨ºæ–·æ•¸æ“š (CSV)"""
    csv_file = session_path / "signal_diagnostics.csv"
    if not csv_file.exists():
        return None
    
    try:
        # è®€å–æœ€å¾Œ 50 è¡Œä»¥é€²è¡Œå¾®è§€ç‰¹å¾µåˆ†æ
        df = pd.read_csv(csv_file)
        return df.tail(50)
    except Exception as e:
        print(f"âš ï¸ è®€å– CSV å¤±æ•—: {e}")
        return None


def load_whale_flip_analysis(session_path):
    """è¼‰å…¥æœ€æ–°çš„ Whale Flip åˆ†ææ•¸æ“š (CSV)"""
    csv_file = session_path / "whale_flip_analysis.csv"
    if not csv_file.exists():
        return None
    
    try:
        # è®€å–æ›´å¤šè¡Œæ•¸ä»¥æ”¯æ´é•·æœŸåˆ†æ (ä¾‹å¦‚ 3000 è¡Œï¼Œç¢ºä¿è¦†è“‹ 4 å°æ™‚)
        df = pd.read_csv(csv_file)
        return df.tail(3000)
    except Exception as e:
        print(f"âš ï¸ è®€å– Whale Flip CSV å¤±æ•—: {e}")
        return None


def load_trading_data(session_path):
    """è¼‰å…¥äº¤æ˜“æ•¸æ“š"""
    json_file = session_path / "trading_data.json"
    if not json_file.exists():
        return None
    
    with open(json_file, 'r') as f:
        return json.load(f)


def load_market_snapshot():
    """è¼‰å…¥å¸‚å ´å¿«ç…§"""
    snapshot_path = Path("data/liquidation_pressure/latest_snapshot.json")
    if not snapshot_path.exists():
        return None
    
    with open(snapshot_path, 'r') as f:
        return json.load(f)


def load_advisor_state():
    """è¼‰å…¥ AI çš„é•·æœŸé æ¸¬ç‹€æ…‹"""
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, 'r') as f:
            return json.load(f)
    return {"last_prediction": None, "prediction_time": None, "entry_price": 0, "action": "WAIT"}


def save_advisor_state(state):
    """å„²å­˜ AI çš„é•·æœŸé æ¸¬ç‹€æ…‹"""
    with open(STATE_FILE, 'w') as f:
        json.dump(state, f, indent=2)

def load_strategy_plan():
    """è¼‰å…¥ AI çš„å¤šéšæ®µç­–ç•¥è¨ˆç•«"""
    if os.path.exists(PLAN_FILE):
        try:
            with open(PLAN_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "plan_id": str(uuid.uuid4()),
        "created_at": datetime.now().isoformat(),
        "outlook": "NEUTRAL",
        "reasoning": "Initializing...",
        "phases": []
    }

def save_strategy_plan(plan):
    """å„²å­˜ AI çš„å¤šéšæ®µç­–ç•¥è¨ˆç•«"""
    with open(PLAN_FILE, 'w') as f:
        json.dump(plan, f, indent=2)

def load_learning_memory():
    """è¼‰å…¥ AI çš„å­¸ç¿’è¨˜æ†¶"""
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "stats": {"total": 0, "correct": 0, "accuracy": 0.0},
        "mistakes": [], # è¨˜éŒ„å¤±æ•—çš„é æ¸¬ç‰¹å¾µ
        "successes": [] # è¨˜éŒ„æˆåŠŸçš„é æ¸¬ç‰¹å¾µ
    }

def save_learning_memory(memory):
    """å„²å­˜ AI çš„å­¸ç¿’è¨˜æ†¶"""
    with open(MEMORY_FILE, 'w') as f:
        json.dump(memory, f, indent=2)

def load_market_memory():
    """è¼‰å…¥å¸‚å ´è¨˜æ†¶ (Regime & Bias)"""
    if os.path.exists(MARKET_MEMORY_FILE):
        try:
            with open(MARKET_MEMORY_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {
        "regime": {"current": "UNKNOWN", "since": datetime.now().isoformat(), "volatility_score": 0.0},
        "strategic_bias": {
            "direction": "NEUTRAL", 
            "strength": 0, 
            "since": datetime.now().isoformat(),
            "pending_change": None # ç”¨æ–¼é˜²æŠ–å‹• (Debounce)
        },
        "short_term_memory": {"last_vpin_spike": None, "last_obi_flip": None}
    }

def save_market_memory(memory):
    """å„²å­˜å¸‚å ´è¨˜æ†¶"""
    with open(MARKET_MEMORY_FILE, 'w') as f:
        json.dump(memory, f, indent=2)

def evaluate_past_prediction(current_price, previous_state, memory):
    """è©•ä¼°éå»çš„é æ¸¬æ˜¯å¦æº–ç¢ºï¼Œä¸¦æ›´æ–°è¨˜æ†¶"""
    if not previous_state.get("prediction_time") or not previous_state.get("entry_price"):
        return memory, None

    pred_time = datetime.fromisoformat(previous_state["prediction_time"])
    time_diff = (datetime.now() - pred_time).total_seconds() / 60.0 # åˆ†é˜
    
    # è‡³å°‘é 5 åˆ†é˜æ‰è©•ä¼°ï¼Œæˆ–è€…åƒ¹æ ¼æ³¢å‹•è¶…é 0.5%
    price_diff_pct = (current_price - previous_state["entry_price"]) / previous_state["entry_price"] * 100
    
    # ğŸ†• å‹•æ…‹æ­¢æ/æ­¢ç›ˆæª¢æ¸¬ï¼šå¦‚æœæ–¹å‘éŒ¯èª¤ä¸”æ³¢å‹•è¶…é 0.3% (é«˜æ§“æ¡¿ä¸‹ç´„ 15-30% æç›Š)ï¼Œç«‹å³åˆ¤å®šç‚ºå¤±æ•—
    is_emergency = False
    action = previous_state.get("action", "WAIT")
    
    if action == "LONG" and price_diff_pct < -0.3: is_emergency = True
    if action == "SHORT" and price_diff_pct > 0.3: is_emergency = True
    
    if not is_emergency and time_diff < 5 and abs(price_diff_pct) < 0.5:
        return memory, None # é‚„å¤ªæ—©ï¼Œä¸è©•ä¼°

    result = "NEUTRAL"
    
    # åˆ¤å®šå‹è² 
    if action == "LONG":
        if price_diff_pct > 0.2: result = "WIN"
        elif price_diff_pct < -0.2: result = "LOSS"
    elif action == "SHORT":
        if price_diff_pct < -0.2: result = "WIN"
        elif price_diff_pct > 0.2: result = "LOSS"
    elif action == "WAIT":
        # WAIT çš„è©•ä¼°æ¯”è¼ƒæ¨¡ç³Šï¼Œå‡è¨­å¦‚æœæ³¢å‹•å¾ˆå°å°±æ˜¯æ­£ç¢ºçš„
        if abs(price_diff_pct) < 0.3: result = "WIN"
        else: result = "LOSS" # éŒ¯éäº†è¡Œæƒ…

    if result == "NEUTRAL":
        return memory, None
        
    # ğŸ†• å¦‚æœæ˜¯ç·Šæ€¥æƒ…æ³ï¼Œå¼·åˆ¶æ¨™è¨˜ç‚ºåš´é‡å¤±æ•—
    if is_emergency:
        result = "SEVERE_LOSS"
        print(f"   ğŸš¨ [Emergency] Detected rapid loss! Price moved {price_diff_pct:.2f}% against {action}.")

    # æ›´æ–°çµ±è¨ˆ
    memory["stats"]["total"] += 1
    if result == "WIN":
        memory["stats"]["correct"] += 1
        # è¨˜éŒ„æˆåŠŸæ¨¡å¼ (åªä¿ç•™æœ€è¿‘ 20 ç­†)
        memory["successes"].append({
            "time": previous_state["prediction_time"],
            "action": action,
            "context_summary": previous_state.get("last_prediction", "")[:50]
        })
        if len(memory["successes"]) > 20: memory["successes"].pop(0)
    else:
        # è¨˜éŒ„å¤±æ•—æ¨¡å¼ (åªä¿ç•™æœ€è¿‘ 20 ç­†)
        memory["mistakes"].append({
            "time": previous_state["prediction_time"],
            "action": action,
            "severity": "HIGH" if result == "SEVERE_LOSS" else "NORMAL",
            "reason": f"Price moved {price_diff_pct:.2f}% against prediction",
            "context_summary": previous_state.get("last_prediction", "")[:50]
        })
        if len(memory["mistakes"]) > 20: memory["mistakes"].pop(0)

    memory["stats"]["accuracy"] = round(memory["stats"]["correct"] / memory["stats"]["total"] * 100, 2)
    
    # é‡ç½®é æ¸¬æ™‚é–“ï¼Œé¿å…é‡è¤‡è©•ä¼°
    previous_state["prediction_time"] = None 
    save_advisor_state(previous_state)
    save_learning_memory(memory)
    
    return memory, result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ ä¸»åŠ›ç­–ç•¥é æ¸¬å™¨ (Whale Strategy Predictor)
# ä¸»å‹•åˆ†æä¸»åŠ›å¯èƒ½çš„æ„åœ–ã€é™·é˜±ã€å’Œæœ€ä½³ç²åˆ©/é¿éšªç­–ç•¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_whale_strategy(
    price: float,
    ls_ratio: float,
    long_liq: float,
    short_liq: float,
    taker_ratio: float,
    oi_change_pct: float,
    funding_rate: float,
    whale_short_term: dict,
    whale_long_term: dict,
    rt_whale: dict,
    rt_micro: dict,
    cascade_active: bool,
    cascade_direction: str,
    cascade_strength: float
) -> dict:
    """
    ğŸ§  ä¸»åŠ›ç­–ç•¥é æ¸¬å™¨
    
    åˆ†æä¸»åŠ›ï¼ˆé¯¨é­šï¼‰å¯èƒ½çš„ç­–ç•¥æ„åœ–ï¼Œä¸¦æä¾›ï¼š
    1. ä¸»åŠ›ç•¶å‰ç­–ç•¥é æ¸¬
    2. æ½›åœ¨é™·é˜±è­¦å‘Š
    3. è·Ÿå–®/åå‘ç­–ç•¥å»ºè­°
    4. æœ€ä½³é€²å ´/é¿éšªæ™‚æ©Ÿ
    
    Returns:
        {
            "whale_intent": str,           # ä¸»åŠ›æ„åœ–
            "predicted_strategy": str,     # é æ¸¬çš„ä¸»åŠ›ç­–ç•¥
            "trap_warning": dict,          # é™·é˜±è­¦å‘Š
            "retail_opportunity": dict,    # æ•£æˆ¶æ©Ÿæœƒ
            "danger_zones": list,          # å±éšªå€åŸŸ
            "optimal_action": str,         # æœ€ä½³è¡Œå‹•
            "confidence": float            # ä¿¡å¿ƒåº¦ 0-100
        }
    """
    result = {
        "whale_intent": "UNKNOWN",
        "predicted_strategy": "HOLD",
        "trap_warning": {"active": False, "type": None, "description": ""},
        "retail_opportunity": {"exists": False, "type": None, "description": ""},
        "danger_zones": [],
        "optimal_action": "WAIT",
        "confidence": 0,
        "analysis_summary": ""
    }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1ï¸âƒ£ åŸºç¤æ•¸æ“šæ•´ç†
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    whale_net_qty = rt_whale.get('net_qty_btc', whale_short_term.get('net_qty', 0))
    whale_dominance = rt_whale.get('dominance', whale_short_term.get('dominance', 0))
    obi = rt_micro.get('obi', 0)
    vpin = rt_micro.get('vpin', 0)
    
    # ä¸»åŠ›æ–¹å‘åˆ¤æ–·
    whale_direction = "NEUTRAL"
    if whale_net_qty > 5:
        whale_direction = "BULLISH"
    elif whale_net_qty < -5:
        whale_direction = "BEARISH"
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2ï¸âƒ£ ä¸»åŠ›ç­–ç•¥æ¨¡å¼è­˜åˆ¥
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    strategies_detected = []
    confidence_factors = []
    
    # ğŸ“Œ æ¨¡å¼ A: å¸ç±Œ (Accumulation)
    # ç‰¹å¾µ: é¯¨é­šè²·å…¥ + åƒ¹æ ¼æ©«ç›¤/å°è·Œ + OI ä¸Šå‡ + Funding è² æˆ–ä¸­æ€§
    if (whale_net_qty > 10 and 
        oi_change_pct > 0 and 
        funding_rate <= 0.0001 and
        abs(obi) < 0.3):
        strategies_detected.append({
            "name": "ACCUMULATION",
            "description": "ä¸»åŠ›æ­£åœ¨å¸ç±Œ - æ‚„æ‚„è²·å…¥ä¸æ‹‰ç›¤",
            "whale_goal": "åœ¨æ•£æˆ¶ä¸æ³¨æ„æ™‚ä½åƒ¹å»ºç«‹å¤šé ­å€‰ä½",
            "next_move": "å¸ç±Œå®Œæˆå¾Œå¯èƒ½æ‹‰ç›¤",
            "retail_strategy": "è·Ÿéš¨åšå¤šï¼Œä½†åˆ†æ‰¹é€²å ´",
            "confidence": min(80, 50 + whale_net_qty * 2)
        })
        confidence_factors.append(("å¸ç±Œæ¨¡å¼", 25))
    
    # ğŸ“Œ æ¨¡å¼ B: æ´¾ç™¼ (Distribution)
    # ç‰¹å¾µ: é¯¨é­šè³£å‡º + åƒ¹æ ¼æ©«ç›¤/å°æ¼² + OI ä¸Šå‡ + Funding æ­£
    if (whale_net_qty < -10 and 
        oi_change_pct > 0 and 
        funding_rate >= 0.0001 and
        abs(obi) < 0.3):
        strategies_detected.append({
            "name": "DISTRIBUTION",
            "description": "ä¸»åŠ›æ­£åœ¨æ´¾ç™¼ - æ‚„æ‚„è³£å‡ºä¸ç ¸ç›¤",
            "whale_goal": "åœ¨æ•£æˆ¶è²ªå©ªæ™‚é«˜åƒ¹å‡ºè²¨",
            "next_move": "æ´¾ç™¼å®Œæˆå¾Œå¯èƒ½ç ¸ç›¤",
            "retail_strategy": "æº–å‚™åšç©ºï¼Œæˆ–æ¸›å°‘å¤šé ­å€‰ä½",
            "confidence": min(80, 50 + abs(whale_net_qty) * 2)
        })
        confidence_factors.append(("æ´¾ç™¼æ¨¡å¼", 25))
    
    # ğŸ“Œ æ¨¡å¼ C: å¤šé ­é™·é˜± (Bull Trap)
    # ç‰¹å¾µ: åƒ¹æ ¼çªç ´ + é¯¨é­šåœ¨è³£ + VPIN é«˜ + æ•£æˆ¶åœ¨è¿½
    if (whale_net_qty < -5 and 
        taker_ratio > 1.05 and  # æ•£æˆ¶åœ¨è¿½å¤š
        vpin > 0.6 and
        obi > 0.2):  # çœ‹èµ·ä¾†å¾ˆå¼·
        strategies_detected.append({
            "name": "BULL_TRAP",
            "description": "ğŸš¨ å¤šé ­é™·é˜±ï¼å‡çªç ´ - ä¸»åŠ›æ­£åœ¨å‡ºè²¨çµ¦è¿½é«˜æ•£æˆ¶",
            "whale_goal": "èª˜å°æ•£æˆ¶è¿½å¤šï¼Œç„¶å¾Œç ¸ç›¤æ”¶å‰²",
            "next_move": "å³å°‡åè½‰ä¸‹è·Œ",
            "retail_strategy": "âš ï¸ é¿å…è¿½å¤šï¼ç­‰å¾…å›è½å†è©•ä¼°",
            "confidence": min(90, 60 + vpin * 30)
        })
        result["trap_warning"] = {
            "active": True,
            "type": "BULL_TRAP",
            "description": "ä¸»åŠ›æ­£åœ¨è¨­ç½®å¤šé ­é™·é˜±ï¼Œæ•£æˆ¶è¿½å¤šä¸­"
        }
        confidence_factors.append(("å¤šé ­é™·é˜±", 35))
    
    # ğŸ“Œ æ¨¡å¼ D: ç©ºé ­é™·é˜± (Bear Trap)
    # ç‰¹å¾µ: åƒ¹æ ¼è·Œç ´ + é¯¨é­šåœ¨è²· + VPIN é«˜ + æ•£æˆ¶åœ¨è¿½ç©º
    if (whale_net_qty > 5 and 
        taker_ratio < 0.95 and  # æ•£æˆ¶åœ¨è¿½ç©º
        vpin > 0.6 and
        obi < -0.2):  # çœ‹èµ·ä¾†å¾ˆå¼±
        strategies_detected.append({
            "name": "BEAR_TRAP",
            "description": "ğŸš¨ ç©ºé ­é™·é˜±ï¼å‡è·Œç ´ - ä¸»åŠ›æ­£åœ¨å¸è²¨çµ¦è¿½ç©ºæ•£æˆ¶",
            "whale_goal": "èª˜å°æ•£æˆ¶è¿½ç©ºï¼Œç„¶å¾Œæ‹‰ç›¤è»‹ç©º",
            "next_move": "å³å°‡åè½‰ä¸Šæ¼²",
            "retail_strategy": "âš ï¸ é¿å…è¿½ç©ºï¼è€ƒæ…®é€¢ä½åšå¤š",
            "confidence": min(90, 60 + vpin * 30)
        })
        result["trap_warning"] = {
            "active": True,
            "type": "BEAR_TRAP",
            "description": "ä¸»åŠ›æ­£åœ¨è¨­ç½®ç©ºé ­é™·é˜±ï¼Œæ•£æˆ¶è¿½ç©ºä¸­"
        }
        confidence_factors.append(("ç©ºé ­é™·é˜±", 35))
    
    # ğŸ“Œ æ¨¡å¼ E: æ“ å£“ (Squeeze Play)
    # ç‰¹å¾µ: é«˜æ§“æ¡¿ç’°å¢ƒ + å–®é‚Šçˆ†å€‰å£“åŠ› + é¯¨é­šæº–å‚™è§¸ç™¼
    if long_liq > 0.3 and whale_direction == "BEARISH":
        strategies_detected.append({
            "name": "LONG_SQUEEZE_SETUP",
            "description": "ä¸»åŠ›æº–å‚™è§¸ç™¼å¤šé ­æ“ å£“",
            "whale_goal": "ç ¸ç›¤è§¸ç™¼å¤šé ­çˆ†å€‰ï¼Œè£½é€ ç€‘å¸ƒ",
            "next_move": "åƒ¹æ ¼å¯èƒ½å¿«é€Ÿä¸‹è·Œ",
            "retail_strategy": "é¿å…æŒæœ‰å¤šé ­ï¼Œå¯è€ƒæ…®è·Ÿç©º",
            "confidence": min(85, 50 + long_liq * 100)
        })
        confidence_factors.append(("å¤šé ­æ“ å£“æº–å‚™", 30))
        
    if short_liq > 0.3 and whale_direction == "BULLISH":
        strategies_detected.append({
            "name": "SHORT_SQUEEZE_SETUP",
            "description": "ä¸»åŠ›æº–å‚™è§¸ç™¼ç©ºé ­æ“ å£“",
            "whale_goal": "æ‹‰ç›¤è§¸ç™¼ç©ºé ­çˆ†å€‰ï¼Œè£½é€ è»‹ç©º",
            "next_move": "åƒ¹æ ¼å¯èƒ½å¿«é€Ÿä¸Šæ¼²",
            "retail_strategy": "é¿å…æŒæœ‰ç©ºé ­ï¼Œå¯è€ƒæ…®è·Ÿå¤š",
            "confidence": min(85, 50 + short_liq * 100)
        })
        confidence_factors.append(("ç©ºé ­æ“ å£“æº–å‚™", 30))
    
    # ğŸ“Œ æ¨¡å¼ F: æ´—ç›¤ (Shakeout)
    # ç‰¹å¾µ: é¯¨é­šæ–¹å‘ä¸è®Š + åƒ¹æ ¼åŠ‡çƒˆæ³¢å‹• + æ•£æˆ¶åœ¨æ­¢æ
    if (abs(whale_net_qty) > 15 and 
        vpin > 0.7 and 
        abs(obi) > 0.4):
        shakeout_direction = "å¤šé ­" if whale_net_qty > 0 else "ç©ºé ­"
        strategies_detected.append({
            "name": "SHAKEOUT",
            "description": f"ä¸»åŠ›æ´—ç›¤ä¸­ - è£½é€ ææ…Œä½†ä¸æ”¹è®Šæ–¹å‘",
            "whale_goal": f"éœ‡å‡º{shakeout_direction}æ•£æˆ¶çš„ç±Œç¢¼",
            "next_move": f"æ´—ç›¤çµæŸå¾Œç¹¼çºŒåŸæ–¹å‘ ({'ä¸Šæ¼²' if whale_net_qty > 0 else 'ä¸‹è·Œ'})",
            "retail_strategy": f"å …å®šæŒæœ‰{shakeout_direction}ï¼Œä¸è¢«å‡å‹•ä½œæ´—å‡º",
            "confidence": min(75, 50 + abs(whale_net_qty))
        })
        confidence_factors.append(("æ´—ç›¤æ¨¡å¼", 20))
    
    # ğŸ“Œ æ¨¡å¼ G: ç€‘å¸ƒæ¸…ç®— (Cascade Liquidation)
    if cascade_active and cascade_strength > 50:
        cascade_type = "å¤šé ­" if cascade_direction == "LONG_SQUEEZE" else "ç©ºé ­"
        strategies_detected.append({
            "name": "CASCADE_IN_PROGRESS",
            "description": f"ğŸ”¥ {cascade_type}ç€‘å¸ƒæ¸…ç®—é€²è¡Œä¸­ï¼",
            "whale_goal": "åˆ©ç”¨é€£ç’°çˆ†å€‰åŠ é€Ÿåƒ¹æ ¼ç§»å‹•",
            "next_move": "ç­‰å¾…ç€‘å¸ƒè€—ç›¡å¾Œåå½ˆ",
            "retail_strategy": f"é †å‹¢æ“ä½œï¼Œä½†æ³¨æ„åè½‰ä¿¡è™Ÿ",
            "confidence": min(95, 70 + cascade_strength * 0.3)
        })
        confidence_factors.append(("ç€‘å¸ƒæ¸…ç®—", 40))
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3ï¸âƒ£ ç¶œåˆåˆ¤æ–·èˆ‡å»ºè­°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if not strategies_detected:
        # æ²’æœ‰æ˜é¡¯ç­–ç•¥æ™‚
        if whale_dominance > 0.5:
            result["whale_intent"] = "POSITIONING"
            result["predicted_strategy"] = whale_direction
            result["optimal_action"] = "FOLLOW_WHALE" if whale_direction != "NEUTRAL" else "WAIT"
            result["confidence"] = 40
            result["analysis_summary"] = "ä¸»åŠ›æ­£åœ¨å»ºå€‰ï¼Œæ–¹å‘å°šä¸æ˜ç¢ºï¼Œå»ºè­°è§€æœ›æˆ–å°å€‰ä½è·Ÿéš¨"
        else:
            result["whale_intent"] = "INACTIVE"
            result["predicted_strategy"] = "RANGING"
            result["optimal_action"] = "WAIT"
            result["confidence"] = 30
            result["analysis_summary"] = "ä¸»åŠ›æ´»å‹•åº¦ä½ï¼Œå¸‚å ´éœ‡ç›ªï¼Œå»ºè­°è§€æœ›"
    else:
        # æœ‰ç­–ç•¥æ™‚ï¼Œé¸æ“‡ä¿¡å¿ƒåº¦æœ€é«˜çš„
        best_strategy = max(strategies_detected, key=lambda x: x['confidence'])
        
        result["whale_intent"] = best_strategy['name']
        result["predicted_strategy"] = best_strategy['name']
        result["confidence"] = best_strategy['confidence']
        result["analysis_summary"] = f"{best_strategy['description']}\nğŸ‘‰ ä¸»åŠ›ç›®æ¨™: {best_strategy['whale_goal']}\nğŸ‘‰ ä¸‹ä¸€æ­¥: {best_strategy['next_move']}\nğŸ’¡ å»ºè­°: {best_strategy['retail_strategy']}"
        
        # æ ¹æ“šç­–ç•¥æ±ºå®šæœ€ä½³è¡Œå‹•
        if best_strategy['name'] in ['BULL_TRAP', 'DISTRIBUTION', 'LONG_SQUEEZE_SETUP']:
            result["optimal_action"] = "AVOID_LONG"
            result["danger_zones"].append("è¿½å¤šå±éšª")
        elif best_strategy['name'] in ['BEAR_TRAP', 'ACCUMULATION', 'SHORT_SQUEEZE_SETUP']:
            result["optimal_action"] = "AVOID_SHORT"
            result["danger_zones"].append("è¿½ç©ºå±éšª")
        elif best_strategy['name'] == 'SHAKEOUT':
            result["optimal_action"] = "HOLD_POSITION"
        elif best_strategy['name'] == 'CASCADE_IN_PROGRESS':
            if cascade_direction == "LONG_SQUEEZE":
                result["optimal_action"] = "SHORT_WITH_CAUTION"
            else:
                result["optimal_action"] = "LONG_WITH_CAUTION"
        
        # æ•£æˆ¶æ©Ÿæœƒè­˜åˆ¥
        if best_strategy['name'] in ['BEAR_TRAP', 'ACCUMULATION']:
            result["retail_opportunity"] = {
                "exists": True,
                "type": "LONG_OPPORTUNITY",
                "description": "ä¸»åŠ›åœ¨å¸ç±Œï¼Œå¯è€ƒæ…®è·Ÿéš¨åšå¤š"
            }
        elif best_strategy['name'] in ['BULL_TRAP', 'DISTRIBUTION']:
            result["retail_opportunity"] = {
                "exists": True,
                "type": "SHORT_OPPORTUNITY", 
                "description": "ä¸»åŠ›åœ¨å‡ºè²¨ï¼Œå¯è€ƒæ…®åšç©ºæˆ–è§€æœ›"
            }
    
    # è¨ˆç®—ç¸½ä¿¡å¿ƒåº¦
    total_confidence = sum(cf[1] for cf in confidence_factors)
    result["confidence"] = min(95, max(result["confidence"], total_confidence))
    result["detected_patterns"] = [s['name'] for s in strategies_detected]
    
    return result


def format_whale_strategy_for_prompt(analysis: dict) -> str:
    """å°‡ä¸»åŠ›ç­–ç•¥åˆ†ææ ¼å¼åŒ–ç‚º Prompt æ–‡å­—"""
    if not analysis or analysis.get('whale_intent') == 'UNKNOWN':
        return "**ä¸»åŠ›ç­–ç•¥åˆ†æ**: æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·"
    
    trap_warning = ""
    if analysis['trap_warning']['active']:
        trap_warning = f"""
ğŸš¨ **é™·é˜±è­¦å‘Š**: {analysis['trap_warning']['type']}
   {analysis['trap_warning']['description']}
"""
    
    opportunity = ""
    if analysis['retail_opportunity']['exists']:
        opportunity = f"""
ğŸ’° **æ•£æˆ¶æ©Ÿæœƒ**: {analysis['retail_opportunity']['type']}
   {analysis['retail_opportunity']['description']}
"""
    
    danger = ""
    if analysis['danger_zones']:
        danger = f"""
âš ï¸ **å±éšªå€åŸŸ**: {', '.join(analysis['danger_zones'])}
"""
    
    return f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ **ä¸»åŠ›ç­–ç•¥é æ¸¬** (ä¿¡å¿ƒåº¦: {analysis['confidence']}%)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ‹ **ä¸»åŠ›æ„åœ–**: {analysis['whale_intent']}
ğŸ“Š **é æ¸¬ç­–ç•¥**: {analysis['predicted_strategy']}
ğŸ¬ **æœ€ä½³è¡Œå‹•**: {analysis['optimal_action']}
{trap_warning}{opportunity}{danger}
ğŸ“ **åˆ†ææ‘˜è¦**:
{analysis['analysis_summary']}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


def extract_micro_features(signals_df):
    """æå–å¾®è§€ç‰¹å¾µ (æ¯«ç§’ç´šç‰¹å¾µæ¨¡æ“¬)"""
    if signals_df is None or signals_df.empty:
        return {}
    
    # ä½¿ç”¨æœ€å¾Œ 20 ç­†æ•¸æ“š (å‡è¨­æ¯ç­†é–“éš”å¾ˆçŸ­)
    recent = signals_df.tail(20)
    
    features = {
        "vpin_spike": False,
        "obi_flip": False,
        "volatility_increasing": False,
        "avg_vpin": 0.0,
        "avg_obi": 0.0
    }
    
    if 'vpin' in recent.columns:
        vpin_values = recent['vpin'].astype(float)
        features["avg_vpin"] = vpin_values.mean()
        features["vpin_max"] = vpin_values.max()
        # æª¢æ¸¬ VPIN æ˜¯å¦åœ¨çŸ­æ™‚é–“å…§æ€¥åŠ‡ä¸Šå‡ (Spike)
        if vpin_values.max() - vpin_values.min() > 0.3 and vpin_values.iloc[-1] > 0.7:
            features["vpin_spike"] = True
            
    if 'obi' in recent.columns:
        obi_values = recent['obi'].astype(float)
        features["avg_obi"] = obi_values.mean()
        # æª¢æ¸¬ OBI æ˜¯å¦ç™¼ç”Ÿæ­£è² ç¿»è½‰ (Flip)
        if (obi_values.max() > 0.2 and obi_values.min() < -0.2):
            features["obi_flip"] = True
            
    return features

def update_market_regime(signals_df, market_memory):
    """æ›´æ–°å¸‚å ´é«”åˆ¶ (Trending vs Ranging) ä¸¦å¯«å…¥è¨˜æ†¶"""
    if signals_df is None or signals_df.empty:
        return "UNKNOWN", market_memory
    
    # ä½¿ç”¨ VPIN å’Œ OBI çš„æ³¢å‹•æ€§ä¾†åˆ¤æ–·
    recent = signals_df.tail(50)
    vpin_std = recent['vpin'].std()
    obi_abs_mean = recent['obi'].abs().mean()
    
    # è¨ˆç®—ç•¶å‰åˆ†æ•¸
    volatility_score = float(vpin_std) if not pd.isna(vpin_std) else 0.0
    trend_score = float(obi_abs_mean) if not pd.isna(obi_abs_mean) else 0.0
    
    # åˆ¤æ–·ç•¶å‰ç‹€æ…‹
    current_regime = "RANGING"
    if volatility_score > 0.1 or trend_score > 0.5:
        current_regime = "VOLATILE"
    elif trend_score > 0.3:
        current_regime = "TRENDING"
        
    # æ›´æ–°è¨˜æ†¶ (ç°¡å–®çš„æ»¯å¾Œé‚è¼¯ï¼Œé¿å…é »ç¹åˆ‡æ›)
    last_regime = market_memory["regime"].get("current", "UNKNOWN")
    
    # å¦‚æœç‹€æ…‹æ”¹è®Šï¼Œè¨˜éŒ„æ™‚é–“
    if current_regime != last_regime:
        market_memory["regime"]["current"] = current_regime
        market_memory["regime"]["since"] = datetime.now().isoformat()
    
    market_memory["regime"]["volatility_score"] = volatility_score
    market_memory["regime"]["trend_score"] = trend_score
    
    return current_regime, market_memory

def summarize_mode_performance(trading_data):
    """ç¸½çµå…¶ä»–æ¨¡å¼çš„è¡¨ç¾ï¼Œä»¥åˆ¤æ–·å¸‚å ´ç‰¹æ€§"""
    if not trading_data or 'modes' not in trading_data:
        return "No trading data available."
    
    modes = trading_data['modes']
    summary = []
    
    # åˆ†é¡æ¨¡å¼
    trend_modes = ['M1', 'M7', 'M8', 'M9']
    mean_reversion_modes = ['M0', 'M2', 'M6']
    whale_modes = ['M_WHALE', 'M_LP_WHALE']
    
    trend_pnl = 0
    mean_pnl = 0
    
    for name, data in modes.items():
        pnl = data.get('pnl_usdt', 0)
        # ç°¡å–®çš„åç¨±åŒ¹é…
        is_trend = any(m in name for m in trend_modes)
        is_mean = any(m in name for m in mean_reversion_modes)
        
        if is_trend: trend_pnl += pnl
        if is_mean: mean_pnl += pnl
        
        if pnl != 0:
            summary.append(f"{name}: ${pnl:.2f}")
            
    regime_hint = "UNCLEAR"
    if trend_pnl > mean_pnl and trend_pnl > 0:
        regime_hint = "TRENDING (Trend strategies are winning)"
    elif mean_pnl > trend_pnl and mean_pnl > 0:
        regime_hint = "RANGING (Mean reversion strategies are winning)"
    elif trend_pnl < 0 and mean_pnl < 0:
        regime_hint = "CHOPPY/DIFFICULT (All strategies losing)"
        
    return f"Market Regime Hint: {regime_hint}. Details: {', '.join(summary)}"

def get_llm_client(model_type="openai"):
    """
    ç²å– LLM å®¢æˆ¶ç«¯ (OpenAI / Ollama / Kimi K2)
    
    æ”¯æ´çš„ model_type:
    - "openai": ä½¿ç”¨ OpenAI GPT (éœ€è¦ OPENAI_API_KEY)
    - "ollama": ä½¿ç”¨æœ¬åœ° Ollama (qwen3:32b ç­‰)
    - "kimi": ä½¿ç”¨ Kimi K2 API (éœ€è¦ KIMI_API_KEY)
    """
    if model_type == "ollama":
        # Ollama ä¸éœ€è¦ API Keyï¼Œbase_url æŒ‡å‘æœ¬åœ°
        return OpenAI(
            base_url='http://localhost:11434/v1',
            api_key='ollama', # required, but unused
        )
    elif model_type == "kimi":
        # Kimi K2 API
        api_key = os.getenv("KIMI_API_KEY")
        if not api_key:
            print("âŒ æœªæ‰¾åˆ° KIMI_API_KEYï¼Œè«‹åœ¨ .env ä¸­è¨­å®š")
            return None
        return OpenAI(
            base_url='https://api.moonshot.cn/v1',
            api_key=api_key,
        )
    else:
        # é»˜èªä½¿ç”¨ OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ æœªæ‰¾åˆ° OPENAI_API_KEY")
            return None
        return OpenAI(api_key=api_key)

def analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    """ä½¿ç”¨ AI åˆ†æç•¶å‰äº¤æ˜“ç‹€æ³ä¸¦æä¾›å»ºè­°"""
    
    # è®€å–é…ç½®ä»¥æ±ºå®šä½¿ç”¨å“ªå€‹æ¨¡å‹
    team_config = load_team_config()
    model_choice = team_config.get("model_config", {}).get("provider", "openai") # openai or ollama
    
    client = get_llm_client(model_choice)
    if not client: return "âŒ LLM Client Init Failed"
    
    # è¼‰å…¥è¨˜æ†¶èˆ‡è¨ˆç•«
    current_plan = load_strategy_plan()
    learning_memory = load_learning_memory()
    market_memory = load_market_memory()
    
    # 1. æå–é—œéµå¸‚å ´æŒ‡æ¨™
    try:
        latest_oi = market_snapshot['open_interest'][-1]
        latest_ls = market_snapshot['global_long_short'][-1]
        
        oi_val = float(latest_oi['sumOpenInterest'])
        oi_usdt = float(latest_oi['sumOpenInterestValue'])
        price = oi_usdt / oi_val if oi_val > 0 else 0
        ls_ratio = float(latest_ls['longShortRatio'])
        
        # ğŸ†• æå–çˆ†å€‰å£“åŠ› (Liquidation Pressure)
        liq_pressure = market_snapshot.get('liquidation_pressure', {})
        long_liq = liq_pressure.get('L_long_liq', 0)
        short_liq = liq_pressure.get('L_short_liq', 0)
        
    except:
        price = 0
        oi_val = 0
        ls_ratio = 0
        long_liq = 0
        short_liq = 0
    
    # 0. è‡ªæˆ‘è©•ä¼°èˆ‡å­¸ç¿’
    learning_memory, eval_result = evaluate_past_prediction(price, previous_state, learning_memory)
    if eval_result:
        print(f"   ğŸ“ [Self-Learning] Previous prediction result: {eval_result}. Accuracy: {learning_memory['stats']['accuracy']}%")

    # 2. æå–ä¿¡è™Ÿæ‘˜è¦ & å¾®è§€ç‰¹å¾µ & æ›´æ–°å¸‚å ´é«”åˆ¶
    signal_summary = ""
    micro_features = extract_micro_features(signals_df)
    market_regime, market_memory = update_market_regime(signals_df, market_memory)
    
    if signals_df is not None and not signals_df.empty:
        latest_signals = signals_df.tail(5)[['mode', 'action', 'reason', 'signal_score', 'obi', 'vpin']].to_dict('records')
        signal_summary = json.dumps(latest_signals, ensure_ascii=False)

    # 3. æå– Whale Flip æ•¸æ“š (å¤šé‡æ™‚é–“æ¡†æ¶)
    whale_short_term = {"net_qty": 0, "dominance": 0}
    whale_long_term = {"net_qty": 0, "trend": "NEUTRAL"}
    
    if whale_flip_df is not None and not whale_flip_df.empty:
        # ç¢ºä¿ timestamp æ¬„ä½æ˜¯ datetime æ ¼å¼
        if 'timestamp' in whale_flip_df.columns:
            whale_flip_df['timestamp'] = pd.to_datetime(whale_flip_df['timestamp'])
            
        # çŸ­æœŸ (æœ€è¿‘ 15 åˆ†é˜)
        # ä½¿ç”¨æ™‚é–“éæ¿¾è€Œéå›ºå®šè¡Œæ•¸
        current_time = pd.Timestamp.now()
        short_term_start = current_time - pd.Timedelta(minutes=15)
        
        if 'timestamp' in whale_flip_df.columns:
            recent_whales = whale_flip_df[whale_flip_df['timestamp'] >= short_term_start]
        else:
            recent_whales = whale_flip_df.tail(20) # Fallback
            
        if 'net_qty' in recent_whales.columns and not recent_whales.empty:
            whale_short_term["net_qty"] = recent_whales['net_qty'].sum()
            whale_short_term["dominance"] = recent_whales['dominance'].mean()
            
        # é•·æœŸ (çœŸæ­£é–å®šéå» 4 å°æ™‚)
        long_term_start = current_time - pd.Timedelta(hours=4)
        
        if 'timestamp' in whale_flip_df.columns:
            long_term_whales = whale_flip_df[whale_flip_df['timestamp'] >= long_term_start]
        else:
            long_term_whales = whale_flip_df.tail(1000) # Fallback
            
        if 'net_qty' in long_term_whales.columns and not long_term_whales.empty:
            net_qty_sum = long_term_whales['net_qty'].sum()
            whale_long_term["net_qty"] = net_qty_sum
            
            # æ ¹æ“š 4 å°æ™‚ç´¯ç©é‡åˆ¤æ–·è¶¨å‹¢ (é–€æª»å€¼éœ€è¦éš¨æ™‚é–“çª—å£èª¿æ•´)
            # 4å°æ™‚çš„ç´¯ç©é‡é€šå¸¸è¼ƒå¤§ï¼Œæé«˜é–€æª»ä»¥éæ¿¾é›œè¨Š
            if net_qty_sum > 500: whale_long_term["trend"] = "STRONG_ACCUMULATION"
            elif net_qty_sum > 150: whale_long_term["trend"] = "MILD_ACCUMULATION"
            elif net_qty_sum < -500: whale_long_term["trend"] = "STRONG_DISTRIBUTION"
            elif net_qty_sum < -150: whale_long_term["trend"] = "MILD_DISTRIBUTION"

    # 4. æ§‹å»º AI Prompt (å‹•æ…‹ä¿¡è™Ÿ + é•·çŸ­æœŸè¨˜æ†¶ + å …å®šæ±ºç­– + é«˜æ§“æ¡¿åˆ·å–®)
    # é€™è£¡å°‡è¢«æ‹†åˆ†ç‚ºå¤šå€‹ Agent çš„ Prompt
    pass

def get_agent_opinion(client, agent_name, system_prompt, user_context, model_name="gpt-4o-mini"):
    """ç²å–å–®å€‹ Agent çš„æ„è¦‹"""
    try:
        # ğŸ”§ GPT-5 ç³»åˆ—ä¸æ”¯æŒè‡ªè¨‚ temperature å’Œ max_tokensï¼Œç§»é™¤é€™äº›åƒæ•¸
        response = client.chat.completions.create(
            model=model_name, 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_context}
            ]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Agent {agent_name} failed: {e}"

def run_council_meeting(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    """å¬é–‹ AI æˆ°ç•¥å§”å“¡æœƒæœƒè­° (4 Agents Debate)"""
    
    # è®€å–é…ç½®ä»¥æ±ºå®šä½¿ç”¨å“ªå€‹æ¨¡å‹
    team_config = load_team_config()
    model_config = team_config.get("model_config", {})
    provider = model_config.get("provider", "openai") # openai or ollama
    model_name = model_config.get("model_name", "gpt-4o-mini") # gpt-4o-mini or qwen3:32b
    
    client = get_llm_client(provider)
    if not client: return "âŒ LLM Client Init Failed"
    
    # è¼‰å…¥è¨˜æ†¶èˆ‡è¨ˆç•«
    current_plan = load_strategy_plan()
    learning_memory = load_learning_memory()
    market_memory = load_market_memory()
    team_config = load_team_config()
    
    # --- æ•¸æ“šæº–å‚™ ---
    # ğŸ†• v1.3.0: å„ªå…ˆè®€å– Testnet çœŸå¯¦æ•¸æ“š (MğŸº = TğŸº çµ±ä¸€æ¨¡å¼)
    bridge = load_bridge()
    wolf_data = bridge.get('wolf_to_ai', {})
    rt_whale = wolf_data.get('whale_status', {})
    rt_micro = wolf_data.get('market_microstructure', {})
    
    # ğŸ†• è®€å– Testnet çœŸå¯¦æŒå€‰ç‹€æ…‹ (å„ªå…ˆæ–¼ Paper)
    testnet_data = wolf_data.get('testnet_trading', {})
    websocket_data = wolf_data.get('websocket_realtime', {})
    
    # çµ±ä¸€æ•¸æ“šä¾†æº: WebSocket > Testnet > Paper
    if websocket_data.get('has_position'):
        # WebSocket æœ‰å³æ™‚æ•¸æ“šï¼Œæœ€æº–ç¢º
        position_source = 'WEBSOCKET'
        has_position = True
        position_info = websocket_data.get('position', {})
        current_pnl_usdt = position_info.get('pnl_usdt', 0)
        current_pnl_pct = position_info.get('pnl_pct', 0)
        position_direction = position_info.get('direction', '')
        entry_price = position_info.get('entry_price', 0)
        leverage = position_info.get('leverage', 75)
        ws_alert = websocket_data.get('alert', {})
        print(f"   ğŸ“¡ [AIæ•¸æ“šæº] WebSocket å³æ™‚: {position_direction} PnL={current_pnl_usdt:.2f} ({current_pnl_pct:.1f}%)")
    elif testnet_data.get('has_position'):
        # Testnet æœ‰æŒå€‰
        position_source = 'TESTNET'
        has_position = True
        position_info = testnet_data.get('position', {})
        current_pnl_usdt = testnet_data.get('unrealized_pnl', 0)
        current_pnl_pct = testnet_data.get('pnl_pct', 0)
        position_direction = testnet_data.get('direction', '')
        entry_price = testnet_data.get('entry_price', 0)
        leverage = testnet_data.get('leverage', 75)
        ws_alert = {}
        print(f"   ğŸ“¡ [AIæ•¸æ“šæº] Testnet: {position_direction} PnL={current_pnl_usdt:.2f}")
    else:
        # ç„¡æŒå€‰
        position_source = 'NONE'
        has_position = False
        current_pnl_usdt = 0
        current_pnl_pct = 0
        position_direction = ''
        entry_price = 0
        leverage = 75
        ws_alert = {}
        print(f"   ğŸ“¡ [AIæ•¸æ“šæº] ç„¡æŒå€‰")
    
    # ğŸ†• è®€å– Testnet å¸³æˆ¶ç‹€æ…‹
    testnet_account = testnet_data.get('account', {})
    testnet_balance = testnet_account.get('balance', 100)
    testnet_total_trades = testnet_account.get('total_trades', 0)
    testnet_total_pnl = testnet_account.get('total_pnl', 0)
    
    # ğŸ†• è®€å– Cascade Alert (çˆ†å€‰æ½®è¨Šè™Ÿ)
    cascade_alert = wolf_data.get('cascade_alert', {})
    cascade_alert = wolf_data.get('cascade_alert', {})
    cascade_active = cascade_alert.get('active', False)
    cascade_direction = cascade_alert.get('direction', 'NONE')  # LONG_SQUEEZE / SHORT_SQUEEZE / MIXED
    cascade_strength = cascade_alert.get('strength', 0)
    cascade_warning = cascade_alert.get('warning', '')
    cascade_suggestion = cascade_alert.get('suggested_action', '')
    
    # ğŸ†• è®€å–é¯¨é­šè¨Šè™Ÿå“è³ªè¿½è¹¤ (é‡æ–°è¨­è¨ˆï¼šä¸åªçœ‹æ­·å²ï¼Œçœ‹ç‰¹å¾µï¼)
    whale_effectiveness = wolf_data.get('whale_signal_effectiveness', {})
    whale_signal_recommendation = whale_effectiveness.get('recommendation', 'WAIT')
    whale_effectiveness_rate = whale_effectiveness.get('effectiveness_rate', 0)
    whale_signal_strength = whale_effectiveness.get('signal_strength', 'NONE')
    whale_is_effective = whale_effectiveness.get('is_signal_effective', False)
    
    # ğŸ†• å“è³ªåˆ†æ•¸ (æ ¸å¿ƒæŒ‡æ¨™ï¼)
    whale_quality_score = whale_effectiveness.get('quality_score', 0)
    whale_quality_info = whale_effectiveness.get('signal_quality', {})
    whale_quality_grade = whale_quality_info.get('grade', 'N/A')
    whale_quality_factors = whale_effectiveness.get('quality_factors', [])
    whale_warning_factors = whale_effectiveness.get('warning_factors', [])
    
    # å°å‡ºé¯¨é­šè¨Šè™Ÿå“è³ªåˆ†æ
    if whale_signal_strength != 'NONE' or whale_quality_score > 0:
        # å“è³ªç­‰ç´šé¡è‰²
        grade_emoji = {
            'A': 'ğŸŸ¢', 'A-': 'ğŸŸ¢', 'B+': 'ğŸŸ¡', 'B': 'ğŸŸ¡', 
            'B-': 'ğŸŸ ', 'C+': 'ğŸŸ ', 'C': 'ğŸ”´', 'D': 'ğŸ”´', 'N/A': 'âšª'
        }
        g_emoji = grade_emoji.get(whale_quality_grade, 'âšª')
        eff_emoji = "âœ…" if whale_is_effective else "â³"
        
        print(f"   ğŸ³ [é¯¨é­šè¨Šè™Ÿå“è³ª]")
        print(f"      â”œâ”€ å“è³ªåˆ†æ•¸: {whale_quality_score:.0f}/100 ({g_emoji} {whale_quality_grade})")
        print(f"      â”œâ”€ å¼·åº¦={whale_signal_strength} | æ­·å²æœ‰æ•ˆç‡={whale_effectiveness_rate:.0f}% {eff_emoji}")
        print(f"      â””â”€ å»ºè­°: {whale_signal_recommendation}")
        
        # é¡¯ç¤ºæ­£é¢å› ç´  (æœ€å¤š 3 å€‹)
        if whale_quality_factors:
            print(f"      ğŸ“Š æ­£é¢å› ç´ :")
            for factor in whale_quality_factors[:3]:
                print(f"         âœ“ {factor}")
        
        # é¡¯ç¤ºè­¦å‘Šå› ç´  (é‡è¦ï¼)
        if whale_warning_factors:
            print(f"      âš ï¸ è­¦å‘Š:")
            for warning in whale_warning_factors[:3]:
                print(f"         âœ— {warning}")
    
    try:
        latest_oi = market_snapshot['open_interest'][-1]
        latest_ls = market_snapshot['global_long_short'][-1]
        oi_val = float(latest_oi['sumOpenInterest'])
        oi_usdt = float(latest_oi['sumOpenInterestValue'])
        price = oi_usdt / oi_val if oi_val > 0 else 0
        ls_ratio = float(latest_ls['longShortRatio'])
        liq_pressure = market_snapshot.get('liquidation_pressure', {})
        long_liq = liq_pressure.get('L_long_liq', 0)
        short_liq = liq_pressure.get('L_short_liq', 0)
        
        # ğŸ†• è®€å–æ›´å¤šæŒ‡æ¨™
        taker_ratio = liq_pressure.get('taker_ratio', {})
        taker_buy_sell_ratio = taker_ratio.get('ratio', 1.0) if isinstance(taker_ratio, dict) else 1.0
        oi_change_pct = liq_pressure.get('oi_change_pct', 0)
        if isinstance(oi_change_pct, list):
            oi_change_pct = oi_change_pct[-1] if oi_change_pct else 0
        
        # funding_rate æ˜¯ä¸€å€‹ listï¼Œå–æœ€æ–°çš„å€¼
        funding_rate_data = market_snapshot.get('funding_rate', [])
        if isinstance(funding_rate_data, list) and funding_rate_data:
            funding_rate = float(funding_rate_data[-1].get('fundingRate', 0))
        else:
            funding_rate = 0
    except:
        price = 0; oi_val = 0; ls_ratio = 0; long_liq = 0; short_liq = 0
        taker_buy_sell_ratio = 1.0; oi_change_pct = 0; funding_rate = 0
    
    # è‡ªæˆ‘è©•ä¼°
    learning_memory, eval_result = evaluate_past_prediction(price, previous_state, learning_memory)
    
    # ç‰¹å¾µæå–
    micro_features = extract_micro_features(signals_df)
    market_regime, market_memory = update_market_regime(signals_df, market_memory)
    mode_performance_summary = summarize_mode_performance(trading_data)
    
    signal_summary = ""
    if signals_df is not None and not signals_df.empty:
        latest_signals = signals_df.tail(5)[['mode', 'action', 'reason', 'signal_score', 'obi', 'vpin']].to_dict('records')
        signal_summary = json.dumps(latest_signals, ensure_ascii=False)

    whale_short_term = {"net_qty": 0, "dominance": 0}
    whale_long_term = {"net_qty": 0, "trend": "NEUTRAL"}
    if whale_flip_df is not None and not whale_flip_df.empty:
        recent_whales = whale_flip_df.tail(5)
        if 'net_qty' in recent_whales.columns:
            whale_short_term["net_qty"] = recent_whales['net_qty'].sum()
            whale_short_term["dominance"] = recent_whales['dominance'].mean()
        long_term_whales = whale_flip_df.tail(300)
        if 'net_qty' in long_term_whales.columns:
            net_qty_sum = long_term_whales['net_qty'].sum()
            whale_long_term["net_qty"] = net_qty_sum
            if net_qty_sum > 200: whale_long_term["trend"] = "STRONG_ACCUMULATION"
            elif net_qty_sum > 50: whale_long_term["trend"] = "MILD_ACCUMULATION"
            elif net_qty_sum < -200: whale_long_term["trend"] = "STRONG_DISTRIBUTION"
            elif net_qty_sum < -50: whale_long_term["trend"] = "MILD_DISTRIBUTION"

    # --- å®šç¾© Agents (ä½¿ç”¨ team_config) ---
    profiles = team_config.get("agent_profiles", {})
    params = team_config.get("dynamic_parameters", {})
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ­£åœ¨é€²è¡Œçš„ Grand Strategy
    grand_strategy = current_plan.get("grand_strategy", {"active": False})
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ¯ Phase 0: ä¸»åŠ›ç­–ç•¥é æ¸¬å™¨ (Whale Strategy Predictor)
    # åœ¨æ‰€æœ‰ Agent è¾¯è«–å‰ï¼Œå…ˆåˆ†æä¸»åŠ›å¯èƒ½çš„æ„åœ–å’Œé™·é˜±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    whale_strategy_analysis = analyze_whale_strategy(
        price=price,
        ls_ratio=ls_ratio,
        long_liq=long_liq,
        short_liq=short_liq,
        taker_ratio=taker_buy_sell_ratio,
        oi_change_pct=oi_change_pct,
        funding_rate=funding_rate,
        whale_short_term=whale_short_term,
        whale_long_term=whale_long_term,
        rt_whale=rt_whale,
        rt_micro=rt_micro,
        cascade_active=cascade_active,
        cascade_direction=cascade_direction,
        cascade_strength=cascade_strength
    )
    
    # ğŸ”§ v2.1: é˜²è­· whale_strategy_analysis ç‚º None çš„æƒ…æ³
    if whale_strategy_analysis is None:
        whale_strategy_analysis = {
            "whale_intent": "UNKNOWN",
            "trap_warning": {"active": False},
            "optimal_action": "WAIT",
            "confidence": 0,
            "predicted_strategy": "HOLD",
            "danger_zones": [],
            "detected_patterns": []
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ”§ v2.0 OPTIMIZED PROMPTS - æ¸›å°‘é‡è¤‡ï¼Œåˆä½µè¦å‰‡ï¼Œé™ä½ Token æ¶ˆè€—
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    p_macro = profiles.get("macro", {})
    p_micro = profiles.get("micro", {})
    p_strat = profiles.get("strategist", {})
    
    # ğŸ¯ å…±ç”¨çš„å¸‚å ´ç‹€æ…‹æ‘˜è¦ (åªå‚³ä¸€æ¬¡çµ¦ Commander)
    market_state_summary = f"""
=== MARKET STATE ===
Price: {price} | LS: {ls_ratio:.2f} | Funding: {funding_rate:.6f}
Whale: {rt_whale.get('current_direction')} ({rt_whale.get('net_qty_btc', 0):.1f} BTC, {rt_whale.get('dominance', 0):.1%})
Micro: OBI={rt_micro.get('obi', 0):.2f}, VPIN={rt_micro.get('vpin', 0):.2f}
Cascade: {"âš ï¸ " + cascade_direction + f" ({cascade_strength})" if cascade_active else "None"}
Whale Intent: {whale_strategy_analysis.get('whale_intent', '?')}, Trap: {whale_strategy_analysis.get('trap_warning', {}).get('active', False)}
"""
    
    # 1. ğŸ‘´ Macro - ç²¾ç°¡ç‰ˆ
    macro_prompt = f"""You are '{p_macro.get('name', 'Macro')}'. Grand Strategist (1-5H vision).
RULE: Real-time whale > Historical. Cascade strength>60 = follow it.
Task: Direction (BULLISH/BEARISH/NEUTRAL), Thesis, Invalidation price.
Data: Whale(4H)={whale_long_term['trend']}, Modes={mode_performance_summary[:100]}"""
    
    macro_context = f"""{market_state_summary}
Liq Pressure: L={long_liq}, S={short_liq} | Taker={taker_buy_sell_ratio:.2f} | OI Î”={oi_change_pct:+.1f}%
Grand Strategy: {json.dumps(grand_strategy, ensure_ascii=False)[:200]}"""

    # 2. âš¡ Micro - ç²¾ç°¡ç‰ˆ
    micro_prompt = f"""You are '{p_micro.get('name', 'Micro')}'. Tactical Navigator.
Task: Validate strategy. ON_TRACK/MINOR_DEVIATION/MAJOR_THREAT. Don't flip-flop.
Data: Whale(15m)={whale_short_term['net_qty']:.1f}BTC, VPIN={micro_features.get('avg_vpin', 0):.2f}"""
    
    micro_context = f"""{market_state_summary}
Strategy: {json.dumps(grand_strategy, ensure_ascii=False)[:150]}
Signals: {signal_summary[:200] if signal_summary else 'None'}"""

    # 3. âš–ï¸ Strategist - ç²¾ç°¡ç‰ˆ  
    hybrid_prompt = f"""You are '{p_strat.get('name', 'Strategist')}'. Discipline checker.
Task: PASS/FAIL discipline. MAINTAIN_COURSE or REVISE_PLAN.
Data: Bias={market_memory['strategic_bias']['direction']}"""
    
    hybrid_context = f"""Plan: {json.dumps(current_plan, ensure_ascii=False)[:200]}
Started: {grand_strategy.get('start_time', 'N/A')}"""

    # --- åŸ·è¡Œè¾¯è«– (å¹³è¡Œèª¿ç”¨) ---
    # ğŸ†• å°å‡ºä¸»åŠ›ç­–ç•¥åˆ†æçµæœ
    if whale_strategy_analysis.get('confidence', 0) >= 40:
        print(f"   ğŸ¯ [ä¸»åŠ›ç­–ç•¥] {whale_strategy_analysis.get('whale_intent', '?')} | ä¿¡å¿ƒåº¦: {whale_strategy_analysis.get('confidence', 0)}%")
        if whale_strategy_analysis.get('trap_warning', {}).get('active'):
            trap_type = whale_strategy_analysis['trap_warning'].get('type', '?')
            print(f"   ğŸš¨ [é™·é˜±è­¦å‘Š] {trap_type} - {whale_strategy_analysis['trap_warning'].get('description', '')}")
        if whale_strategy_analysis.get('optimal_action', 'WAIT') != 'WAIT':
            print(f"   ğŸ’¡ [å»ºè­°è¡Œå‹•] {whale_strategy_analysis.get('optimal_action', 'WAIT')}")
    
    print(f"   ğŸ§  AI deciding (Model: {model_name})...")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸš€ GPT-5 å„ªåŒ–ï¼šå–®æ¬¡ API å‘¼å«ï¼ˆæ™ºåŠ›è¶³å¤ ï¼Œä¸éœ€è¦å¤š Agent è¾¯è«–ï¼‰
    # ä¹‹å‰ï¼š4 æ¬¡ API (Macro + Micro + Hybrid + Commander) = æ…¢ + è²´
    # ç¾åœ¨ï¼š1 æ¬¡ API (Unified Commander) = å¿« + çœ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # --- 4. ğŸ‘‘ The Supreme Commander (è£åˆ¤) ---
    # ğŸ†• æ§‹å»ºä¸»åŠ›ç­–ç•¥åˆ†æè¨Šæ¯ (ç²¾ç°¡ç‰ˆ)
    trap_active = whale_strategy_analysis.get('trap_warning', {}).get('active', False)
    # ğŸ”§ v2.2: å¼·åŒ– None é˜²è­· - ç¢ºä¿ä¸æœƒ NoneType.upper() éŒ¯èª¤
    whale_intent = whale_strategy_analysis.get('whale_intent') or 'UNKNOWN'
    whale_optimal = whale_strategy_analysis.get('optimal_action') or 'WAIT'
    if whale_intent is None:
        whale_intent = 'UNKNOWN'
    if whale_optimal is None:
        whale_optimal = 'WAIT'

    # ğŸ†• è®€å–äº¤æ˜“ç¸¾æ•ˆ (ç”¨æ–¼æ´—ç›¤åµæ¸¬)
    feedback_loop = bridge.get('feedback_loop', {})
    # ğŸ”§ ä¿®æ­£ï¼šbridge ä½¿ç”¨ consecutive_losses ä¸æ˜¯ failure_streak
    failure_streak = feedback_loop.get('consecutive_losses', 0)
    avg_holding_time = feedback_loop.get('avg_holding_time', 0)
    total_trades = feedback_loop.get('total_trades', 0)
    
    # ğŸ†• æ´—ç›¤æ¨¡å¼åµæ¸¬
    is_shakeout_mode = whale_intent.upper() in ['SHAKEOUT', 'WASHOUT', 'STOP_HUNT', 'TRAP']
    is_dead_market = wolf_data.get('volatility', {}).get('atr_pct', 0.1) < 0.03
    is_being_washed = failure_streak >= 2 and avg_holding_time < 60  # é€£è™§ + å¿«é€Ÿå‡ºå ´
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• Phase 2: è®€å– Loss Review è«‹æ±‚ (Paper Trader ç™¼é€çš„è™§æåˆ†æè«‹æ±‚)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    wolf_to_ai = bridge.get('wolf_to_ai', {})
    loss_review = wolf_to_ai.get('loss_review', {})
    has_loss_review = loss_review.get('request_type') == 'LOSS_ANALYSIS'
    
    # æ§‹å»º Loss Review ä¸Šä¸‹æ–‡ (å¦‚æœæœ‰è«‹æ±‚)
    loss_review_context = ""
    if has_loss_review:
        lr_mode = loss_review.get('mode', 'UNKNOWN')
        lr_streak = loss_review.get('consecutive_losses', 0)
        lr_total_loss = loss_review.get('total_loss_pct', 0)
        lr_prelim = loss_review.get('preliminary_diagnosis', 'UNKNOWN')
        lr_recent = loss_review.get('recent_trades', [])
        
        loss_review_context = f"""
=== ğŸš¨ LOSS REVIEW REQUEST (PRIORITY!) ===
Mode: {lr_mode} | Consecutive Losses: {lr_streak} | Total Loss: {lr_total_loss:.2f}%
Preliminary Diagnosis: {lr_prelim}
Recent Trades:
"""
        for trade in lr_recent[-3:]:  # åªé¡¯ç¤ºæœ€è¿‘ 3 ç­†
            loss_review_context += f"  - {trade.get('direction', '?')} @ ${trade.get('entry_price', 0):.2f} â†’ PnL: {trade.get('pnl_pct', 0):.2f}%, Reason: {trade.get('exit_reason', '?')}\n"
        
        loss_review_context += f"""
**YOUR TASK**: Analyze WHY we're losing and provide `recommended_adjustments` in your output!
Categories: TOXIC_FLOW, WHALE_TRAP, DEAD_MARKET_CHURN, FALSE_BREAKOUT, WHALE_FLIP
"""
        print(f"   ğŸ” [LOSS REVIEW] Received loss analysis request for {lr_mode}")
        print(f"   ğŸ” Consecutive: {lr_streak} | Total Loss: {lr_total_loss:.2f}% | Diagnosis: {lr_prelim}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ‘‘ Commander Prompt - ç²¾ç°¡æ•´åˆç‰ˆ v2.0
    # å°‡æ‰€æœ‰è¦å‰‡æ•´åˆåˆ°ä¸€å€‹æ¸…æ™°çš„æ±ºç­–æ¡†æ¶
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # è¨ˆç®—æŒå€‰æ™‚é–“ï¼ˆå¦‚æœæœ‰æŒå€‰ï¼‰
    holding_seconds = 0
    if has_position and wolf_data.get('testnet_trading', {}).get('position', {}).get('entry_time'):
        try:
            entry_time_str = wolf_data['testnet_trading']['position']['entry_time']
            entry_time = datetime.fromisoformat(entry_time_str)
            holding_seconds = (datetime.now() - entry_time).total_seconds()
        except:
            pass
    
    commander_prompt = f"""You are the SUPREME COMMANDER. Make FINAL trading decisions.

=== ğŸš¨ ABSOLUTE RULE #1: WHALE DOMINANCE OVERRIDE (CRITICAL!) ===
**When whale_dominance >= 70%: YOU MUST FOLLOW WHALE DIRECTION!**
- Current whale_direction: {rt_whale.get('current_direction', 'UNKNOWN')}
- Current whale_dominance: {rt_whale.get('dominance', 0):.0%}
- Current whale_net_btc: {rt_whale.get('net_qty_btc', 0):.1f} BTC

IF whale_dominance >= 0.7:
  - Whale=LONG â†’ Your action MUST be LONG or HOLD (NEVER SHORT!)
  - Whale=SHORT â†’ Your action MUST be SHORT or HOLD (NEVER LONG!)
  - VIOLATION = Getting washed by market makers = GUARANTEED LOSS!

=== CORE RULES (PRIORITY ORDER) ===
1. **WHALE DOMINANCE (>70%)**: FOLLOW whale direction UNCONDITIONALLY
2. DIRECTION PROBES (Most Reliable): Mup>Mdown â†’ BULLISH, Mdown>Mup â†’ BEARISH
3. CASCADE (strength>60): MUST follow cascade direction
4. WHALE REALTIME: NetQty<-5 â†’ BEARISH, NetQty>+5 â†’ BULLISH
5. TRAP DETECTED: Do NOT enter trap direction
6. NO FLIP-FLOP: Only change direction on MAJOR structural break

=== LEVERAGE RULES (MIN 50x) ===
- Normal (60-75% conf): 50-75x
- High (75-90% conf): 75-100x  
- CASCADE aligned: 100x
- TRAP detected: 30x

=== â±ï¸ MINIMUM HOLDING TIME RULE ===
**IF holding_seconds < 180 (3 minutes): DO NOT issue CUT_LOSS!**
- Exception: Only if PnL < -10% (catastrophic loss)
- Current holding: {holding_seconds:.0f} seconds

=== ğŸ“Š MARKET CONTEXT (For Reference Only) ===
- Whale Intent: {whale_intent}
- Failure Streak: {failure_streak} | Avg Holding: {avg_holding_time:.0f}s | Total Trades: {total_trades}
- Note: These are WARNING signals, not trading blockers!

=== CURRENT STATE ===
{market_state_summary}
Position: {"NO_POSITION" if not has_position else f"{position_direction} @ ${entry_price:.2f}, PnL={current_pnl_pct:.1f}%, Holding={holding_seconds:.0f}s"}
Strategy: {grand_strategy.get('direction', 'INACTIVE')} (Active={grand_strategy.get('active', False)})
Probes: {json.dumps(wolf_data.get('direction_probes', {}), ensure_ascii=False)}

=== ADDITIONAL CONTEXT ===
Whale Long-term: {whale_long_term['trend']} ({whale_long_term['net_qty']:.0f} BTC)
Whale Short-term: {whale_short_term['net_qty']:.1f} BTC, Dominance={whale_short_term['dominance']:.1%}
Micro Features: OBI={micro_features.get('avg_obi', 0):.2f}, VPIN={micro_features.get('avg_vpin', 0):.2f}
Mode Performance: {mode_performance_summary[:80]}

=== DECISION FLOW (SIMPLIFIED - Like Original +47.66% Version) ===
1. IF whale_dominance >= 0.7: MUST align with whale direction!
2. IF failure_streak >= 5: CIRCUIT BREAKER - Output HOLD
3. IF Strategy ACTIVE + ON_TRACK: HOLD/ADD (Don't flip-flop!)
4. IF Strategy ACTIVE + MAJOR_THREAT: CUT_LOSS (only if holding > 180s OR PnL < -10%)
5. IF Strategy INACTIVE: Create NEW strategy based on Macro + Whale
6. CASCADE > 60 strength: Follow cascade direction
7. **IF LOSS_REVIEW PRESENT**: Analyze losses and provide recommended_adjustments!

=== ğŸ” LOSS REVIEW HANDLING (When loss_review is present) ===
IF you receive a LOSS_REVIEW request in context:
1. Analyze the recent_trades patterns
2. Identify root cause from: TOXIC_FLOW, WHALE_TRAP, DEAD_MARKET_CHURN, FALSE_BREAKOUT, WHALE_FLIP
3. MUST output "recommended_adjustments" with specific parameter changes
4. Set tactical_action to HOLD until parameters are adjusted

Diagnosis Guide:
- TOXIC_FLOW: Large trades hitting our stops â†’ Increase stop_loss_pct, reduce leverage
- WHALE_TRAP: Entered opposite to whale â†’ Increase confidence_threshold, add cooldown
- DEAD_MARKET_CHURN: Low volatility choppy losses â†’ Switch to LIMIT entry, reduce position
- FALSE_BREAKOUT: Breakout failed quickly â†’ Tighter stop, faster trailing
- WHALE_FLIP: Whale changed direction mid-trade â†’ Add cooldown, reduce leverage
{loss_review_context}

OUTPUT JSON (IMPORTANT - Include dynamic_params AND recommended_adjustments!):
{{
  "strategic_bias": "BULLISH|BEARISH",
  "tactical_action": "LONG|SHORT|HOLD|ADD_LONG|ADD_SHORT|CUT_LOSS",
  "recommended_leverage": 50-125,
  "conviction_score": 50-100,
  "whale_reversal_price": 0,
  "cascade_aligned": bool,
  "trap_avoided": bool,
  "dynamic_params": {{
    "leverage": 50-125,
    "take_profit_pct": 5.0-15.0,
    "stop_loss_pct": 2.0-5.0,
    "position_size_pct": 50-100,
    "trailing_activation": 3.0-10.0,
    "trailing_distance": 1.0-3.0,
    "entry_strategy": "MARKET|LIMIT",
    "limit_offset_bps": 0-10,
    "max_holding_minutes": 10-60,
    "add_position_threshold": 2.0-5.0
  }},
  "ai_prediction": {{
    "price_target": number,
    "price_direction": "UP|DOWN",
    "expected_move_pct": 0.1-2.0,
    "time_horizon_minutes": 5-60,
    "invalidation_price": number
  }},
  "grand_strategy_update": {{
    "active": bool,
    "direction": "...",
    "thesis": "...",
    "target_duration_hours": 3,
    "start_time": "{datetime.now().isoformat()}",
    "invalidation_price": 0
  }},
  "recommended_adjustments": {{
    "diagnosis": "TOXIC_FLOW|WHALE_TRAP|DEAD_MARKET_CHURN|FALSE_BREAKOUT|WHALE_FLIP|NONE",
    "confidence_threshold_delta": -5 to +10,
    "stop_loss_pct_delta": -1.0 to +2.0,
    "leverage_multiplier": 0.5 to 1.0,
    "cooldown_minutes": 0-60,
    "strategy_switch": "NONE|SNIPER|SCALP|SWING",
    "reasoning": "Why these adjustments"
  }},
  "analysis": "Brief reason"
}}

=== DYNAMIC PARAMS GUIDELINES ===
- HIGH confidence (>85%) + whale aligned: leverage=100-125, tp=8-12%, sl=2-3%
- MEDIUM confidence (70-85%): leverage=75-100, tp=6-8%, sl=3-4%
- LOW confidence (<70%): leverage=50-75, tp=5-6%, sl=4-5%
- DEAD MARKET (ATR<0.05%): entry_strategy=LIMIT, limit_offset_bps=5-10
- HIGH VOLATILITY (ATR>0.3%): smaller position_size_pct=50-70%, wider trailing
"""
    
    # ğŸ†• ç²å–ç•¶å‰æŒå€‰ç‹€æ…‹
    current_position_status = "NO_POSITION"
    if has_position:
        current_position_status = f"IN_POSITION: {position_direction} @ ${entry_price:.2f}, PnL: {current_pnl_pct:.1f}%"
    
    commander_context = f"""
Current Price: {price}
Market Regime: {market_regime}
Other Modes: {mode_performance_summary[:100]}
REAL-TIME WHALE: {rt_whale}
REAL-TIME MICRO: {rt_micro}
DIRECTION PROBES (Mup/Mdown PnL): {wolf_data.get('direction_probes', {})}

ğŸ¯ **CURRENT POSITION STATUS**: {current_position_status}
"""

    try:
        # ğŸ”§ GPT-5 ç³»åˆ—ä¸æ”¯æŒè‡ªè¨‚ temperatureï¼Œç§»é™¤æ­¤åƒæ•¸
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": commander_prompt},
                {"role": "user", "content": commander_context}
            ],
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        
        # ğŸ†• å¥å£¯çš„ JSON è§£æ (è™•ç† DeepSeek ç­‰æ¨¡å‹å¯èƒ½çš„ç©ºå›æ‡‰)
        if not content or not content.strip():
            print("   âš ï¸ [AI Response] Empty response, defaulting to HOLD")
            result = {
                "strategic_bias": "NEUTRAL",
                "tactical_action": "HOLD",
                "conviction_score": 50,
                "analysis": "AI returned empty response, holding position",
                "recommended_leverage": 75
            }
        else:
            try:
                # å˜—è©¦æå– JSON (æœ‰æ™‚æ¨¡å‹æœƒåœ¨ JSON å‰å¾ŒåŠ æ–‡å­—)
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    result = json.loads(json_match.group())
                else:
                    result = json.loads(content)
            except json.JSONDecodeError as je:
                print(f"   âš ï¸ [JSON Parse Error] {je}")
                print(f"   âš ï¸ Raw content: {content[:200]}...")
                result = {
                    "strategic_bias": "NEUTRAL",
                    "tactical_action": "HOLD",
                    "conviction_score": 50,
                    "analysis": f"JSON parse failed: {str(je)[:50]}",
                    "recommended_leverage": 75
                }
        
        # --- è™•ç†çµæœ (èˆ‡ä¹‹å‰ç›¸åŒ) ---
        analysis_text = result.get('analysis') or "No analysis provided"
        
        new_state = {
            "last_prediction": analysis_text[:100] + "...", 
            "prediction_time": datetime.now().isoformat(),
            "entry_price": price,
            "action": result.get('tactical_action') or 'WAIT',
            "strategic_bias": result.get('strategic_bias') or 'NEUTRAL',
            "confidence": result.get('conviction_score') or 50,
            "whale_reversal_price": result.get('whale_reversal_price', 0),  # ğŸ†• æ–°å¢åè½‰åƒ¹æ ¼
            "full_analysis": f"ğŸ‘‘ COMMANDER DECISION (GPT-5-mini):\n{analysis_text}"
        }
        save_advisor_state(new_state)
        
        # ğŸ†• æ›´æ–° Bridge: AI â†’ Wolf æŒ‡ä»¤
        bridge = load_bridge()
        wolf_feedback = bridge.get('wolf_to_ai', {})
        
        # ğŸ†• ç¿»è½‰å†·å»æª¢æŸ¥ (é¿å…é »ç¹ç¿»å€‰æµªè²»æ‰‹çºŒè²»)
        raw_command = result.get('tactical_action') or 'WAIT'
        raw_confidence = result.get('conviction_score') or 50
        
        should_flip, flip_reason, final_command = check_flip_cooldown(bridge, raw_command, raw_confidence)
        
        if not should_flip:
            print(f"   ğŸ›‘ [FLIP COOLDOWN] AI wanted {raw_command} but blocked: {flip_reason}")
            print(f"   ğŸ›‘ Adjusted to: {final_command}")
        elif flip_reason not in ["same_direction", "not_directional", "no_previous_trade", "cooldown_disabled"]:
            print(f"   âœ… [FLIP ALLOWED] {flip_reason}")
        
        # ğŸ†• v2.4: æ±ºç­–ç©©å®šæ€§æª¢æŸ¥ (é˜²æ­¢ 5 ç§’åˆ¤æ–·é€ æˆ AI åè¦†ç„¡å¸¸)
        is_stable, stability_reason, stable_command = check_decision_stability(final_command, raw_confidence)
        
        if not is_stable:
            print(f"   ğŸ§  [STABILITY] AI wants {final_command} but {stability_reason}")
            final_command = stable_command
        elif stability_reason not in ["stability_disabled", "non_directional"]:
            print(f"   ğŸ§  [STABILITY] Decision {stability_reason}")
        
        # ğŸ†• æœ€å°æŒå€‰æ™‚é–“ä¿è­· (é˜²æ­¢éæ—© CUT_LOSS)
        MIN_HOLDING_SECONDS = 180  # æœ€å°‘æŒå€‰ 3 åˆ†é˜ (ä¿åº•)
        CATASTROPHIC_LOSS_PCT = -10.0  # ç½é›£æ€§è™§æé–€æª»
        
        # ğŸ†• æœ€å°æŒå€‰æ™‚é–“ä¿è­· (é˜²æ­¢éæ—© CUT_LOSS è¢«æ´—ç›¤æ´—æ‰)
        # ğŸ”§ v2.2: ç§»é™¤ã€Œé¯¨é­šç¿»å‘ç„¡è¦–æ™‚é–“ã€é‚è¼¯ï¼Œé¿å…è¢«é€£çºŒæ´—æ‰
        # è®“ AI å…¨æ¬Šæ±ºå®šï¼Œä½†é€™è£¡ä»ä¿ç•™åŸºæœ¬ä¿è­·
        whale_dom = rt_whale.get('dominance', 0) or 0
        whale_dir = (rt_whale.get('current_direction') or '').upper()
        
        if final_command == "CUT_LOSS" and has_position:
            # è¨ˆç®—æŒå€‰æ™‚é–“
            holding_time = 0
            try:
                testnet_pos = wolf_data.get('testnet_trading', {}).get('position', {})
                if testnet_pos.get('entry_time'):
                    entry_time = datetime.fromisoformat(testnet_pos['entry_time'])
                    holding_time = (datetime.now() - entry_time).total_seconds()
            except:
                pass
            
            # ğŸ†• v2.3: æ™ºæ…§ç¿»è½‰åˆ¤æ–· - ç”¨ä¿¡è™Ÿå“è³ªæŒ‡æ¨™ï¼Œä¸æ˜¯ç¬¨ç¬¨ç­‰ 180 ç§’
            whale_signal = wolf_feedback.get('whale_signal_effectiveness', {})
            signal_quality = whale_signal.get('quality_score', 50)  # 0-100
            signal_grade = whale_signal.get('signal_quality', {}).get('grade', 'C')  # A/B/C/D/F
            is_effective = whale_signal.get('is_signal_effective', False)  # åƒ¹æ ¼æœ‰æ²’æœ‰è·Ÿä¸Š
            recommendation = whale_signal.get('recommendation', 'CAUTIOUS')  # TRUST/CAUTIOUS/IGNORE
            warning_factors = whale_signal.get('warning_factors', [])
            
            # ğŸ¯ æ™ºæ…§ç¿»è½‰æ¢ä»¶ (ä»»ä¸€æ»¿è¶³å°±å…è¨±ææ—©ç¿»è½‰)
            smart_flip_allowed = False
            smart_flip_reason = ""
            
            # æ¢ä»¶ 1: é«˜å“è³ªä¿¡è™Ÿ (A æˆ– B ç´šï¼Œåˆ†æ•¸ >= 70)
            if signal_grade in ['A', 'B'] and signal_quality >= 70:
                smart_flip_allowed = True
                smart_flip_reason = f"é«˜å“è³ªä¿¡è™Ÿ (Grade={signal_grade}, Score={signal_quality})"
            
            # æ¢ä»¶ 2: ä¿¡è™Ÿæœ‰æ•ˆ + å»ºè­°ä¿¡ä»»
            elif is_effective and recommendation == 'TRUST':
                smart_flip_allowed = True
                smart_flip_reason = f"ä¿¡è™Ÿæœ‰æ•ˆä¸”å»ºè­°ä¿¡ä»» (effective={is_effective}, rec={recommendation})"
            
            # æ¢ä»¶ 3: ç„¡è­¦å‘Šå› ç´  + ä¸­ç­‰ä»¥ä¸Šå“è³ª
            elif len(warning_factors) == 0 and signal_quality >= 60:
                smart_flip_allowed = True
                smart_flip_reason = f"ç„¡è­¦å‘Šå› ç´  (warnings=0, score={signal_quality})"
            
            # æ¢ä»¶ 4: ç½é›£æ€§è™§æ (> -10%)
            elif current_pnl_pct <= CATASTROPHIC_LOSS_PCT:
                smart_flip_allowed = True
                smart_flip_reason = f"ç½é›£æ€§è™§æ ({current_pnl_pct:.1f}% <= {CATASTROPHIC_LOSS_PCT}%)"
            
            # æ¢ä»¶ 5: æŒå€‰è¶…é 180 ç§’ (ä¿åº•)
            elif holding_time >= MIN_HOLDING_SECONDS:
                smart_flip_allowed = True
                smart_flip_reason = f"æŒå€‰æ™‚é–“è¶³å¤  ({holding_time:.0f}s >= {MIN_HOLDING_SECONDS}s)"
            
            if smart_flip_allowed:
                print(f"   ğŸ§  [SMART FLIP] å…è¨±ææ—©ç¿»è½‰: {smart_flip_reason}")
                print(f"   ğŸ³ Whale Signal: Grade={signal_grade}, Score={signal_quality}, Rec={recommendation}")
                if warning_factors:
                    print(f"   âš ï¸ Warnings: {warning_factors}")
            else:
                # ä¸æ»¿è¶³æ™ºæ…§æ¢ä»¶ï¼Œé˜»æ“‹ç¿»è½‰
                print(f"   ğŸ›¡ï¸ [SMART PROTECT] ä¿¡è™Ÿå“è³ªä¸è¶³ï¼Œæš«ç·©ç¿»è½‰")
                print(f"   ğŸ³ Whale Signal: Grade={signal_grade}, Score={signal_quality}, Rec={recommendation}")
                print(f"   âš ï¸ Warnings: {warning_factors}")
                print(f"   â±ï¸ Holding: {holding_time:.0f}s | PnL: {current_pnl_pct:.1f}%")
                print(f"   ğŸ›¡ï¸ Adjusted CUT_LOSS â†’ HOLD (ç­‰å¾…æ›´å¥½ä¿¡è™Ÿ)")
                final_command = "HOLD"
        
        # ğŸ¯ é«˜ç²¾æº–ç‹™æ“Šç­–ç•¥æª¢æŸ¥ (åªæœ‰é«˜å‘½ä¸­ç‡æ‰é€²å ´)
        sniper_can_enter, sniper_reason, sniper_leverage = check_sniper_entry_conditions(bridge, raw_confidence)
        
        if final_command in ["LONG", "SHORT"]:
            if not sniper_can_enter:
                print(f"   ğŸ¯ [SNIPER REJECT] {sniper_reason}")
                print(f"   ğŸ¯ Adjusted {final_command} â†’ HOLD (ç­‰å¾…æ›´å¥½æ©Ÿæœƒ)")
                final_command = "HOLD"
            else:
                print(f"   ğŸ¯ [SNIPER APPROVED] {sniper_reason} | å‹•æ…‹æ§“æ¡¿: {sniper_leverage}x")
        
        # ğŸ†• é¯¨é­šæ–¹å‘å¼·åˆ¶ä¿®æ­£ (ç¨‹å¼å±¤ç´šä¿éšªï¼Œé˜²æ­¢ AI åˆ¤æ–·éŒ¯èª¤)
        WHALE_OVERRIDE_THRESHOLD = 0.70  # 70% æ”¯é…æ€§æ™‚å¼·åˆ¶ä¸€è‡´
        whale_dom = rt_whale.get('dominance', 0) or 0
        whale_dir = (rt_whale.get('current_direction') or '').upper()
        
        if whale_dom >= WHALE_OVERRIDE_THRESHOLD and whale_dir in ['LONG', 'SHORT']:
            if final_command == 'LONG' and whale_dir == 'SHORT':
                print(f"   ğŸ³ [WHALE OVERRIDE] AI={final_command} vs Whale={whale_dir} (Dom={whale_dom:.0%})")
                print(f"   ğŸ³ å¼·åˆ¶ä¿®æ­£: LONG â†’ HOLD (é¯¨é­šåœ¨åšç©ºï¼)")
                final_command = 'HOLD'
            elif final_command == 'SHORT' and whale_dir == 'LONG':
                print(f"   ğŸ³ [WHALE OVERRIDE] AI={final_command} vs Whale={whale_dir} (Dom={whale_dom:.0%})")
                print(f"   ğŸ³ å¼·åˆ¶ä¿®æ­£: SHORT â†’ HOLD (é¯¨é­šåœ¨åšå¤šï¼)")
                final_command = 'HOLD'
            elif final_command in ['LONG', 'SHORT'] and final_command == whale_dir:
                print(f"   ğŸ³ [WHALE ALIGNED] AI={final_command} = Whale={whale_dir} (Dom={whale_dom:.0%}) âœ…")
        
        # ğŸ”§ v2.1: æ´—ç›¤æ¨¡å¼æ”¹ç‚ºã€Œè­¦å‘Šã€è€Œéã€Œé˜»æ“‹ã€
        # åŸç‰ˆ +47.66% æ™‚æœŸæ²’æœ‰å¼·åˆ¶é˜»æ“‹ï¼Œåªæœ‰è­¦å‘Š
        # éåº¦é˜»æ“‹æœƒè®“ AI å®Œå…¨ä¸äº¤æ˜“ï¼Œåè€ŒéŒ¯éæ©Ÿæœƒ
        if is_shakeout_mode or is_being_washed:
            if final_command in ['LONG', 'SHORT']:
                print(f"   âš ï¸ [SHAKEOUT WARNING] æ´—ç›¤æ¨¡å¼åµæ¸¬ (ä¸é˜»æ“‹ï¼Œåƒ…è­¦å‘Š)")
                print(f"      - Whale Intent: {whale_intent}")
                print(f"      - Failure Streak: {failure_streak}")
                print(f"      - Avg Holding: {avg_holding_time:.0f}s")
                # ğŸ”§ v2.1: åªæœ‰åœ¨é€£è™§ 5 æ¬¡ä»¥ä¸Šæ‰å¼·åˆ¶ HOLD (åŸç‰ˆçš„ CIRCUIT BREAKER)
                if failure_streak >= 5:
                    print(f"   ğŸš¨ [CIRCUIT BREAKER] é€£è™§ {failure_streak} æ¬¡ â†’ å¼·åˆ¶ HOLD")
                    final_command = 'HOLD'
                else:
                    print(f"   âœ… é€£è™§ {failure_streak} æ¬¡ < 5 æ¬¡ï¼Œå…è¨±äº¤æ˜“")
        
        # ä½¿ç”¨ç‹™æ“Šç­–ç•¥çš„æ­¢ç›ˆæ­¢æè¨­å®š
        targets = SNIPER_CONFIG["targets"]
        
        # ğŸ†• Phase 1: è®€å– AI å‹•æ…‹åƒæ•¸ (å¦‚æœ AI æœ‰è¼¸å‡ºçš„è©±)
        ai_dynamic_params = result.get('dynamic_params', {})
        ai_prediction = result.get('ai_prediction', {})
        
        # å¦‚æœ AI æ²’æœ‰è¼¸å‡ºå‹•æ…‹åƒæ•¸ï¼Œä½¿ç”¨é è¨­å€¼
        default_dynamic_params = {
            "leverage": sniper_leverage if sniper_can_enter else SNIPER_CONFIG["min_leverage"],
            "take_profit_pct": targets["take_profit_pct"],
            "stop_loss_pct": targets["stop_loss_pct"],
            "position_size_pct": 100,
            "trailing_activation": targets["trailing_activation"],
            "trailing_distance": targets["trailing_distance"],
            "entry_strategy": "MARKET",
            "limit_offset_bps": 0,
            "max_holding_minutes": 30,
            "add_position_threshold": 3.0
        }
        
        # åˆä½µ AI åƒæ•¸å’Œé è¨­åƒæ•¸ (AI å„ªå…ˆ)
        final_dynamic_params = {**default_dynamic_params, **ai_dynamic_params}
        
        # ğŸ›¡ï¸ å®‰å…¨é™åˆ¶ - é˜²æ­¢ AI è¨­å®šéæ–¼æ¿€é€²çš„åƒæ•¸
        # ğŸ”§ v2.5: SL ä¸‹é™æé«˜åˆ° 3.5%ï¼Œé¿å…è¢«å°æ³¢å‹•æ´—æ‰
        final_dynamic_params["leverage"] = max(50, min(125, final_dynamic_params.get("leverage", 75)))
        final_dynamic_params["take_profit_pct"] = max(3.0, min(20.0, final_dynamic_params.get("take_profit_pct", 10.0)))
        final_dynamic_params["stop_loss_pct"] = max(3.5, min(8.0, final_dynamic_params.get("stop_loss_pct", 3.5)))  # ğŸ”§ ä¸‹é™ 3.5%
        final_dynamic_params["position_size_pct"] = max(30, min(100, final_dynamic_params.get("position_size_pct", 100)))
        final_dynamic_params["trailing_activation"] = max(2.0, min(15.0, final_dynamic_params.get("trailing_activation", 7.0)))
        final_dynamic_params["trailing_distance"] = max(1.0, min(5.0, final_dynamic_params.get("trailing_distance", 2.5)))  # ğŸ”§ ä¸‹é™ 1.0%
        final_dynamic_params["max_holding_minutes"] = max(5, min(120, final_dynamic_params.get("max_holding_minutes", 30)))
        
        # é è¨­ AI é æ¸¬
        default_ai_prediction = {
            "price_target": 0,
            "price_direction": result.get('strategic_bias', 'NEUTRAL').replace('BULLISH', 'UP').replace('BEARISH', 'DOWN'),
            "expected_move_pct": 0.5,
            "time_horizon_minutes": 15,
            "invalidation_price": 0
        }
        final_ai_prediction = {**default_ai_prediction, **ai_prediction}
        
        # ğŸ†• Phase 2: è™•ç† AI çš„ recommended_adjustments (ç”¨æ–¼ Loss Review)
        ai_recommended_adjustments = result.get('recommended_adjustments', {})
        default_adjustments = {
            "diagnosis": "NONE",
            "confidence_threshold_delta": 0,
            "stop_loss_pct_delta": 0,
            "leverage_multiplier": 1.0,
            "cooldown_minutes": 0,
            "strategy_switch": "NONE",
            "reasoning": ""
        }
        final_recommended_adjustments = {**default_adjustments, **ai_recommended_adjustments}
        
        # ğŸ†• å¦‚æœæœ‰ Loss Review è«‹æ±‚ä¸” AI æœ‰çµ¦å‡ºè¨ºæ–·ï¼Œå°å‡ºçµæœ
        if has_loss_review and final_recommended_adjustments.get('diagnosis', 'NONE') != 'NONE':
            print(f"   ğŸ”§ [AI DIAGNOSIS] {final_recommended_adjustments['diagnosis']}")
            print(f"   ğŸ”§ Adjustments: conf_delta={final_recommended_adjustments['confidence_threshold_delta']}, "
                  f"sl_delta={final_recommended_adjustments['stop_loss_pct_delta']}, "
                  f"lev_mult={final_recommended_adjustments['leverage_multiplier']}")
            print(f"   ğŸ”§ Reasoning: {final_recommended_adjustments.get('reasoning', 'N/A')[:100]}")
        
        bridge['ai_to_wolf'] = {
            "command": final_command,  # ğŸ”§ ä½¿ç”¨ç¶“éå†·å»+ç‹™æ“Šæª¢æŸ¥çš„æŒ‡ä»¤
            "raw_command": raw_command,  # ğŸ†• ä¿ç•™åŸå§‹æŒ‡ä»¤ä¾›åƒè€ƒ
            "flip_cooldown_applied": not should_flip,  # ğŸ†• æ¨™è¨˜æ˜¯å¦è¢«å†·å»é˜»æ­¢
            "flip_reason": flip_reason,  # ğŸ†• è¨˜éŒ„åŸå› 
            "sniper_approved": sniper_can_enter,  # ğŸ†• ç‹™æ“Šç­–ç•¥æ˜¯å¦æ‰¹å‡†
            "sniper_reason": sniper_reason,  # ğŸ†• ç‹™æ“Šç­–ç•¥åŸå› 
            "direction": result.get('strategic_bias') or 'NEUTRAL',
            "confidence": raw_confidence,
            # ğŸ†• Phase 1: ä¿ç•™èˆŠæ¬„ä½ä¾›å‘å¾Œå…¼å®¹ï¼Œä½†ä¹ŸåŠ å…¥ dynamic_params
            "leverage": final_dynamic_params["leverage"],
            "whale_reversal_price": result.get('whale_reversal_price', 0),
            "take_profit_pct": final_dynamic_params["take_profit_pct"],
            "stop_loss_pct": final_dynamic_params["stop_loss_pct"],
            "trailing_activation": final_dynamic_params["trailing_activation"],
            "trailing_distance": final_dynamic_params["trailing_distance"],
            "reasoning": analysis_text[:200],
            "timestamp": datetime.now().isoformat(),
            # ğŸ†• Phase 1: AI å‹•æ…‹åƒæ•¸ (å®Œæ•´ç‰ˆ)
            "dynamic_params": final_dynamic_params,
            # ğŸ†• Phase 1: AI åƒ¹æ ¼é æ¸¬
            "ai_prediction": final_ai_prediction,
            # ğŸ†• Phase 2: AI å»ºè­°èª¿æ•´ (ç”¨æ–¼ Loss Review)
            "recommended_adjustments": final_recommended_adjustments,
            # ğŸ†• åŠ å…¥ä¸»åŠ›ç­–ç•¥åˆ†æçµæœ
            "whale_strategy": {
                "intent": whale_strategy_analysis.get('whale_intent', 'UNKNOWN'),
                "predicted_strategy": whale_strategy_analysis.get('predicted_strategy', 'HOLD'),
                "optimal_action": whale_strategy_analysis.get('optimal_action', 'WAIT'),
                "trap_warning": whale_strategy_analysis.get('trap_warning', {}),
                "danger_zones": whale_strategy_analysis.get('danger_zones', []),
                "confidence": whale_strategy_analysis.get('confidence', 0),
                "detected_patterns": whale_strategy_analysis.get('detected_patterns', [])
            }
        }
        save_bridge(bridge)

        # ğŸ”„ å¼·åˆ¶åŒæ­¥ Strategy Plan (ç¢ºä¿èˆ‡ Bridge åŒæ­¥)
        # å³ä½¿ LLM æ²’æœ‰è¿”å›å®Œæ•´çš„ strategic_planï¼Œä¹Ÿè¦æ ¹æ“šç•¶å‰æ±ºç­–æ›´æ–°é—œéµæ¬„ä½
        try:
            current_plan = load_strategy_plan()
            
            # 1. æå– LLM çš„è¨ˆç•«ç´°ç¯€ (å¦‚æœæœ‰çš„è©±)
            if 'strategic_plan' in result and isinstance(result['strategic_plan'], dict):
                plan_update = result['strategic_plan']
                current_plan.update(plan_update)
            
            # ğŸ†• æ›´æ–° Grand Strategy
            if 'grand_strategy_update' in result and isinstance(result['grand_strategy_update'], dict):
                current_plan['grand_strategy'] = result['grand_strategy_update']
                
            # 2. å¼·åˆ¶è¦†è“‹é—œéµç‹€æ…‹ (ä»¥ Bridge æ±ºç­–ç‚ºæº–)
            current_plan['market_bias'] = result.get('strategic_bias', 'NEUTRAL')
            current_plan['phase'] = result.get('tactical_action', 'WAIT')
            current_plan['max_leverage'] = result.get('recommended_leverage', 1)
            current_plan['risk_level'] = team_config['dynamic_parameters'].get('risk_level', 'MODERATE')
            
            # 3. æ›´æ–°å…ƒæ•¸æ“š
            current_plan['created_at'] = datetime.now().isoformat()
            current_plan['plan_id'] = str(uuid.uuid4())
            
            save_strategy_plan(current_plan)
            print(f"   ğŸ“ [Plan Synced] Strategy Plan updated to {current_plan['market_bias']} / {current_plan['phase']}")
        except Exception as e:
            print(f"   âš ï¸ Failed to sync strategy plan: {e}")
        
        # ğŸ†• è®€å– Wolf çš„å®Œæ•´å›é¥‹ä¸¦åšæ™ºèƒ½èª¿æ•´
        feedback_loop = bridge.get('feedback_loop', {})
        # ğŸ”§ ä¿®æ­£ï¼šbridge ä½¿ç”¨ consecutive_losses ä¸æ˜¯ failure_streak
        failure_streak = feedback_loop.get('consecutive_losses', 0)
        
        # ğŸš¨ CIRCUIT BREAKER (ç†”æ–·æ©Ÿåˆ¶)
        if failure_streak >= 5:
            print(f"   ğŸš¨ [CIRCUIT BREAKER] Failure streak {failure_streak} detected! Forcing HOLD and RESET.")
            bridge['ai_to_wolf']['command'] = 'HOLD'
            bridge['ai_to_wolf']['reasoning'] = f"CIRCUIT BREAKER: Too many consecutive losses ({failure_streak}). Pausing to realign."
            save_bridge(bridge)
            
            # é‡ç½® Grand Strategy
            current_plan['grand_strategy'] = {"active": False}
            save_strategy_plan(current_plan)
            return "CIRCUIT BREAKER TRIGGERED"

        if wolf_feedback.get('status') == 'IN_POSITION' or has_position:
            # ğŸ†• ä½¿ç”¨çµ±ä¸€çš„ Testnet æ•¸æ“š
            pnl_pct = current_pnl_pct if has_position else wolf_feedback.get('current_pnl_pct', 0)
            
            # ğŸ“Š Priority 1: åˆ†æé¯¨é­šç‹€æ…‹
            whale_status = wolf_feedback.get('whale_status', {})
            whale_direction = whale_status.get('current_direction')
            whale_dominance = whale_status.get('dominance', 0)
            whale_flip_count = whale_status.get('flip_count_30min', 0)
            
            # ğŸ“ˆ Priority 1: åˆ†æå¸‚å ´å¾®çµæ§‹
            micro = wolf_feedback.get('market_microstructure', {})
            obi = micro.get('obi', 0)
            vpin = micro.get('vpin', 0)
            funding_rate = micro.get('funding_rate', 0)
            
            # ğŸŒŠ Priority 1: åˆ†ææ³¢å‹•ç’°å¢ƒ
            volatility = wolf_feedback.get('volatility', {})
            atr_pct = volatility.get('atr_pct', 0)
            is_dead_market = volatility.get('is_dead_market', False)
            regime = volatility.get('regime', 'UNKNOWN')
            
            # ğŸ¯ Priority 2: æª¢æŸ¥é æ¸¬æº–ç¢ºåº¦
            feedback_loop = bridge.get('feedback_loop', {})
            prediction_accuracy = feedback_loop.get('prediction_accuracy', {})
            direction_accuracy = prediction_accuracy.get('direction_accuracy_pct', 0)
            
            # ğŸš¨ Priority 3: é¢¨éšªè­¦ç¤º
            risk_indicators = wolf_feedback.get('risk_indicators', {})
            liquidation_pressure = risk_indicators.get('liquidation_pressure', 0)
            whale_trap_prob = risk_indicators.get('whale_trap_probability', 0)
            
            # æ™ºèƒ½æ±ºç­–é‚è¼¯
            warnings = []
            profit_adjustments = []
            
            # ğŸ¯ å‹•æ…‹èª¿æ•´æ­¢ç›ˆé…ç½®
            profit_config_file = "ai_profit_config.json"
            if os.path.exists(profit_config_file):
                try:
                    with open(profit_config_file, 'r') as f:
                        profit_config = json.load(f)
                    
                    # æ ¹æ“šå¸‚å ´ç‹€æ³å’Œç¸¾æ•ˆèª¿æ•´æ­¢ç›ˆç›®æ¨™
                    win_rate = feedback_loop.get('win_rate', 0)
                    total_trades = feedback_loop.get('total_trades', 0)
                    
                    should_update_config = False
                    
                    # æ ¹æ“šå‹ç‡å‹•æ…‹èª¿æ•´
                    if total_trades >= 5:
                        dynamic_profit = profit_config.get('dynamic_profit_taking', {})
                        base_targets = dynamic_profit.get('base_targets', {})
                        
                        if win_rate >= 70 and base_targets.get('standard', 15.0) < 25.0:
                            # å‹ç‡é«˜,æé«˜æ­¢ç›ˆç›®æ¨™
                            base_targets['standard'] = 25.0
                            base_targets['dead_market_reversal'] = 15.0
                            base_targets['reversal_ambush'] = 30.0
                            profit_adjustments.append(f"ğŸ“ˆ High win rate ({win_rate:.0f}%) â†’ Increased profit targets")
                            should_update_config = True
                        elif win_rate < 30 and base_targets.get('standard', 15.0) > 10.0:
                            # å‹ç‡ä½,é™ä½æ­¢ç›ˆç›®æ¨™ (ä½†ä¸èƒ½ä½æ–¼æ‰‹çºŒè²»æˆæœ¬)
                            base_targets['standard'] = 12.0
                            base_targets['dead_market_reversal'] = 10.0
                            base_targets['reversal_ambush'] = 15.0
                            profit_adjustments.append(f"ğŸ“‰ Low win rate ({win_rate:.0f}%) â†’ Reduced profit targets")
                            should_update_config = True
                    
                    # æ ¹æ“šæ³¢å‹•ç‡èª¿æ•´
                    if atr_pct > 0.1:
                        # é«˜æ³¢å‹•,å¯ä»¥æé«˜ç›®æ¨™
                        progressive = profit_config.get('dynamic_profit_taking', {}).get('progressive_targets', {})
                        high_stage = progressive.get('stages', {}).get('high', {})
                        if high_stage.get('max_target', 6.0) < 8.0:
                            high_stage['max_target'] = 8.0
                            profit_adjustments.append(f"âš¡ High volatility (ATR: {atr_pct:.4f}%) â†’ Max target 8%")
                            should_update_config = True
                    elif atr_pct < 0.02:
                        # ä½æ³¢å‹•,é™ä½ç›®æ¨™
                        progressive = profit_config.get('dynamic_profit_taking', {}).get('progressive_targets', {})
                        high_stage = progressive.get('stages', {}).get('high', {})
                        if high_stage.get('max_target', 6.0) > 3.0:
                            high_stage['max_target'] = 3.0
                            profit_adjustments.append(f"ğŸ’¤ Low volatility (ATR: {atr_pct:.4f}%) â†’ Max target 3%")
                            should_update_config = True
                    
                    # å„²å­˜æ›´æ–°
                    if should_update_config:
                        profit_config['last_updated'] = datetime.now().isoformat()
                        history = profit_config.get('ai_adjustment_history', [])
                        history.append({
                            "timestamp": datetime.now().isoformat(),
                            "reason": f"Auto-adjustment based on WR={win_rate:.0f}%, ATR={atr_pct:.4f}%",
                            "changes": profit_adjustments
                        })
                        profit_config['ai_adjustment_history'] = history[-20:]  # ä¿ç•™æœ€è¿‘ 20 æ¬¡
                        
                        with open(profit_config_file, 'w') as f:
                            json.dump(profit_config, f, indent=2)
                except Exception as e:
                    print(f"   âš ï¸ Failed to adjust profit config: {e}")
            
            # æª¢æŸ¥ 1: PnL + é¯¨é­šåè½‰
            if pnl_pct < -0.5:
                if whale_direction and whale_direction != bridge['ai_to_wolf']['direction']:
                    warnings.append(f"âš ï¸ WHALE FLIPPED! Now {whale_direction} (Dom: {whale_dominance:.2f})")
                elif whale_flip_count >= 2:
                    warnings.append(f"âš ï¸ Whale churning ({whale_flip_count} flips) - possible trap")
                else:
                    warnings.append(f"âš ï¸ Position underwater: {pnl_pct:.2f}%")
            
            # æª¢æŸ¥ 2: æ­»æ°´ç›¤è­¦å‘Š
            if is_dead_market and atr_pct < 0.01:
                warnings.append(f"ğŸ’¤ Dead market (ATR: {atr_pct:.4f}%) - low win probability")
            
            # æª¢æŸ¥ 3: æ¥µç«¯é¢¨éšª
            if liquidation_pressure > 70:
                warnings.append(f"ğŸ”´ High liquidation risk: {liquidation_pressure}/100")
            
            if whale_trap_prob > 0.6:
                warnings.append(f"ğŸª¤ Whale trap probability: {whale_trap_prob:.0%}")
            
            # æª¢æŸ¥ 4: é æ¸¬æº–ç¢ºåº¦ä½
            if direction_accuracy < 40 and feedback_loop.get('total_trades', 0) >= 5:
                warnings.append(f"ğŸ“‰ Low prediction accuracy: {direction_accuracy:.0f}%")
            
            # æª¢æŸ¥ 5: ç²åˆ© + ç’°å¢ƒç¢ºèª
            if pnl_pct > 1.0:
                if whale_direction == bridge['ai_to_wolf']['direction']:
                    warnings.append(f"âœ… Profitable + Whale aligned ({whale_dominance:.2f} dom) - hold/add")
                else:
                    warnings.append(f"âš ï¸ Profitable but whale diverging - consider partial exit")
            
            # è¼¸å‡ºæ‰€æœ‰è­¦å‘Š
            if profit_adjustments:
                print(f"   ğŸ¯ Profit Config Auto-Adjustments:")
                for adj in profit_adjustments:
                    print(f"      {adj}")
            
            for warning in warnings:
                print(f"   {warning}")
            
            # è¼¸å‡ºé—œéµå¸‚å ´æŒ‡æ¨™
            print(f"   ğŸ“Š Market: {regime} | ATR: {atr_pct:.4f}% | OBI: {obi:.2f} | VPIN: {vpin:.2f} | Fund: {funding_rate:.4f}")
        
        # æ›´æ–°å¸‚å ´è¨˜æ†¶ (Bias) - å¸¶é˜²æŠ–å‹•
        suggested_bias = result.get('strategic_bias') or 'NEUTRAL'
        current_bias = market_memory["strategic_bias"]["direction"]
        
        if suggested_bias != current_bias:
            pending = market_memory["strategic_bias"].get("pending_change")
            if pending and pending["direction"] == suggested_bias:
                pending["count"] += 1
                if pending["count"] >= 3:
                    market_memory["strategic_bias"]["direction"] = suggested_bias
                    market_memory["strategic_bias"]["since"] = datetime.now().isoformat()
                    market_memory["strategic_bias"]["pending_change"] = None
                    print(f"   ğŸ”„ [Bias Flip] Confirmed change to {suggested_bias}")
                else:
                    print(f"   â³ [Bias Stability] Potential flip to {suggested_bias} detected ({pending['count']}/3)... Holding {current_bias}")
            else:
                market_memory["strategic_bias"]["pending_change"] = {
                    "direction": suggested_bias,
                    "count": 1,
                    "last_check": datetime.now().isoformat()
                }
                print(f"   â³ [Bias Stability] Potential flip to {suggested_bias} detected (1/3)... Holding {current_bias}")
                new_state["strategic_bias"] = current_bias # å¼·åˆ¶ä¿æŒ
        else:
             if market_memory["strategic_bias"].get("pending_change"):
                market_memory["strategic_bias"]["pending_change"] = None
        
        save_market_memory(market_memory)
            
        # è™•ç†åƒæ•¸æ›´æ–°
        if 'parameter_updates' in result and result['parameter_updates']:
            updates = result['parameter_updates']
            print(f"   âš™ï¸ [Auto-Tuning] Commander suggested updates: {updates}")
            # æ›´æ–° team_config
            for k, v in updates.items():
                if k in team_config['dynamic_parameters']:
                    team_config['dynamic_parameters'][k] = v
            team_config['recent_adjustments'].append({
                "time": datetime.now().isoformat(),
                "updates": updates,
                "reason": "Commander Decision"
            })
            save_team_config(team_config)
            
        # æ ¼å¼åŒ–è¼¸å‡º (GPT-5 å–®æ¬¡æ±ºç­–ï¼Œä¸éœ€è¦å¤š Agent è¾¯è«–)
        analysis_preview = (result.get('analysis') or "No analysis")[:150]
        
        return f"[{result.get('strategic_bias')} | {result.get('tactical_action')} (Lev x{result.get('recommended_leverage', 1)})] {analysis_preview}"

    except Exception as e:
        return f"âŒ Commander failed: {e}"

def analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state):
    # ç‚ºäº†å…¼å®¹èˆŠä»£ç¢¼æ¥å£ï¼Œé€™è£¡ç›´æ¥è½‰ç™¼çµ¦ run_council_meeting
    return run_council_meeting(trading_data, market_snapshot, signals_df, whale_flip_df, previous_state)


def parse_args():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(description='AI Trading Advisor - GPT Version')
    parser.add_argument('hours', nargs='?', type=float, default=0,
                        help='é‹è¡Œæ™‚é–“ï¼ˆå°æ™‚ï¼‰ï¼Œ0 è¡¨ç¤ºç„¡é™é‹è¡Œ')
    parser.add_argument('--interval', type=int, default=20,
                        help='åˆ†æé–“éš”ï¼ˆç§’ï¼‰ï¼Œé è¨­ 20 ç§’')
    return parser.parse_args()


def main():
    args = parse_args()
    
    # ğŸ†• å•Ÿç”¨çµ‚ç«¯æ©Ÿæ—¥èªŒè¨˜éŒ„
    logger = setup_terminal_logging()
    
    # è¨ˆç®—çµæŸæ™‚é–“
    start_time = datetime.now()
    end_time = None
    if args.hours > 0:
        end_time = start_time + timedelta(hours=args.hours)
        print(f"â° å°‡åœ¨ {args.hours} å°æ™‚å¾Œè‡ªå‹•åœæ­¢ ({end_time.strftime('%Y-%m-%d %H:%M:%S')})")
    
    print("="*60)
    print("ğŸ¤– AI Whale Hunter (Trap Master Mode) - GPT Version")
    print("="*60)
    if end_time:
        print(f"ğŸ“… é–‹å§‹æ™‚é–“: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“… çµæŸæ™‚é–“: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    while True:
        try:
            # æª¢æŸ¥æ˜¯å¦è¶…æ™‚
            if end_time and datetime.now() >= end_time:
                elapsed = datetime.now() - start_time
                print(f"\nâ° é‹è¡Œæ™‚é–“å·²é” {elapsed.total_seconds()/3600:.2f} å°æ™‚ï¼Œè‡ªå‹•åœæ­¢")
                print(f"ğŸ›‘ AI Advisor GPT å·²åœæ­¢ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
                break
            
            # 1. è¼‰å…¥æ•¸æ“š
            session_path = find_latest_pt_session()
            if not session_path:
                print("âŒ No session found.")
                time.sleep(60)
                continue
                
            trading_data = load_trading_data(session_path)
            market_snapshot = load_market_snapshot()
            signals_df = load_signal_diagnostics(session_path)
            whale_flip_df = load_whale_flip_analysis(session_path)
            prev_state = load_advisor_state()
            
            # 2. AI åˆ†æ
            current_time = datetime.now().strftime('%H:%M:%S')
            remaining = ""
            if end_time:
                remaining_seconds = (end_time - datetime.now()).total_seconds()
                remaining_hours = remaining_seconds / 3600
                remaining = f" | å‰©é¤˜ {remaining_hours:.1f}h"
            
            print(f"\n[{current_time}] ğŸ” Analyzing Session: {session_path.name}{remaining}")
            analysis = analyze_with_ai(trading_data, market_snapshot, signals_df, whale_flip_df, prev_state)
            
            print("\n" + analysis)
            print("\n" + "-"*60)
            print(f"ğŸ’¤ Observing fluctuations... (Next check in {args.interval}s)")
            
            time.sleep(args.interval)
            
        except KeyboardInterrupt:
            elapsed = datetime.now() - start_time
            print(f"\nğŸ›‘ AI Advisor GPT Stopped. (é‹è¡Œæ™‚é–“: {elapsed.total_seconds()/3600:.2f} å°æ™‚)")
            break
        except Exception as e:
            print(f"âš ï¸ Error: {e}")
            time.sleep(60)
    
    # ğŸ†• é—œé–‰æ—¥èªŒè¨˜éŒ„
    close_terminal_logging()

if __name__ == "__main__":
    main()

