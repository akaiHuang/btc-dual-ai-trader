"""
ç¹¼çºŒä¸‹è¼‰å‰©é¤˜çš„æ™‚é–“æ¡†æ¶
"""

import sys
from pathlib import Path
from datetime import datetime, timedelta
import time
import pandas as pd
from tqdm import tqdm
import json

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.exchange.binance_client import BinanceClient


class DataDownloader:
    """ç°¡åŒ–çš„è³‡æ–™ä¸‹è¼‰å™¨"""
    
    MAX_KLINES_PER_REQUEST = 1000
    
    def __init__(self):
        self.client = BinanceClient()
        # ä½¿ç”¨ Mainnet
        from binance.client import Client
        self.client.client = Client(api_key="", api_secret="")
        self.data_dir = Path("data/historical")
        self.data_dir.mkdir(parents=True, exist_ok=True)
    
    def download_interval(self, interval: str, years: int = 5):
        """ä¸‹è¼‰å–®ä¸€æ™‚é–“æ¡†æ¶"""
        print(f"\nğŸ“¥ ä¸‹è¼‰ {interval} Kç·šè³‡æ–™")
        
        end_time = datetime.now()
        start_time = end_time - timedelta(days=years * 365)
        
        symbol = "BTCUSDT"
        all_klines = []
        current_start = int(start_time.timestamp() * 1000)
        end_ts = int(end_time.timestamp() * 1000)
        
        # é ä¼°è«‹æ±‚æ¬¡æ•¸
        estimated_requests = 2629 if interval == '1m' else 1000
        pbar = tqdm(total=estimated_requests, desc=f"  {interval}", unit="req")
        
        while current_start < end_ts:
            try:
                klines = self.client.get_klines(
                    symbol=symbol,
                    interval=interval,
                    start_time=current_start,
                    limit=self.MAX_KLINES_PER_REQUEST
                )
                
                if not klines:
                    break
                
                all_klines.extend(klines)
                current_start = int(klines[-1][6]) + 1
                pbar.update(1)
                
                time.sleep(0.05)  # é¿å…é€Ÿç‡é™åˆ¶
                
            except Exception as e:
                print(f"\nâŒ éŒ¯èª¤: {e}")
                time.sleep(5)
                continue
        
        pbar.close()
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(all_klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base',
            'taker_buy_quote', 'ignore'
        ])
        
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
        
        for col in ['open', 'high', 'low', 'close', 'volume', 'quote_volume', 'taker_buy_base', 'taker_buy_quote']:
            df[col] = df[col].astype(float)
        
        df['trades'] = df[col].astype(int)
        df = df.drop(columns=['ignore'])
        
        # å»é‡æ’åº
        df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
        
        # å„²å­˜
        file_path = self.data_dir / f"{symbol}_{interval}.parquet"
        df.to_parquet(file_path, index=False)
        
        file_size_mb = file_path.stat().st_size / 1024 / 1024
        
        print(f"   âœ… å®Œæˆï¼{len(df):,} rows, {file_size_mb:.2f} MB")
        print(f"   æ™‚é–“ç¯„åœ: {df.iloc[0]['timestamp']} ~ {df.iloc[-1]['timestamp']}")
        
        return {
            'rows': len(df),
            'size_mb': round(file_size_mb, 2),
            'start': df.iloc[0]['timestamp'].isoformat(),
            'end': df.iloc[-1]['timestamp'].isoformat(),
        }


def main():
    """ä¸»å‡½æ•¸"""
    print("\nğŸš€ ç¹¼çºŒä¸‹è¼‰å‰©é¤˜æ™‚é–“æ¡†æ¶\n")
    
    downloader = DataDownloader()
    
    # æª¢æŸ¥å·²å®Œæˆçš„
    completed = []
    for interval in ['1m', '3m', '15m', '1h', '1d', '1w']:
        file_path = downloader.data_dir / f"BTCUSDT_{interval}.parquet"
        if file_path.exists():
            completed.append(interval)
    
    print(f"å·²å®Œæˆ: {', '.join(completed) if completed else 'ç„¡'}")
    
    # å‰©é¤˜çš„
    remaining = ['3m', '15m', '1h', '1d', '1w']
    remaining = [i for i in remaining if i not in completed]
    
    if not remaining:
        print("âœ… æ‰€æœ‰æ™‚é–“æ¡†æ¶å·²ä¸‹è¼‰å®Œæˆï¼")
        return
    
    print(f"å¾…ä¸‹è¼‰: {', '.join(remaining)}\n")
    
    # çµ±è¨ˆè³‡è¨Š
    stats = {'intervals': {}, 'total_rows': 0, 'total_size_mb': 0}
    
    # åŠ è¼‰å·²æœ‰çš„çµ±è¨ˆ
    stats_file = downloader.data_dir / 'download_stats.json'
    if stats_file.exists():
        with open(stats_file, 'r') as f:
            stats = json.load(f)
    
    stats['start_time'] = datetime.now().isoformat()
    
    # ä¸‹è¼‰
    for interval in remaining:
        try:
            result = downloader.download_interval(interval, years=5)
            stats['intervals'][interval] = result
            stats['total_rows'] += result['rows']
            stats['total_size_mb'] += result['size_mb']
        except Exception as e:
            print(f"âŒ {interval} ä¸‹è¼‰å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    stats['end_time'] = datetime.now().isoformat()
    
    # å„²å­˜çµ±è¨ˆ
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print("\nâœ… ä¸‹è¼‰å®Œæˆï¼")
    print(f"ç¸½Kç·šæ•¸: {stats['total_rows']:,}")
    print(f"ç¸½å¤§å°: {stats['total_size_mb']:.2f} MB")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸  ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
