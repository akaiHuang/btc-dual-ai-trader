"""
éŒ¯å–®æ”¾å¤§é¡ - Loss Pattern Analyzer
åˆ†ææ¯ç­†è™§æäº¤æ˜“çš„ç‰¹å¾µï¼Œæ‰¾å‡ºå°è‡´è™§æçš„æ¨¡å¼
å¹«åŠ©å„ªåŒ–æ­¢æç­–ç•¥å’Œé€²å ´æ¢ä»¶

ä½œè€…: Phase 0 å„ªåŒ–é …ç›®
æ—¥æœŸ: 2025-11-14
"""

import json
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict, Counter


@dataclass
class LossTrade:
    """è™§æäº¤æ˜“è¨˜éŒ„"""
    trade_id: str
    entry_time: datetime
    exit_time: datetime
    entry_price: float
    exit_price: float
    position_size: float
    leverage: int
    direction: str  # LONG/SHORT
    loss_amount: float
    loss_percent: float
    holding_time_seconds: int
    
    # é€²å ´ç‰¹å¾µ
    rsi_at_entry: Optional[float] = None
    spread_at_entry: Optional[float] = None
    volume_at_entry: Optional[float] = None
    volatility_at_entry: Optional[float] = None
    obi_at_entry: Optional[float] = None
    vpin_at_entry: Optional[float] = None
    
    # å‡ºå ´ç‰¹å¾µ
    exit_reason: str = "UNKNOWN"  # SL_HIT/TP_HIT/MANUAL/TIMEOUT
    sl_percent: Optional[float] = None
    tp_percent: Optional[float] = None
    
    # å…ƒæ•¸æ“š
    strategy: str = "unknown"
    metadata: Optional[Dict] = None
    
    def to_dict(self) -> Dict:
        """è½‰æ›ç‚ºå­—å…¸ï¼ˆåºåˆ—åŒ–å‹å¥½ï¼‰"""
        d = asdict(self)
        d['entry_time'] = self.entry_time.isoformat()
        d['exit_time'] = self.exit_time.isoformat()
        return d
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'LossTrade':
        """å¾å­—å…¸å‰µå»ºå°è±¡"""
        data['entry_time'] = datetime.fromisoformat(data['entry_time'])
        data['exit_time'] = datetime.fromisoformat(data['exit_time'])
        return cls(**data)


@dataclass
class LossPattern:
    """è™§ææ¨¡å¼"""
    pattern_name: str
    description: str
    occurrence_count: int
    total_loss: float
    avg_loss: float
    trades: List[str]  # trade_id åˆ—è¡¨
    confidence: float  # ä¿¡å¿ƒåº¦ (0-1)
    recommendation: str  # å„ªåŒ–å»ºè­°


class LossPatternAnalyzer:
    """
    éŒ¯å–®æ”¾å¤§é¡
    
    åŠŸèƒ½ï¼š
    1. è¨˜éŒ„æ‰€æœ‰è™§æäº¤æ˜“çš„è©³ç´°ç‰¹å¾µ
    2. åˆ†æè™§ææ¨¡å¼ï¼ˆå¦‚ã€Œç›¤æ•´æœŸè™§æã€ã€Œå¿«é€Ÿæ­¢æã€ç­‰ï¼‰
    3. æä¾›å„ªåŒ–å»ºè­°
    4. ç”Ÿæˆè™§æå ±å‘Š
    """
    
    def __init__(
        self,
        data_file: str = "data/loss_trades.json",
        min_pattern_count: int = 3  # è‡³å°‘3ç­†äº¤æ˜“æ‰èªå®šç‚ºæ¨¡å¼
    ):
        """
        åˆå§‹åŒ–éŒ¯å–®æ”¾å¤§é¡
        
        Args:
            data_file: æ•¸æ“šå­˜å„²æ–‡ä»¶
            min_pattern_count: æœ€å°‘æ¨¡å¼è­˜åˆ¥æ¬¡æ•¸
        """
        self.data_file = Path(data_file)
        self.min_pattern_count = min_pattern_count
        
        # è™§æäº¤æ˜“è¨˜éŒ„
        self.loss_trades: Dict[str, LossTrade] = {}
        
        # è¼‰å…¥æ­·å²æ•¸æ“š
        self.load_data()
    
    def load_data(self):
        """è¼‰å…¥æ­·å²è™§ææ•¸æ“š"""
        if not self.data_file.exists():
            print(f"è™§ææ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°æ–‡ä»¶: {self.data_file}")
            self.data_file.parent.mkdir(parents=True, exist_ok=True)
            self.save_data()
            return
        
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.loss_trades = {}
            for trade_id, trade_data in data.get('loss_trades', {}).items():
                self.loss_trades[trade_id] = LossTrade.from_dict(trade_data)
            
            print(f"è¼‰å…¥è™§æè¨˜éŒ„: {len(self.loss_trades)} ç­†")
        
        except Exception as e:
            print(f"è¼‰å…¥è™§ææ•¸æ“šå¤±æ•—: {e}")
            self.loss_trades = {}
    
    def save_data(self):
        """ä¿å­˜æ•¸æ“šåˆ°æ–‡ä»¶"""
        try:
            data = {
                'loss_trades': {
                    trade_id: trade.to_dict() 
                    for trade_id, trade in self.loss_trades.items()
                },
                'last_updated': datetime.now().isoformat(),
                'total_losses': len(self.loss_trades)
            }
            
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        
        except Exception as e:
            print(f"ä¿å­˜è™§ææ•¸æ“šå¤±æ•—: {e}")
    
    def record_loss(self, trade: LossTrade):
        """
        è¨˜éŒ„ä¸€ç­†è™§æäº¤æ˜“
        
        Args:
            trade: LossTrade å°è±¡
        """
        self.loss_trades[trade.trade_id] = trade
        
        # å®šæœŸä¿å­˜ï¼ˆæ¯10ç­†ï¼‰
        if len(self.loss_trades) % 10 == 0:
            self.save_data()
    
    def analyze_patterns(self) -> List[LossPattern]:
        """
        åˆ†æè™§ææ¨¡å¼
        
        Returns:
            è­˜åˆ¥å‡ºçš„è™§ææ¨¡å¼åˆ—è¡¨
        """
        if len(self.loss_trades) < self.min_pattern_count:
            return []
        
        patterns = []
        trades = list(self.loss_trades.values())
        
        # æ¨¡å¼ 1ï¼šå¿«é€Ÿæ­¢æï¼ˆæŒå€‰æ™‚é–“ < 5åˆ†é˜ï¼‰
        fast_sl_trades = [
            t for t in trades 
            if t.holding_time_seconds < 300 and t.exit_reason == "SL_HIT"
        ]
        if len(fast_sl_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="å¿«é€Ÿæ­¢æ",
                description="é€²å ´å¾ŒçŸ­æ™‚é–“å…§è¢«æ­¢æï¼Œå¯èƒ½æ˜¯å‡çªç ´æˆ–é€²å ´æ™‚æ©Ÿä¸ä½³",
                occurrence_count=len(fast_sl_trades),
                total_loss=sum(t.loss_amount for t in fast_sl_trades),
                avg_loss=np.mean([t.loss_amount for t in fast_sl_trades]),
                trades=[t.trade_id for t in fast_sl_trades],
                confidence=min(1.0, len(fast_sl_trades) / 20),
                recommendation="å»ºè­°ï¼š1) åŠ å…¥ç¢ºèªæŒ‡æ¨™ï¼ˆå¦‚çªç ´å¾Œå›è¸©ï¼‰ 2) æ”¾å¯¬æ­¢æ 3) ä½¿ç”¨æ™‚é–“ç¯©é¸å™¨"
            ))
        
        # æ¨¡å¼ 2ï¼šé«˜æ³¢å‹•æœŸè™§æï¼ˆVPIN > 0.5 æˆ– ATR é«˜ï¼‰
        high_vol_trades = [
            t for t in trades 
            if t.vpin_at_entry and t.vpin_at_entry > 0.5
        ]
        if len(high_vol_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="é«˜æ³¢å‹•æœŸè™§æ",
                description="åœ¨å¸‚å ´æ³¢å‹•åŠ‡çƒˆæ™‚é€²å ´ï¼Œå®¹æ˜“è¢«æƒæ­¢æ",
                occurrence_count=len(high_vol_trades),
                total_loss=sum(t.loss_amount for t in high_vol_trades),
                avg_loss=np.mean([t.loss_amount for t in high_vol_trades]),
                trades=[t.trade_id for t in high_vol_trades],
                confidence=min(1.0, len(high_vol_trades) / 15),
                recommendation="å»ºè­°ï¼š1) å•Ÿç”¨ç›¤æ•´åµæ¸¬å™¨ 2) VPIN > 0.5 æ™‚ç¦æ­¢äº¤æ˜“ 3) ä½¿ç”¨å‹•æ…‹æ­¢æ"
            ))
        
        # æ¨¡å¼ 3ï¼šå¯¬åƒ¹å·®æœŸè™§æï¼ˆSpread > 0.1%ï¼‰
        wide_spread_trades = [
            t for t in trades 
            if t.spread_at_entry and t.spread_at_entry > 0.001
        ]
        if len(wide_spread_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="å¯¬åƒ¹å·®æœŸè™§æ",
                description="åƒ¹å·®éå¯¬æ™‚é€²å ´ï¼Œæ»‘é»æˆæœ¬é«˜",
                occurrence_count=len(wide_spread_trades),
                total_loss=sum(t.loss_amount for t in wide_spread_trades),
                avg_loss=np.mean([t.loss_amount for t in wide_spread_trades]),
                trades=[t.trade_id for t in wide_spread_trades],
                confidence=min(1.0, len(wide_spread_trades) / 10),
                recommendation="å»ºè­°ï¼š1) Spread > 0.1% æ™‚ç¦æ­¢äº¤æ˜“ 2) ä½¿ç”¨é™åƒ¹å–®"
            ))
        
        # æ¨¡å¼ 4ï¼šæ¥µç«¯ RSI é€²å ´è™§æï¼ˆRSI < 20 æˆ– > 80ï¼‰
        extreme_rsi_trades = [
            t for t in trades 
            if t.rsi_at_entry and (t.rsi_at_entry < 20 or t.rsi_at_entry > 80)
        ]
        if len(extreme_rsi_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="æ¥µç«¯RSIé€²å ´è™§æ",
                description="åœ¨ RSI æ¥µç«¯å€¼é€²å ´ï¼ˆæŠ„åº•/æ‘¸é ‚ï¼‰ï¼Œä½†è¶¨å‹¢ç¹¼çºŒ",
                occurrence_count=len(extreme_rsi_trades),
                total_loss=sum(t.loss_amount for t in extreme_rsi_trades),
                avg_loss=np.mean([t.loss_amount for t in extreme_rsi_trades]),
                trades=[t.trade_id for t in extreme_rsi_trades],
                confidence=min(1.0, len(extreme_rsi_trades) / 15),
                recommendation="å»ºè­°ï¼š1) ç­‰å¾… RSI èƒŒé›¢ç¢ºèª 2) çµåˆè¶¨å‹¢æŒ‡æ¨™ï¼ˆMAï¼‰3) é¿å…å–®ç´”æŠ„åº•"
            ))
        
        # æ¨¡å¼ 5ï¼šé•·æ™‚é–“æŒå€‰è™§æï¼ˆ> 1å°æ™‚ä»è¢«æ­¢æï¼‰
        long_hold_trades = [
            t for t in trades 
            if t.holding_time_seconds > 3600 and t.exit_reason == "SL_HIT"
        ]
        if len(long_hold_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="é•·æ™‚é–“æŒå€‰è™§æ",
                description="æŒå€‰è¶…é1å°æ™‚ä»è¢«æ­¢æï¼Œå¯èƒ½æ–¹å‘åˆ¤æ–·éŒ¯èª¤",
                occurrence_count=len(long_hold_trades),
                total_loss=sum(t.loss_amount for t in long_hold_trades),
                avg_loss=np.mean([t.loss_amount for t in long_hold_trades]),
                trades=[t.trade_id for t in long_hold_trades],
                confidence=min(1.0, len(long_hold_trades) / 10),
                recommendation="å»ºè­°ï¼š1) ä½¿ç”¨æ™‚é–“æ­¢æï¼ˆå¦‚30åˆ†é˜æœªç›ˆåˆ©å‰‡å‡ºå ´ï¼‰2) ä½¿ç”¨è¿½è¹¤æ­¢æ"
            ))
        
        # æ¨¡å¼ 6ï¼šç‰¹å®šæ™‚æ®µè™§æï¼ˆä¾‹å¦‚å‡Œæ™¨2-6é»ï¼‰
        night_trades = [
            t for t in trades 
            if 2 <= t.entry_time.hour <= 6
        ]
        if len(night_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="æ·±å¤œæ™‚æ®µè™§æ",
                description="åœ¨å‡Œæ™¨2-6é»äº¤æ˜“ï¼Œæµå‹•æ€§å·®",
                occurrence_count=len(night_trades),
                total_loss=sum(t.loss_amount for t in night_trades),
                avg_loss=np.mean([t.loss_amount for t in night_trades]),
                trades=[t.trade_id for t in night_trades],
                confidence=min(1.0, len(night_trades) / 10),
                recommendation="å»ºè­°ï¼š1) å•Ÿç”¨æ™‚é–“å€é–“åˆ†æå™¨ 2) å‡Œæ™¨2-6é»ç¦æ­¢äº¤æ˜“"
            ))
        
        # æ¨¡å¼ 7ï¼šé«˜æ§“æ¡¿è™§æï¼ˆæ§“æ¡¿ >= 10xï¼‰
        high_leverage_trades = [
            t for t in trades 
            if t.leverage >= 10
        ]
        if len(high_leverage_trades) >= self.min_pattern_count:
            patterns.append(LossPattern(
                pattern_name="é«˜æ§“æ¡¿è™§æ",
                description="ä½¿ç”¨é«˜æ§“æ¡¿ï¼ˆâ‰¥10xï¼‰ï¼Œå°æ³¢å‹•å³çˆ†å€‰",
                occurrence_count=len(high_leverage_trades),
                total_loss=sum(t.loss_amount for t in high_leverage_trades),
                avg_loss=np.mean([t.loss_amount for t in high_leverage_trades]),
                trades=[t.trade_id for t in high_leverage_trades],
                confidence=min(1.0, len(high_leverage_trades) / 8),
                recommendation="å»ºè­°ï¼š1) é™ä½æ§“æ¡¿è‡³ 3-5x 2) ä½¿ç”¨å‹•æ…‹æ§“æ¡¿ï¼ˆæ ¹æ“šæ³¢å‹•ç‡èª¿æ•´ï¼‰"
            ))
        
        # æŒ‰è™§æç¸½é¡æ’åº
        patterns.sort(key=lambda p: p.total_loss, reverse=True)
        
        return patterns
    
    def get_worst_patterns(self, top_n: int = 3) -> List[LossPattern]:
        """
        ç²å–æœ€åš´é‡çš„è™§ææ¨¡å¼
        
        Args:
            top_n: è¿”å›å‰ N å€‹æ¨¡å¼
            
        Returns:
            æŒ‰è™§æé‡‘é¡æ’åºçš„æ¨¡å¼åˆ—è¡¨
        """
        patterns = self.analyze_patterns()
        return patterns[:top_n]
    
    def get_summary_report(self) -> Dict:
        """
        ç”Ÿæˆè™§ææ‘˜è¦å ±å‘Š
        
        Returns:
            åŒ…å«çµ±è¨ˆä¿¡æ¯çš„å­—å…¸
        """
        if not self.loss_trades:
            return {'message': 'å°šç„¡è™§æè¨˜éŒ„'}
        
        trades = list(self.loss_trades.values())
        patterns = self.analyze_patterns()
        
        # è¨ˆç®—çµ±è¨ˆ
        total_loss = sum(t.loss_amount for t in trades)
        avg_loss = np.mean([t.loss_amount for t in trades])
        median_loss = np.median([t.loss_amount for t in trades])
        max_loss = max(t.loss_amount for t in trades)
        
        # å‡ºå ´åŸå› çµ±è¨ˆ
        exit_reasons = Counter(t.exit_reason for t in trades)
        
        # ç­–ç•¥çµ±è¨ˆ
        strategy_stats = defaultdict(lambda: {'count': 0, 'total_loss': 0})
        for t in trades:
            strategy_stats[t.strategy]['count'] += 1
            strategy_stats[t.strategy]['total_loss'] += t.loss_amount
        
        return {
            'total_losses': len(trades),
            'total_loss_amount': total_loss,
            'avg_loss': avg_loss,
            'median_loss': median_loss,
            'max_single_loss': max_loss,
            'patterns_identified': len(patterns),
            'top_patterns': [p.pattern_name for p in patterns[:3]],
            'exit_reasons': dict(exit_reasons),
            'worst_strategy': max(
                strategy_stats.items(), 
                key=lambda x: x[1]['total_loss']
            )[0] if strategy_stats else None,
            'avg_holding_time_minutes': np.mean([
                t.holding_time_seconds / 60 for t in trades
            ])
        }
    
    def generate_detailed_report(self) -> str:
        """
        ç”Ÿæˆè©³ç´°çš„éŒ¯å–®åˆ†æå ±å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„å ±å‘Šå­—ç¬¦ä¸²
        """
        patterns = self.analyze_patterns()
        summary = self.get_summary_report()
        
        report = "=" * 60 + "\n"
        report += "éŒ¯å–®æ”¾å¤§é¡ - è™§ææ¨¡å¼åˆ†æå ±å‘Š\n"
        report += "=" * 60 + "\n\n"
        
        report += "ğŸ“Š è™§æçµ±è¨ˆæ‘˜è¦\n"
        report += f"  ç¸½è™§æç­†æ•¸: {summary['total_losses']}\n"
        report += f"  ç¸½è™§æé‡‘é¡: ${summary['total_loss_amount']:.2f}\n"
        report += f"  å¹³å‡è™§æ: ${summary['avg_loss']:.2f}\n"
        report += f"  æœ€å¤§å–®ç­†è™§æ: ${summary['max_single_loss']:.2f}\n"
        report += f"  å¹³å‡æŒå€‰æ™‚é–“: {summary['avg_holding_time_minutes']:.1f} åˆ†é˜\n\n"
        
        if patterns:
            report += f"ğŸ” è­˜åˆ¥å‡º {len(patterns)} å€‹è™§ææ¨¡å¼\n\n"
            
            for i, pattern in enumerate(patterns, 1):
                report += f"æ¨¡å¼ {i}: {pattern.pattern_name}\n"
                report += f"  æè¿°: {pattern.description}\n"
                report += f"  å‡ºç¾æ¬¡æ•¸: {pattern.occurrence_count}\n"
                report += f"  ç´¯è¨ˆè™§æ: ${pattern.total_loss:.2f}\n"
                report += f"  å¹³å‡è™§æ: ${pattern.avg_loss:.2f}\n"
                report += f"  ä¿¡å¿ƒåº¦: {pattern.confidence:.0%}\n"
                report += f"  {pattern.recommendation}\n\n"
        else:
            report += "âšª æ•¸æ“šä¸è¶³ï¼Œæš«ç„¡é¡¯è‘—è™§ææ¨¡å¼\n\n"
        
        report += "=" * 60 + "\n"
        
        return report


# ==================== ä½¿ç”¨ç¯„ä¾‹ ====================
if __name__ == "__main__":
    # å‰µå»ºåˆ†æå™¨
    analyzer = LossPatternAnalyzer(
        data_file="data/test_loss_trades.json",
        min_pattern_count=3
    )
    
    # æ¨¡æ“¬è¨˜éŒ„è™§æäº¤æ˜“
    print("=== æ¨¡æ“¬è™§æäº¤æ˜“è¨˜éŒ„ ===\n")
    
    np.random.seed(42)
    
    for i in range(30):
        entry_time = datetime.now() - timedelta(hours=np.random.randint(1, 720))
        exit_time = entry_time + timedelta(seconds=np.random.randint(60, 7200))
        
        trade = LossTrade(
            trade_id=f"LOSS_{i:04d}",
            entry_time=entry_time,
            exit_time=exit_time,
            entry_price=50000 + np.random.randn() * 1000,
            exit_price=49500 + np.random.randn() * 1000,
            position_size=0.1 + np.random.random() * 0.5,
            leverage=np.random.choice([3, 5, 10, 20]),
            direction=np.random.choice(["LONG", "SHORT"]),
            loss_amount=np.random.uniform(5, 100),
            loss_percent=np.random.uniform(0.005, 0.02),
            holding_time_seconds=int((exit_time - entry_time).total_seconds()),
            rsi_at_entry=np.random.uniform(15, 85),
            spread_at_entry=np.random.uniform(0.0001, 0.002),
            vpin_at_entry=np.random.uniform(0.1, 0.8),
            exit_reason=np.random.choice(["SL_HIT", "TIMEOUT", "MANUAL"]),
            sl_percent=0.01,
            tp_percent=0.02,
            strategy="test_strategy"
        )
        
        analyzer.record_loss(trade)
    
    # ç”Ÿæˆå ±å‘Š
    print(analyzer.generate_detailed_report())
    
    # æœ€åš´é‡æ¨¡å¼
    print("=== å‰3å¤§è™§ææ¨¡å¼ ===")
    for pattern in analyzer.get_worst_patterns(3):
        print(f"\n{pattern.pattern_name}: ${pattern.total_loss:.2f}")
        print(f"  {pattern.recommendation}")
