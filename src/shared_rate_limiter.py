"""
å…±äº«é€Ÿç‡é™åˆ¶å™¨ (Shared Rate Limiter)
=====================================

è·¨é€²ç¨‹çš„ dYdX API é€Ÿç‡é™åˆ¶å”èª¿å™¨ã€‚
å…è¨±å¤šå€‹ bot åŒæ™‚é‹è¡Œè€Œä¸æœƒè¶…é API é™åˆ¶ã€‚

åŸç†:
- ä½¿ç”¨æ–‡ä»¶é– (fcntl) ç¢ºä¿åŸå­æ“ä½œ
- å…±äº«ç‹€æ…‹æ–‡ä»¶è¨˜éŒ„æ‰€æœ‰é€²ç¨‹çš„è«‹æ±‚æ™‚é–“æˆ³
- æ¯å€‹é€²ç¨‹åœ¨ç™¼é€è«‹æ±‚å‰æª¢æŸ¥å…¨å±€é…é¡

ç”¨æ³•:
    from src.shared_rate_limiter import SharedRateLimiter
    
    limiter = SharedRateLimiter()
    
    # åœ¨ç™¼é€ API è«‹æ±‚å‰èª¿ç”¨
    await limiter.acquire()
    response = await session.get(url)
"""

import asyncio
import fcntl
import json
import os
import time
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


class SharedRateLimiter:
    """
    è·¨é€²ç¨‹å…±äº«çš„é€Ÿç‡é™åˆ¶å™¨
    
    dYdX é™åˆ¶: 100 requests / 10 sec per IP
    å®‰å…¨è¨­å®š: 80 requests / 10 sec (ç•™ 20% ç·©è¡)
    """
    
    # å…±äº«ç‹€æ…‹æ–‡ä»¶è·¯å¾‘
    STATE_FILE = Path("/tmp/dydx_rate_limit_state.json")
    LOCK_FILE = Path("/tmp/dydx_rate_limit.lock")
    
    # é€Ÿç‡é™åˆ¶è¨­å®š
    MAX_REQUESTS_PER_WINDOW = 80  # ä¿å®ˆè¨­å®š (å®˜æ–¹ 100)
    WINDOW_SIZE_SECONDS = 10.0
    
    # å–®é€²ç¨‹æœ€å°é–“éš” (é¿å… burst)
    MIN_INTERVAL_MS = 150  # 150ms = ~6.6 req/sec per process
    
    def __init__(
        self,
        max_requests: int = None,
        window_seconds: float = None,
        process_id: str = None
    ):
        """
        åˆå§‹åŒ–å…±äº«é€Ÿç‡é™åˆ¶å™¨
        
        Args:
            max_requests: è‡ªè¨‚æœ€å¤§è«‹æ±‚æ•¸ (é è¨­ 80)
            window_seconds: æ™‚é–“çª—å£ç§’æ•¸ (é è¨­ 10)
            process_id: é€²ç¨‹è­˜åˆ¥ç¢¼ (é è¨­ä½¿ç”¨ PID)
        """
        self.max_requests = max_requests or self.MAX_REQUESTS_PER_WINDOW
        self.window_seconds = window_seconds or self.WINDOW_SIZE_SECONDS
        self.process_id = process_id or f"pid_{os.getpid()}"
        
        self._last_request_time = 0.0
        self._lock = asyncio.Lock()
        
        # ç¢ºä¿ç‹€æ…‹æ–‡ä»¶å­˜åœ¨
        self._init_state_file()
        
        logger.info(
            f"ğŸ”’ SharedRateLimiter åˆå§‹åŒ–: {self.process_id} "
            f"(é™åˆ¶: {self.max_requests}/{self.window_seconds}s)"
        )
    
    def _init_state_file(self):
        """åˆå§‹åŒ–å…±äº«ç‹€æ…‹æ–‡ä»¶"""
        if not self.STATE_FILE.exists():
            self._write_state({"requests": [], "processes": {}})
    
    def _read_state(self) -> dict:
        """è®€å–å…±äº«ç‹€æ…‹ (å¸¶æ–‡ä»¶é–)"""
        try:
            with open(self.LOCK_FILE, 'w') as lock_file:
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_SH)
                try:
                    if self.STATE_FILE.exists():
                        with open(self.STATE_FILE, 'r') as f:
                            return json.load(f)
                except (json.JSONDecodeError, FileNotFoundError):
                    pass
                finally:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
        except Exception as e:
            logger.warning(f"è®€å–ç‹€æ…‹æ–‡ä»¶å¤±æ•—: {e}")
        
        return {"requests": [], "processes": {}}
    
    def _write_state(self, state: dict):
        """å¯«å…¥å…±äº«ç‹€æ…‹ (å¸¶æ–‡ä»¶é–)"""
        try:
            with open(self.LOCK_FILE, 'w') as lock_file:
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
                try:
                    with open(self.STATE_FILE, 'w') as f:
                        json.dump(state, f)
                finally:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
        except Exception as e:
            logger.warning(f"å¯«å…¥ç‹€æ…‹æ–‡ä»¶å¤±æ•—: {e}")
    
    def _update_state_atomic(self, new_request_time: float) -> tuple[bool, float]:
        """
        åŸå­æ›´æ–°ç‹€æ…‹ä¸¦æª¢æŸ¥æ˜¯å¦å…è¨±è«‹æ±‚
        
        Returns:
            (allowed, wait_time): æ˜¯å¦å…è¨±è«‹æ±‚ï¼Œéœ€è¦ç­‰å¾…çš„æ™‚é–“
        """
        try:
            with open(self.LOCK_FILE, 'w') as lock_file:
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
                try:
                    # è®€å–ç•¶å‰ç‹€æ…‹
                    state = {"requests": [], "processes": {}}
                    if self.STATE_FILE.exists():
                        try:
                            with open(self.STATE_FILE, 'r') as f:
                                state = json.load(f)
                        except:
                            pass
                    
                    now = time.time()
                    window_start = now - self.window_seconds
                    
                    # æ¸…ç†éæœŸçš„è«‹æ±‚è¨˜éŒ„
                    state["requests"] = [
                        ts for ts in state["requests"] 
                        if ts > window_start
                    ]
                    
                    # æ¸…ç†ä¸æ´»èºçš„é€²ç¨‹
                    state["processes"] = {
                        pid: last_time 
                        for pid, last_time in state.get("processes", {}).items()
                        if now - last_time < 60  # 60 ç§’æ²’æ´»å‹•å°±æ¸…é™¤
                    }
                    
                    # è¨ˆç®—ç•¶å‰è«‹æ±‚æ•¸
                    current_count = len(state["requests"])
                    active_processes = len(state["processes"]) + 1  # +1 åŒ…å«è‡ªå·±
                    
                    # æ ¹æ“šæ´»èºé€²ç¨‹æ•¸å‹•æ…‹èª¿æ•´é…é¡
                    per_process_quota = self.max_requests / max(active_processes, 1)
                    my_requests = sum(
                        1 for ts in state["requests"]
                        if state.get("request_owners", {}).get(str(ts)) == self.process_id
                    )
                    
                    # æª¢æŸ¥æ˜¯å¦è¶…éå…¨å±€é™åˆ¶
                    if current_count >= self.max_requests:
                        # è¨ˆç®—éœ€è¦ç­‰å¾…çš„æ™‚é–“
                        oldest = min(state["requests"]) if state["requests"] else now
                        wait_time = max(0.1, oldest + self.window_seconds - now + 0.1)
                        return False, wait_time
                    
                    # è¨˜éŒ„æ–°è«‹æ±‚
                    state["requests"].append(new_request_time)
                    state["processes"][self.process_id] = now
                    
                    # è¨˜éŒ„è«‹æ±‚æ‰€æœ‰è€… (ç”¨æ–¼é…é¡è¨ˆç®—)
                    if "request_owners" not in state:
                        state["request_owners"] = {}
                    state["request_owners"][str(new_request_time)] = self.process_id
                    
                    # æ¸…ç†èˆŠçš„æ‰€æœ‰è€…è¨˜éŒ„
                    state["request_owners"] = {
                        ts: owner 
                        for ts, owner in state["request_owners"].items()
                        if float(ts) > window_start
                    }
                    
                    # å¯«å›ç‹€æ…‹
                    with open(self.STATE_FILE, 'w') as f:
                        json.dump(state, f)
                    
                    return True, 0.0
                    
                finally:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                    
        except Exception as e:
            logger.warning(f"æ›´æ–°ç‹€æ…‹å¤±æ•—: {e}")
            return True, 0.0  # ç™¼ç”ŸéŒ¯èª¤æ™‚å…è¨±è«‹æ±‚
    
    async def acquire(self, timeout: float = 30.0) -> bool:
        """
        ç²å– API è«‹æ±‚è¨±å¯
        
        Args:
            timeout: æœ€å¤§ç­‰å¾…æ™‚é–“ (ç§’)
            
        Returns:
            æ˜¯å¦æˆåŠŸç²å–è¨±å¯
        """
        async with self._lock:
            start_time = time.time()
            
            while True:
                # æª¢æŸ¥è¶…æ™‚
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    logger.warning(f"â° é€Ÿç‡é™åˆ¶ç­‰å¾…è¶…æ™‚ ({timeout}s)")
                    return False
                
                # ç¢ºä¿å–®é€²ç¨‹æœ€å°é–“éš”
                time_since_last = (time.time() - self._last_request_time) * 1000
                if time_since_last < self.MIN_INTERVAL_MS:
                    await asyncio.sleep((self.MIN_INTERVAL_MS - time_since_last) / 1000)
                
                # å˜—è©¦ç²å–è¨±å¯
                now = time.time()
                allowed, wait_time = self._update_state_atomic(now)
                
                if allowed:
                    self._last_request_time = now
                    return True
                
                # éœ€è¦ç­‰å¾…
                logger.debug(f"â³ é€Ÿç‡é™åˆ¶: ç­‰å¾… {wait_time:.2f}s")
                await asyncio.sleep(min(wait_time, timeout - elapsed))
    
    def get_stats(self) -> dict:
        """ç²å–ç•¶å‰é€Ÿç‡é™åˆ¶çµ±è¨ˆ"""
        state = self._read_state()
        now = time.time()
        window_start = now - self.window_seconds
        
        recent_requests = [ts for ts in state.get("requests", []) if ts > window_start]
        active_processes = {
            pid: last_time 
            for pid, last_time in state.get("processes", {}).items()
            if now - last_time < 60
        }
        
        return {
            "current_requests": len(recent_requests),
            "max_requests": self.max_requests,
            "window_seconds": self.window_seconds,
            "active_processes": len(active_processes),
            "process_ids": list(active_processes.keys()),
            "usage_percent": len(recent_requests) / self.max_requests * 100,
            "remaining_quota": self.max_requests - len(recent_requests),
        }
    
    def cleanup(self):
        """æ¸…ç†é€²ç¨‹è¨˜éŒ„ (ç¨‹å¼çµæŸæ™‚èª¿ç”¨)"""
        try:
            with open(self.LOCK_FILE, 'w') as lock_file:
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
                try:
                    if self.STATE_FILE.exists():
                        with open(self.STATE_FILE, 'r') as f:
                            state = json.load(f)
                        
                        # ç§»é™¤è‡ªå·±çš„é€²ç¨‹è¨˜éŒ„
                        if self.process_id in state.get("processes", {}):
                            del state["processes"][self.process_id]
                        
                        with open(self.STATE_FILE, 'w') as f:
                            json.dump(state, f)
                            
                        logger.info(f"ğŸ§¹ å·²æ¸…ç†é€²ç¨‹è¨˜éŒ„: {self.process_id}")
                finally:
                    fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
        except Exception as e:
            logger.warning(f"æ¸…ç†å¤±æ•—: {e}")


class RateLimitedSession:
    """
    åŒ…è£ aiohttp.ClientSessionï¼Œè‡ªå‹•æ‡‰ç”¨é€Ÿç‡é™åˆ¶
    
    ç”¨æ³•:
        async with RateLimitedSession() as session:
            async with session.get(url) as resp:
                data = await resp.json()
    """
    
    def __init__(self, limiter: SharedRateLimiter = None):
        self.limiter = limiter or SharedRateLimiter()
        self._session = None
    
    async def __aenter__(self):
        import aiohttp
        self._session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, *args):
        if self._session:
            await self._session.close()
        self.limiter.cleanup()
    
    async def get(self, url: str, **kwargs):
        """ç™¼é€ GET è«‹æ±‚ (è‡ªå‹•é€Ÿç‡é™åˆ¶)"""
        await self.limiter.acquire()
        return await self._session.get(url, **kwargs)
    
    async def post(self, url: str, **kwargs):
        """ç™¼é€ POST è«‹æ±‚ (è‡ªå‹•é€Ÿç‡é™åˆ¶)"""
        await self.limiter.acquire()
        return await self._session.post(url, **kwargs)


# å…¨å±€å¯¦ä¾‹ (å¯é¸)
_global_limiter: Optional[SharedRateLimiter] = None


def get_shared_limiter() -> SharedRateLimiter:
    """ç²å–å…¨å±€å…±äº«é€Ÿç‡é™åˆ¶å™¨"""
    global _global_limiter
    if _global_limiter is None:
        _global_limiter = SharedRateLimiter()
    return _global_limiter


# å¿«æ·å‡½æ•¸
async def acquire_rate_limit(timeout: float = 30.0) -> bool:
    """
    å¿«æ·å‡½æ•¸: ç²å– API è«‹æ±‚è¨±å¯
    
    ç”¨æ³•:
        from src.shared_rate_limiter import acquire_rate_limit
        
        if await acquire_rate_limit():
            response = await session.get(url)
    """
    return await get_shared_limiter().acquire(timeout)


def get_rate_limit_stats() -> dict:
    """å¿«æ·å‡½æ•¸: ç²å–é€Ÿç‡é™åˆ¶çµ±è¨ˆ"""
    return get_shared_limiter().get_stats()


if __name__ == "__main__":
    # æ¸¬è©¦
    import asyncio
    
    async def test():
        limiter = SharedRateLimiter()
        
        print("ğŸ“Š åˆå§‹ç‹€æ…‹:")
        print(json.dumps(limiter.get_stats(), indent=2))
        
        print("\nğŸ§ª æ¸¬è©¦ 10 æ¬¡ acquire:")
        for i in range(10):
            start = time.time()
            allowed = await limiter.acquire()
            elapsed = (time.time() - start) * 1000
            print(f"  {i+1}. allowed={allowed}, wait={elapsed:.0f}ms")
        
        print("\nğŸ“Š æœ€çµ‚ç‹€æ…‹:")
        print(json.dumps(limiter.get_stats(), indent=2))
        
        limiter.cleanup()
    
    asyncio.run(test())
